# 5.2.3 Compresi√≥n y Sumarizaci√≥n de Memoria

## Tiempo estimado: 75 minutos
## Nivel: Avanzado

## Prerrequisitos
- Vector Stores (5.2.1)
- Grafos de Conocimiento (5.2.2)
- Chain of Thought (2.2.1)

## ¬øPor qu√© es importante?

A medida que los agentes acumulan experiencias, la memoria crece indefinidamente. La **compresi√≥n y sumarizaci√≥n** son esenciales para:
- Mantener la memoria dentro de l√≠mites manejables
- Preservar informaci√≥n importante mientras se descarta ruido
- Mejorar la eficiencia de recuperaci√≥n
- Reducir costos de tokens en el contexto

> "La memoria perfecta no es √∫til si no puedes acceder a ella eficientemente. La compresi√≥n inteligente es la clave."

## Estrategias de Compresi√≥n

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ESTRATEGIAS DE COMPRESI√ìN DE MEMORIA                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                         ‚îÇ
‚îÇ  1. SUMARIZACI√ìN JER√ÅRQUICA                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                                                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   Memorias      ‚Üí   Res√∫menes    ‚Üí   Meta-resumen                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   individuales      por grupo        global                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚îÇ M1‚îÇ ‚îÇ M2‚îÇ  ‚Üí   ‚îÇResumen A‚îÇ  ‚Üí   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ             ‚îÇ             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                      ‚îÇ Meta-resumen‚îÇ             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ   Global    ‚îÇ             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚îÇ M3‚îÇ ‚îÇ M4‚îÇ  ‚Üí   ‚îÇResumen B‚îÇ  ‚Üí   ‚îÇ             ‚îÇ             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                         ‚îÇ
‚îÇ  2. CONSOLIDACI√ìN TEMPORAL                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                                                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   Hoy: Memorias detalladas                                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   Ayer: Memorias resumidas                                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   Semana pasada: Highlights                                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   Mes pasado: Insights clave                                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚îÇ HOY ‚îÇ ‚îÇAYER ‚îÇ ‚îÇSEMANA‚îÇ ‚îÇ MES ‚îÇ                               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚îÇ 100%‚îÇ ‚îÇ 50% ‚îÇ ‚îÇ 20%  ‚îÇ ‚îÇ 5%  ‚îÇ  ‚Üê Nivel de detalle          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                         ‚îÇ
‚îÇ  3. EXTRACCI√ìN DE HECHOS                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                                                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   Texto largo ‚Üí  Hechos at√≥micos                                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   "Juan pregunt√≥ sobre     ‚Üí  ‚Ä¢ Juan interesado en Python        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    Python ayer. Le gust√≥   ‚Üí  ‚Ä¢ Juan prefiere ejemplos           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    el ejemplo de listas    ‚Üí  ‚Ä¢ Interacci√≥n positiva             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    que le mostr√©."                                                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                         ‚îÇ
‚îÇ  4. CLUSTERING Y DEDUPLICACI√ìN                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                                                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   Memorias similares ‚Üí Representante √∫nico                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   "Usuario pidi√≥ info de Python" ‚îê                                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   "Usuario quiere aprender Python"‚îú‚Üí "Usuario interesado en     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   "Usuario pregunt√≥ por Python"  ‚îò    Python (3 menciones)"      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Implementaci√≥n del Sistema de Compresi√≥n

```python
import google.generativeai as genai
from dataclasses import dataclass, field
from typing import Optional, Any
from datetime import datetime, timedelta
from collections import defaultdict
import json
import os
import numpy as np

@dataclass
class MemoryItem:
    """Item de memoria con metadatos."""
    id: str
    content: str
    timestamp: datetime
    memory_type: str
    importance: float = 0.5
    access_count: int = 0
    compressed: bool = False
    original_ids: list[str] = field(default_factory=list)  # IDs originales si es comprimido


class MemoryCompressor:
    """
    Sistema de compresi√≥n y sumarizaci√≥n de memoria.
    """

    def __init__(self, model_name: str = "gemini-2.0-flash"):
        genai.configure(api_key=os.environ["GOOGLE_API_KEY"])
        self.model = genai.GenerativeModel(model_name)

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # SUMARIZACI√ìN
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    def summarize_memories(
        self,
        memories: list[MemoryItem],
        max_summary_length: int = 500,
        preserve_key_facts: bool = True
    ) -> str:
        """
        Resume un conjunto de memorias en un texto m√°s corto.
        """
        if not memories:
            return ""

        # Preparar contenido
        content = "\n\n".join([
            f"[{m.timestamp.strftime('%Y-%m-%d')}] {m.content}"
            for m in memories
        ])

        prompt = f"""Resume estas memorias en un texto conciso (m√°ximo {max_summary_length} caracteres).

MEMORIAS:
{content}

INSTRUCCIONES:
- Mant√©n la informaci√≥n m√°s importante
- Preserva fechas clave si son relevantes
- Elimina redundancias
- {'Extrae y lista hechos clave al final' if preserve_key_facts else ''}

RESUMEN:"""

        response = self.model.generate_content(prompt)
        return response.text[:max_summary_length]

    def summarize_hierarchically(
        self,
        memories: list[MemoryItem],
        group_size: int = 5,
        levels: int = 2
    ) -> dict:
        """
        Crea res√∫menes jer√°rquicos de las memorias.

        Returns:
            Dict con res√∫menes por nivel
        """
        result = {"level_0": [m.content for m in memories]}

        current_items = memories
        for level in range(1, levels + 1):
            summaries = []

            # Agrupar memorias
            groups = [current_items[i:i+group_size]
                     for i in range(0, len(current_items), group_size)]

            for group in groups:
                if isinstance(group[0], MemoryItem):
                    summary = self.summarize_memories(group)
                else:
                    # Ya son strings de nivel anterior
                    summary = self._summarize_texts(group)

                summaries.append(summary)

            result[f"level_{level}"] = summaries
            current_items = summaries

        # Resumen final
        if len(result[f"level_{levels}"]) > 1:
            result["final"] = self._summarize_texts(result[f"level_{levels}"])
        else:
            result["final"] = result[f"level_{levels}"][0] if result[f"level_{levels}"] else ""

        return result

    def _summarize_texts(self, texts: list[str]) -> str:
        """Resume una lista de textos."""
        content = "\n\n".join(texts)
        prompt = f"""Resume estos textos en uno solo, manteniendo la informaci√≥n esencial:

{content}

RESUMEN:"""

        response = self.model.generate_content(prompt)
        return response.text

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # CONSOLIDACI√ìN TEMPORAL
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    def consolidate_by_time(
        self,
        memories: list[MemoryItem],
        current_time: datetime = None
    ) -> dict[str, list]:
        """
        Consolida memorias seg√∫n su antig√ºedad.

        - Hoy: Sin cambios
        - Ayer a 7 d√≠as: Resumir por d√≠a
        - 7 a 30 d√≠as: Resumir por semana
        - M√°s de 30 d√≠as: Solo highlights
        """
        if current_time is None:
            current_time = datetime.now()

        buckets = {
            "today": [],
            "week": defaultdict(list),
            "month": defaultdict(list),
            "old": []
        }

        for memory in memories:
            age = current_time - memory.timestamp

            if age < timedelta(days=1):
                buckets["today"].append(memory)
            elif age < timedelta(days=7):
                day_key = memory.timestamp.strftime("%Y-%m-%d")
                buckets["week"][day_key].append(memory)
            elif age < timedelta(days=30):
                week_num = memory.timestamp.isocalendar()[1]
                week_key = f"week_{week_num}"
                buckets["month"][week_key].append(memory)
            else:
                buckets["old"].append(memory)

        # Consolidar cada bucket
        result = {
            "today": buckets["today"],  # Sin cambios
            "week_summaries": [],
            "month_summaries": [],
            "historical_highlights": None
        }

        # Resumir por d√≠a (√∫ltima semana)
        for day, day_memories in buckets["week"].items():
            summary = self.summarize_memories(day_memories)
            result["week_summaries"].append({
                "date": day,
                "summary": summary,
                "count": len(day_memories)
            })

        # Resumir por semana (√∫ltimo mes)
        for week, week_memories in buckets["month"].items():
            summary = self.summarize_memories(week_memories)
            result["month_summaries"].append({
                "week": week,
                "summary": summary,
                "count": len(week_memories)
            })

        # Extraer highlights de memorias antiguas
        if buckets["old"]:
            result["historical_highlights"] = self.extract_highlights(buckets["old"])

        return result

    def extract_highlights(
        self,
        memories: list[MemoryItem],
        max_highlights: int = 10
    ) -> list[str]:
        """
        Extrae los highlights m√°s importantes de un conjunto de memorias.
        """
        content = "\n".join([m.content for m in memories])

        prompt = f"""De estas memorias antiguas, extrae los {max_highlights} hechos/insights m√°s importantes que vale la pena recordar.

MEMORIAS:
{content}

Lista los highlights m√°s importantes (uno por l√≠nea):"""

        response = self.model.generate_content(prompt)

        highlights = []
        for line in response.text.split("\n"):
            line = line.strip().lstrip("‚Ä¢-*0123456789. ")
            if line:
                highlights.append(line)

        return highlights[:max_highlights]

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # EXTRACCI√ìN DE HECHOS
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    def extract_facts(self, memory: MemoryItem) -> list[str]:
        """
        Extrae hechos at√≥micos de una memoria.
        """
        prompt = f"""Extrae hechos at√≥micos de este texto. Cada hecho debe ser una afirmaci√≥n simple y verificable.

TEXTO:
{memory.content}

HECHOS (uno por l√≠nea, formato: "- hecho"):"""

        response = self.model.generate_content(prompt)

        facts = []
        for line in response.text.split("\n"):
            line = line.strip().lstrip("‚Ä¢-* ")
            if line and len(line) > 10:
                facts.append(line)

        return facts

    def compress_to_facts(
        self,
        memories: list[MemoryItem]
    ) -> list[dict]:
        """
        Comprime memorias a una lista de hechos con referencias.
        """
        all_facts = []

        for memory in memories:
            facts = self.extract_facts(memory)
            for fact in facts:
                all_facts.append({
                    "fact": fact,
                    "source_id": memory.id,
                    "timestamp": memory.timestamp.isoformat(),
                    "type": memory.memory_type
                })

        # Deduplicar hechos similares
        return self._deduplicate_facts(all_facts)

    def _deduplicate_facts(self, facts: list[dict]) -> list[dict]:
        """Elimina hechos duplicados o muy similares."""
        if not facts:
            return []

        # Generar embeddings
        embeddings = []
        for fact in facts:
            emb = self._generate_embedding(fact["fact"])
            embeddings.append(emb)

        # Encontrar duplicados por similitud
        unique_facts = []
        used_indices = set()

        for i, fact in enumerate(facts):
            if i in used_indices:
                continue

            # Buscar similares
            similar_indices = [i]
            for j in range(i + 1, len(facts)):
                if j not in used_indices:
                    sim = self._cosine_similarity(embeddings[i], embeddings[j])
                    if sim > 0.9:  # Umbral alto para considerar duplicado
                        similar_indices.append(j)
                        used_indices.add(j)

            # Crear entrada con conteo de ocurrencias
            merged_fact = fact.copy()
            merged_fact["occurrences"] = len(similar_indices)
            unique_facts.append(merged_fact)

        return unique_facts

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # CLUSTERING
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    def cluster_memories(
        self,
        memories: list[MemoryItem],
        n_clusters: int = 5
    ) -> dict[int, list[MemoryItem]]:
        """
        Agrupa memorias similares usando clustering.
        """
        if len(memories) < n_clusters:
            return {0: memories}

        # Generar embeddings
        embeddings = []
        for memory in memories:
            emb = self._generate_embedding(memory.content)
            embeddings.append(emb)

        embeddings_array = np.array(embeddings)

        # K-means simple
        clusters = self._simple_kmeans(embeddings_array, n_clusters)

        # Organizar memorias por cluster
        result = defaultdict(list)
        for i, cluster_id in enumerate(clusters):
            result[cluster_id].append(memories[i])

        return dict(result)

    def _simple_kmeans(
        self,
        data: np.ndarray,
        k: int,
        max_iters: int = 100
    ) -> list[int]:
        """K-means simplificado."""
        n_samples = data.shape[0]

        # Inicializar centroides aleatoriamente
        indices = np.random.choice(n_samples, k, replace=False)
        centroids = data[indices]

        for _ in range(max_iters):
            # Asignar a clusters
            distances = np.array([
                [np.linalg.norm(point - centroid) for centroid in centroids]
                for point in data
            ])
            labels = np.argmin(distances, axis=1)

            # Actualizar centroides
            new_centroids = np.array([
                data[labels == i].mean(axis=0) if np.sum(labels == i) > 0 else centroids[i]
                for i in range(k)
            ])

            if np.allclose(centroids, new_centroids):
                break

            centroids = new_centroids

        return labels.tolist()

    def summarize_clusters(
        self,
        clustered_memories: dict[int, list[MemoryItem]]
    ) -> dict[int, dict]:
        """
        Genera un resumen para cada cluster.
        """
        summaries = {}

        for cluster_id, memories in clustered_memories.items():
            summary = self.summarize_memories(memories, max_summary_length=300)

            # Encontrar tema com√∫n
            theme = self._identify_cluster_theme(memories)

            summaries[cluster_id] = {
                "theme": theme,
                "summary": summary,
                "count": len(memories),
                "date_range": {
                    "start": min(m.timestamp for m in memories).isoformat(),
                    "end": max(m.timestamp for m in memories).isoformat()
                }
            }

        return summaries

    def _identify_cluster_theme(self, memories: list[MemoryItem]) -> str:
        """Identifica el tema com√∫n de un cluster."""
        content = "\n".join([m.content[:200] for m in memories[:5]])

        prompt = f"""¬øCu√°l es el tema com√∫n de estas memorias? Responde en 3-5 palabras.

{content}

TEMA:"""

        response = self.model.generate_content(prompt)
        return response.text.strip()

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # UTILIDADES
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    def _generate_embedding(self, text: str) -> list[float]:
        try:
            result = genai.embed_content(
                model="models/embedding-001",
                content=text
            )
            return result['embedding']
        except:
            return list(np.random.randn(768))

    def _cosine_similarity(self, vec1: list[float], vec2: list[float]) -> float:
        a = np.array(vec1)
        b = np.array(vec2)
        return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)))


class CompressedMemoryManager:
    """
    Gestor de memoria con compresi√≥n autom√°tica.
    """

    def __init__(
        self,
        max_uncompressed: int = 100,
        compression_threshold: int = 50
    ):
        self.compressor = MemoryCompressor()
        self.memories: list[MemoryItem] = []
        self.compressed_memories: list[MemoryItem] = []
        self.max_uncompressed = max_uncompressed
        self.compression_threshold = compression_threshold

    def add_memory(self, content: str, memory_type: str = "general") -> str:
        """Agrega una memoria, comprimiendo si es necesario."""
        memory = MemoryItem(
            id=f"mem_{len(self.memories)}",
            content=content,
            timestamp=datetime.now(),
            memory_type=memory_type
        )
        self.memories.append(memory)

        # Verificar si necesita compresi√≥n
        if len(self.memories) >= self.max_uncompressed:
            self._auto_compress()

        return memory.id

    def _auto_compress(self):
        """Comprime memorias antiguas autom√°ticamente."""
        # Tomar las m√°s antiguas para comprimir
        to_compress = self.memories[:self.compression_threshold]
        self.memories = self.memories[self.compression_threshold:]

        # Consolidar por tiempo
        consolidated = self.compressor.consolidate_by_time(to_compress)

        # Crear memorias comprimidas
        for summary in consolidated.get("week_summaries", []):
            compressed = MemoryItem(
                id=f"compressed_{len(self.compressed_memories)}",
                content=summary["summary"],
                timestamp=datetime.fromisoformat(summary["date"]),
                memory_type="compressed_daily",
                compressed=True,
                original_ids=[m.id for m in to_compress]
            )
            self.compressed_memories.append(compressed)

        print(f"üóúÔ∏è Comprimidas {len(to_compress)} memorias")

    def get_relevant_memories(
        self,
        query: str,
        k: int = 5,
        include_compressed: bool = True
    ) -> list[MemoryItem]:
        """Obtiene memorias relevantes para una consulta."""
        all_memories = self.memories.copy()
        if include_compressed:
            all_memories.extend(self.compressed_memories)

        # Ranking simple por similitud
        query_emb = self.compressor._generate_embedding(query)

        scored = []
        for memory in all_memories:
            mem_emb = self.compressor._generate_embedding(memory.content)
            score = self.compressor._cosine_similarity(query_emb, mem_emb)
            scored.append((memory, score))

        scored.sort(key=lambda x: x[1], reverse=True)
        return [m for m, s in scored[:k]]

    def get_statistics(self) -> dict:
        return {
            "uncompressed": len(self.memories),
            "compressed": len(self.compressed_memories),
            "total_logical": len(self.memories) + sum(
                len(m.original_ids) for m in self.compressed_memories
            )
        }
```

## Ejemplo de Uso

```python
# Crear manager con compresi√≥n
manager = CompressedMemoryManager(
    max_uncompressed=50,
    compression_threshold=25
)

# Simular muchas memorias
for i in range(100):
    manager.add_memory(
        f"Usuario interactu√≥ con el sistema. Pregunta #{i} sobre Python.",
        memory_type="interaction"
    )

# Ver estad√≠sticas
print(manager.get_statistics())

# Buscar memorias relevantes
relevant = manager.get_relevant_memories("Python programming", k=5)
for mem in relevant:
    print(f"- {mem.content[:100]}...")

# Compresi√≥n manual
compressor = MemoryCompressor()
memories = manager.memories[:10]

# Sumarizaci√≥n jer√°rquica
hierarchy = compressor.summarize_hierarchically(memories, group_size=3, levels=2)
print(f"Resumen final: {hierarchy['final']}")

# Extracci√≥n de hechos
facts = compressor.compress_to_facts(memories)
print(f"Hechos extra√≠dos: {len(facts)}")
```

## Resumen

La **compresi√≥n de memoria** mantiene el sistema eficiente:

**Estrategias**:
1. **Sumarizaci√≥n jer√°rquica**: Res√∫menes de res√∫menes
2. **Consolidaci√≥n temporal**: M√°s detalle para memorias recientes
3. **Extracci√≥n de hechos**: Convertir narrativas en hechos at√≥micos
4. **Clustering**: Agrupar y representar memorias similares

**Mejores pr√°cticas**:
- Comprimir autom√°ticamente al alcanzar umbrales
- Preservar informaci√≥n de alta importancia
- Mantener referencias a originales
- Balancear compresi√≥n con recuperabilidad

---

## Navegaci√≥n

- **Anterior**: [5.2.2 Memoria Estructurada (Grafos)](./5.2.2-memoria-grafos-conocimiento.md)
- **Siguiente**: [6.1.1 Arquitectura RAG](../../modulo_6/tema_6.1/6.1.1-arquitectura-rag.md)
- **√çndice**: [README del Curso](../../README.md)
