# 11.2.1 Desarrollo de Agentes Core

## Objetivo de Aprendizaje

Al finalizar este subtema, habrás implementado los agentes core del sistema: BaseAgent, Orchestrator, Researcher, Analyst, Writer y Critic, con sus tools y lógica de negocio.

## Introducción

Es momento de implementar. Construiremos cada agente desde la clase base hasta las especializaciones, integrando todo lo aprendido en el curso.

## BaseAgent - Clase Abstracta

```python
# src/agents/base.py
import google.generativeai as genai
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Callable
import json
import time
import logging
import uuid

from src.config.settings import get_settings
from src.observability.metrics import MetricsCollector
from src.observability.tracing import AgentTracer

logger = logging.getLogger(__name__)

@dataclass
class AgentMessage:
    """Mensaje estandarizado entre agentes"""
    id: str = field(default_factory=lambda: str(uuid.uuid4()))
    sender: str = ""
    receiver: str = ""
    type: str = ""  # "task", "result", "error", "status"
    content: Dict[str, Any] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)
    timestamp: float = field(default_factory=time.time)

@dataclass
class AgentStep:
    """Registro de un paso del agente"""
    step_number: int
    action: str  # "llm_call", "tool_call", "decision"
    input_summary: str
    output_summary: str
    duration_ms: float
    tokens_used: int = 0
    tool_name: Optional[str] = None

class BaseAgent(ABC):
    """
    Clase base para todos los agentes del sistema.
    Implementa el loop fundamental: think → act → observe.
    """

    def __init__(
        self,
        name: str,
        role: str,
        system_instruction: str,
        model_name: str = "gemini-2.0-flash",
        tools: Optional[List[Dict]] = None,
        max_steps: int = 10,
        token_budget: int = 20000,
        metrics: Optional[MetricsCollector] = None,
        tracer: Optional[AgentTracer] = None
    ):
        self.name = name
        self.role = role
        self.system_instruction = system_instruction
        self.model_name = model_name
        self.max_steps = max_steps
        self.token_budget = token_budget
        self.metrics = metrics or MetricsCollector()
        self.tracer = tracer or AgentTracer()

        # Inicializar modelo
        self.model = genai.GenerativeModel(
            model_name,
            system_instruction=system_instruction,
            tools=tools or []
        )

        # Estado interno
        self._steps: List[AgentStep] = []
        self._total_tokens = 0
        self._tool_registry: Dict[str, Callable] = {}

        logger.info(f"Agent '{name}' initialized with model '{model_name}'")

    def register_tool(self, name: str, handler: Callable):
        """Registra handler para una tool"""
        self._tool_registry[name] = handler
        logger.debug(f"Tool '{name}' registered for agent '{self.name}'")

    async def execute(
        self,
        task: str,
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Ejecuta una tarea completa con el loop del agente.

        Returns:
            Dict con resultado, pasos, y métricas
        """
        self._steps = []
        self._total_tokens = 0
        start_time = time.time()

        with self.tracer.trace_task(
            task_description=task,
            task_type=self.role
        ) as span:
            try:
                # Preparar contexto
                full_prompt = self._build_prompt(task, context)

                # Iniciar chat
                chat = self.model.start_chat()

                # Primer mensaje
                with self.tracer.trace_llm_call(
                    model=self.model_name, step_number=0
                ):
                    response = chat.send_message(full_prompt)
                    self._track_tokens(response)

                # Loop de agente
                for step_num in range(1, self.max_steps + 1):
                    # Verificar budget
                    if self._total_tokens >= self.token_budget:
                        logger.warning(
                            f"Agent '{self.name}' exceeded token budget"
                        )
                        break

                    # Extraer function calls
                    function_calls = self._extract_function_calls(response)

                    if not function_calls:
                        # No más tools que llamar, tenemos respuesta
                        break

                    # Ejecutar tools
                    tool_responses = []
                    for fc in function_calls:
                        tool_result = await self._execute_tool(
                            fc["name"],
                            fc["args"],
                            step_num
                        )
                        tool_responses.append(
                            genai.protos.Part(
                                function_response=genai.protos.FunctionResponse(
                                    name=fc["name"],
                                    response={"result": json.dumps(tool_result, default=str)}
                                )
                            )
                        )

                    # Enviar resultados al modelo
                    with self.tracer.trace_llm_call(
                        model=self.model_name,
                        step_number=step_num
                    ):
                        response = chat.send_message(tool_responses)
                        self._track_tokens(response)

                # Extraer respuesta final
                final_text = self._extract_text(response)
                result = self._parse_output(final_text)

                duration = time.time() - start_time

                # Métricas
                self.metrics.record_agent_steps(self.role, len(self._steps))

                return {
                    "success": True,
                    "result": result,
                    "raw_response": final_text,
                    "steps": [
                        {
                            "step": s.step_number,
                            "action": s.action,
                            "tool": s.tool_name,
                            "duration_ms": s.duration_ms
                        }
                        for s in self._steps
                    ],
                    "metrics": {
                        "total_steps": len(self._steps),
                        "total_tokens": self._total_tokens,
                        "duration_seconds": round(duration, 2),
                        "agent": self.name
                    }
                }

            except Exception as e:
                logger.error(f"Agent '{self.name}' failed: {e}")
                return {
                    "success": False,
                    "error": str(e),
                    "steps": len(self._steps),
                    "agent": self.name
                }

    def _build_prompt(
        self,
        task: str,
        context: Optional[Dict] = None
    ) -> str:
        """Construye prompt con contexto"""
        parts = [f"TAREA: {task}"]

        if context:
            parts.append(f"\nCONTEXTO:\n{json.dumps(context, indent=2, default=str)}")

        return "\n".join(parts)

    def _extract_function_calls(self, response) -> List[Dict]:
        """Extrae function calls de la respuesta"""
        calls = []
        for candidate in response.candidates:
            for part in candidate.content.parts:
                if hasattr(part, 'function_call') and part.function_call:
                    calls.append({
                        "name": part.function_call.name,
                        "args": dict(part.function_call.args)
                    })
        return calls

    def _extract_text(self, response) -> str:
        """Extrae texto de la respuesta"""
        texts = []
        for candidate in response.candidates:
            for part in candidate.content.parts:
                if hasattr(part, 'text') and part.text:
                    texts.append(part.text)
        return "\n".join(texts)

    async def _execute_tool(
        self,
        tool_name: str,
        args: Dict,
        step_number: int
    ) -> Any:
        """Ejecuta una tool registrada"""
        handler = self._tool_registry.get(tool_name)

        if not handler:
            logger.error(f"Tool '{tool_name}' not registered")
            return {"error": f"Unknown tool: {tool_name}"}

        start = time.time()

        with self.tracer.trace_tool_call(tool_name, args):
            try:
                result = await handler(**args) if callable(handler) else handler(args)
                duration = (time.time() - start) * 1000

                self._steps.append(AgentStep(
                    step_number=step_number,
                    action="tool_call",
                    input_summary=f"{tool_name}({list(args.keys())})",
                    output_summary=str(result)[:200],
                    duration_ms=duration,
                    tool_name=tool_name
                ))

                self.metrics.record_tool_call(tool_name, duration / 1000, True)
                return result

            except Exception as e:
                logger.error(f"Tool '{tool_name}' failed: {e}")
                self.metrics.record_tool_call(tool_name, 0, False)
                return {"error": str(e)}

    def _track_tokens(self, response):
        """Trackea tokens consumidos"""
        if hasattr(response, 'usage_metadata'):
            tokens = response.usage_metadata.total_token_count
            self._total_tokens += tokens
            self.metrics.record_llm_call(
                model=self.model_name,
                input_tokens=response.usage_metadata.prompt_token_count,
                output_tokens=response.usage_metadata.candidates_token_count,
                duration_seconds=0,
                success=True
            )

    @abstractmethod
    def _parse_output(self, raw_output: str) -> Dict[str, Any]:
        """Parsea output del agente a formato estructurado"""
        pass
```

## Agentes Especializados

### Researcher Agent

```python
# src/agents/researcher.py
from src.agents.base import BaseAgent
from src.memory.manager import MemoryManager
from typing import Dict, Any, Optional
import json
import logging

logger = logging.getLogger(__name__)

class ResearcherAgent(BaseAgent):
    """Agente especializado en búsqueda y recopilación"""

    def __init__(self, memory: MemoryManager, **kwargs):
        # Definir tools para Gemini
        tools = [{
            "function_declarations": [
                {
                    "name": "web_search",
                    "description": "Busca información en la web",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "query": {"type": "string", "description": "Consulta de búsqueda"},
                            "num_results": {"type": "integer", "description": "Número de resultados"}
                        },
                        "required": ["query"]
                    }
                },
                {
                    "name": "extract_content",
                    "description": "Extrae contenido de una URL",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "url": {"type": "string", "description": "URL a extraer"}
                        },
                        "required": ["url"]
                    }
                },
                {
                    "name": "store_finding",
                    "description": "Almacena hallazgo en memoria",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "topic": {"type": "string"},
                            "content": {"type": "string"},
                            "source": {"type": "string"},
                            "reliability": {"type": "string", "enum": ["high", "medium", "low"]}
                        },
                        "required": ["topic", "content"]
                    }
                },
                {
                    "name": "search_memory",
                    "description": "Busca información previa en memoria",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "query": {"type": "string"},
                            "top_k": {"type": "integer"}
                        },
                        "required": ["query"]
                    }
                }
            ]
        }]

        super().__init__(
            name="Researcher",
            role="researcher",
            system_instruction=self._get_system_instruction(),
            tools=tools,
            max_steps=15,
            token_budget=20000,
            **kwargs
        )

        self.memory = memory
        self._register_tools()

    def _get_system_instruction(self) -> str:
        return """Eres el Researcher, especialista en búsqueda y recopilación.
Busca información relevante, evalúa fuentes, y organiza hallazgos.
Usa mínimo 3 queries diferentes. Siempre cita fuentes.
Responde con JSON estructurado al finalizar."""

    def _register_tools(self):
        """Registra handlers de tools"""
        self.register_tool("web_search", self._web_search)
        self.register_tool("extract_content", self._extract_content)
        self.register_tool("store_finding", self._store_finding)
        self.register_tool("search_memory", self._search_memory)

    async def _web_search(self, query: str, num_results: int = 5) -> Dict:
        """Búsqueda web (implementar con API real)"""
        # TODO: Integrar con Google Search API o SerpAPI
        logger.info(f"Searching: {query}")
        return {
            "results": [
                {"title": f"Result for: {query}", "url": "https://example.com", "snippet": "..."}
            ],
            "total_results": 1
        }

    async def _extract_content(self, url: str) -> Dict:
        """Extrae contenido de URL"""
        # TODO: Implementar con httpx + BeautifulSoup
        logger.info(f"Extracting: {url}")
        return {"content": "Extracted content...", "url": url}

    async def _store_finding(
        self,
        topic: str,
        content: str,
        source: str = "",
        reliability: str = "medium"
    ) -> Dict:
        """Almacena hallazgo en memoria semántica"""
        await self.memory.semantic.store(
            content=content,
            metadata={"topic": topic, "source": source, "reliability": reliability}
        )
        return {"stored": True, "topic": topic}

    async def _search_memory(self, query: str, top_k: int = 5) -> Dict:
        """Busca en memoria semántica"""
        results = await self.memory.semantic.search(query, top_k=top_k)
        return {"results": results}

    def _parse_output(self, raw_output: str) -> Dict[str, Any]:
        """Parsea output del researcher"""
        try:
            # Intentar extraer JSON del output
            start = raw_output.find('{')
            end = raw_output.rfind('}') + 1
            if start >= 0 and end > start:
                return json.loads(raw_output[start:end])
        except json.JSONDecodeError:
            pass

        return {
            "findings": [],
            "raw_text": raw_output,
            "parsed": False
        }
```

### Orchestrator Agent

```python
# src/agents/orchestrator.py
from src.agents.base import BaseAgent, AgentMessage
from src.agents.researcher import ResearcherAgent
from src.agents.analyst import AnalystAgent
from src.agents.writer import WriterAgent
from src.agents.critic import CriticAgent
from src.memory.manager import MemoryManager
from typing import Dict, Any, List, Optional
import json
import logging
import asyncio

logger = logging.getLogger(__name__)

class OrchestratorAgent(BaseAgent):
    """Agente orquestador que coordina el flujo de investigación"""

    def __init__(
        self,
        memory: MemoryManager,
        researcher: ResearcherAgent,
        analyst: 'AnalystAgent',
        writer: 'WriterAgent',
        critic: 'CriticAgent',
        **kwargs
    ):
        tools = [{
            "function_declarations": [
                {
                    "name": "delegate_research",
                    "description": "Delega investigación al Researcher",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "subtopic": {"type": "string"},
                            "instructions": {"type": "string"}
                        },
                        "required": ["subtopic"]
                    }
                },
                {
                    "name": "delegate_analysis",
                    "description": "Delega análisis al Analyst",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "data_summary": {"type": "string"},
                            "focus_areas": {"type": "string"}
                        },
                        "required": ["data_summary"]
                    }
                },
                {
                    "name": "delegate_writing",
                    "description": "Delega escritura al Writer",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "research_data": {"type": "string"},
                            "analysis_data": {"type": "string"},
                            "report_type": {"type": "string"}
                        },
                        "required": ["research_data"]
                    }
                },
                {
                    "name": "delegate_review",
                    "description": "Delega revisión al Critic",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "report": {"type": "string"}
                        },
                        "required": ["report"]
                    }
                }
            ]
        }]

        super().__init__(
            name="Orchestrator",
            role="orchestrator",
            system_instruction=self._get_system_instruction(),
            tools=tools,
            max_steps=20,
            token_budget=30000,
            **kwargs
        )

        self.memory = memory
        self.researcher = researcher
        self.analyst = analyst
        self.writer = writer
        self.critic = critic
        self._register_tools()

    def _get_system_instruction(self) -> str:
        return """Eres el Orchestrator. Coordinas una investigación completa.

PROCESO:
1. Analiza la solicitud y descompón en subtemas
2. Delega investigación de cada subtema al Researcher
3. Envía hallazgos al Analyst para análisis
4. Envía todo al Writer para crear reporte
5. Envía reporte al Critic para revisión
6. Si score < 8, pide mejoras (máx 2 veces)
7. Entrega resultado final

Siempre delega, nunca investigues directamente.
Responde con JSON al finalizar."""

    def _register_tools(self):
        self.register_tool("delegate_research", self._delegate_research)
        self.register_tool("delegate_analysis", self._delegate_analysis)
        self.register_tool("delegate_writing", self._delegate_writing)
        self.register_tool("delegate_review", self._delegate_review)

    async def _delegate_research(
        self,
        subtopic: str,
        instructions: str = ""
    ) -> Dict:
        """Delega al Researcher"""
        logger.info(f"Delegating research: {subtopic}")
        result = await self.researcher.execute(
            task=f"Investiga: {subtopic}. {instructions}",
            context={"parent_task": "investigation"}
        )
        return result

    async def _delegate_analysis(
        self,
        data_summary: str,
        focus_areas: str = ""
    ) -> Dict:
        """Delega al Analyst"""
        logger.info("Delegating analysis")
        result = await self.analyst.execute(
            task=f"Analiza: {data_summary}. Enfócate en: {focus_areas}",
            context={"type": "analysis"}
        )
        return result

    async def _delegate_writing(
        self,
        research_data: str,
        analysis_data: str = "",
        report_type: str = "investigation"
    ) -> Dict:
        """Delega al Writer"""
        logger.info("Delegating writing")
        result = await self.writer.execute(
            task=f"Escribe reporte tipo '{report_type}' basado en:\n"
                 f"INVESTIGACIÓN: {research_data}\n"
                 f"ANÁLISIS: {analysis_data}",
            context={"report_type": report_type}
        )
        return result

    async def _delegate_review(self, report: str) -> Dict:
        """Delega al Critic"""
        logger.info("Delegating review")
        result = await self.critic.execute(
            task=f"Revisa este reporte:\n{report}",
            context={"type": "review"}
        )
        return result

    def _parse_output(self, raw_output: str) -> Dict[str, Any]:
        try:
            start = raw_output.find('{')
            end = raw_output.rfind('}') + 1
            if start >= 0 and end > start:
                return json.loads(raw_output[start:end])
        except json.JSONDecodeError:
            pass
        return {"final_report": raw_output, "parsed": False}
```

## Ejemplo de Ejecución

```python
# scripts/run_investigation.py
import asyncio
import google.generativeai as genai
from src.agents.orchestrator import OrchestratorAgent
from src.agents.researcher import ResearcherAgent
from src.memory.manager import MemoryManager

async def main():
    genai.configure(api_key="YOUR_API_KEY")

    # Inicializar memoria
    memory = MemoryManager()

    # Crear agentes
    researcher = ResearcherAgent(memory=memory)
    analyst = AnalystAgent(memory=memory)
    writer = WriterAgent(memory=memory)
    critic = CriticAgent(memory=memory)

    # Crear orquestador
    orchestrator = OrchestratorAgent(
        memory=memory,
        researcher=researcher,
        analyst=analyst,
        writer=writer,
        critic=critic
    )

    # Ejecutar investigación
    result = await orchestrator.execute(
        task="Investiga el impacto de la inteligencia artificial en la educación"
    )

    if result["success"]:
        print("=== INVESTIGACIÓN COMPLETADA ===")
        print(f"Pasos: {result['metrics']['total_steps']}")
        print(f"Tokens: {result['metrics']['total_tokens']}")
        print(f"Duración: {result['metrics']['duration_seconds']}s")
        print(f"\n{result['raw_response'][:500]}...")
    else:
        print(f"Error: {result['error']}")

if __name__ == "__main__":
    asyncio.run(main())
```

## Ejercicios

### Ejercicio 1: Implementa AnalystAgent y WriterAgent siguiendo el patrón de ResearcherAgent.
### Ejercicio 2: Añade manejo de timeout en las delegaciones del Orchestrator.
### Ejercicio 3: Implementa ejecución paralela de subtemas en el Researcher.

## Resumen

| Componente | LOC Aprox | Dependencias |
|-----------|-----------|--------------|
| BaseAgent | ~200 | genai, logging, tracing |
| ResearcherAgent | ~150 | BaseAgent, Memory |
| AnalystAgent | ~120 | BaseAgent, Memory |
| WriterAgent | ~120 | BaseAgent, Memory |
| CriticAgent | ~100 | BaseAgent |
| OrchestratorAgent | ~200 | BaseAgent, All Agents |

---

**Siguiente:** [11.2.2 Integración y Orquestación](./11.2.2-integracion-orquestacion.md)
