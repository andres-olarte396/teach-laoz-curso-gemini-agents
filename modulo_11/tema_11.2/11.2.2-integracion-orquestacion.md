# 11.2.2 Integración y Orquestación

## Objetivo de Aprendizaje

Al finalizar este subtema, habrás integrado todos los agentes en un sistema funcional con comunicación, API REST, y flujo end-to-end de investigación.

## Introducción

La integración conecta todos los componentes: agentes se comunican vía message broker, la API REST expone el sistema, y el flujo end-to-end funciona de forma cohesiva.

## Message Broker

```python
# src/communication/broker.py
import redis.asyncio as redis
import json
import asyncio
import logging
from typing import Dict, Any, Optional, Callable, List
from dataclasses import asdict
from src.agents.base import AgentMessage
import uuid

logger = logging.getLogger(__name__)

class MessageBroker:
    """Broker de mensajes entre agentes usando Redis"""

    def __init__(self, redis_url: str = "redis://localhost:6379"):
        self.redis = redis.from_url(redis_url, decode_responses=True)
        self.pubsub = self.redis.pubsub()
        self._handlers: Dict[str, List[Callable]] = {}
        self._running = False

    async def publish(self, channel: str, message: AgentMessage):
        """Publica mensaje en un canal"""
        msg_data = json.dumps({
            "id": message.id,
            "sender": message.sender,
            "receiver": message.receiver,
            "type": message.type,
            "content": message.content,
            "metadata": message.metadata,
            "timestamp": message.timestamp
        }, default=str)

        await self.redis.publish(channel, msg_data)

        # También almacenar en lista para historial
        await self.redis.lpush(f"messages:{channel}", msg_data)
        await self.redis.ltrim(f"messages:{channel}", 0, 999)

        logger.debug(f"Published to {channel}: {message.type}")

    async def subscribe(self, channel: str, handler: Callable):
        """Suscribe handler a un canal"""
        if channel not in self._handlers:
            self._handlers[channel] = []
            await self.pubsub.subscribe(channel)

        self._handlers[channel].append(handler)
        logger.info(f"Subscribed to {channel}")

    async def start_listening(self):
        """Inicia loop de escucha de mensajes"""
        self._running = True

        async for message in self.pubsub.listen():
            if not self._running:
                break

            if message["type"] == "message":
                channel = message["channel"]
                data = json.loads(message["data"])

                agent_msg = AgentMessage(
                    id=data["id"],
                    sender=data["sender"],
                    receiver=data["receiver"],
                    type=data["type"],
                    content=data["content"],
                    metadata=data.get("metadata", {}),
                    timestamp=data["timestamp"]
                )

                # Ejecutar handlers
                for handler in self._handlers.get(channel, []):
                    try:
                        await handler(agent_msg)
                    except Exception as e:
                        logger.error(f"Handler error on {channel}: {e}")

    async def stop(self):
        """Detiene el broker"""
        self._running = False
        await self.pubsub.unsubscribe()
        await self.redis.close()

    async def request_reply(
        self,
        channel: str,
        message: AgentMessage,
        timeout: float = 60.0
    ) -> Optional[AgentMessage]:
        """Patrón request-reply: envía y espera respuesta"""
        reply_channel = f"reply:{message.id}"
        reply_received = asyncio.Event()
        reply_message = None

        async def on_reply(msg: AgentMessage):
            nonlocal reply_message
            reply_message = msg
            reply_received.set()

        await self.subscribe(reply_channel, on_reply)
        message.metadata["reply_to"] = reply_channel

        await self.publish(channel, message)

        try:
            await asyncio.wait_for(reply_received.wait(), timeout=timeout)
            return reply_message
        except asyncio.TimeoutError:
            logger.warning(f"Request-reply timeout for {message.id}")
            return None
        finally:
            await self.pubsub.unsubscribe(reply_channel)


class TaskQueue:
    """Cola de tareas para procesamiento asíncrono"""

    def __init__(self, redis_client: redis.Redis):
        self.redis = redis_client

    async def enqueue(self, task: Dict[str, Any]) -> str:
        """Añade tarea a la cola"""
        task_id = str(uuid.uuid4())
        task["task_id"] = task_id
        task["status"] = "queued"

        await self.redis.lpush("task_queue", json.dumps(task, default=str))
        await self.redis.hset(f"task:{task_id}", mapping={
            "status": "queued",
            "data": json.dumps(task, default=str)
        })

        return task_id

    async def dequeue(self, timeout: float = 30) -> Optional[Dict]:
        """Obtiene siguiente tarea de la cola"""
        result = await self.redis.brpop("task_queue", timeout=int(timeout))
        if result:
            return json.loads(result[1])
        return None

    async def update_status(
        self,
        task_id: str,
        status: str,
        result: Optional[Dict] = None
    ):
        """Actualiza estado de una tarea"""
        update = {"status": status}
        if result:
            update["result"] = json.dumps(result, default=str)

        await self.redis.hset(f"task:{task_id}", mapping=update)

    async def get_status(self, task_id: str) -> Optional[Dict]:
        """Obtiene estado de una tarea"""
        data = await self.redis.hgetall(f"task:{task_id}")
        if data:
            result = {"task_id": task_id, "status": data.get("status")}
            if "result" in data:
                result["result"] = json.loads(data["result"])
            return result
        return None
```

## API REST Integrada

```python
# src/api/main.py
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, Depends, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import Optional, Dict, Any
import google.generativeai as genai
import logging
import uuid

from src.config.settings import get_settings
from src.agents.orchestrator import OrchestratorAgent
from src.agents.researcher import ResearcherAgent
from src.communication.broker import MessageBroker, TaskQueue
from src.memory.manager import MemoryManager
from src.observability.logging import setup_logging

settings = get_settings()
logger = logging.getLogger(__name__)

# Estado de la aplicación
class AppState:
    orchestrator: OrchestratorAgent = None
    broker: MessageBroker = None
    task_queue: TaskQueue = None
    memory: MemoryManager = None

state = AppState()

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Ciclo de vida de la aplicación"""
    setup_logging(level=settings.log_level)
    genai.configure(api_key=settings.google_api_key)

    # Inicializar componentes
    state.memory = MemoryManager(redis_url=settings.redis_url)
    state.broker = MessageBroker(redis_url=settings.redis_url)

    # Crear agentes
    researcher = ResearcherAgent(memory=state.memory)
    # analyst = AnalystAgent(memory=state.memory)
    # writer = WriterAgent(memory=state.memory)
    # critic = CriticAgent(memory=state.memory)

    state.orchestrator = OrchestratorAgent(
        memory=state.memory,
        researcher=researcher,
        analyst=None,  # Implementar
        writer=None,   # Implementar
        critic=None    # Implementar
    )

    state.task_queue = TaskQueue(state.broker.redis)

    logger.info("Application started")
    yield
    logger.info("Application shutting down")

    await state.broker.stop()

# Crear app
app = FastAPI(
    title="Research Agent API",
    version="1.0.0",
    lifespan=lifespan
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# === Schemas ===

class ResearchRequest(BaseModel):
    topic: str = Field(..., min_length=5, max_length=1000)
    depth: str = Field(default="standard", pattern="^(quick|standard|deep)$")
    max_subtopics: int = Field(default=3, ge=1, le=10)

class ResearchResponse(BaseModel):
    research_id: str
    status: str
    message: str

class ChatRequest(BaseModel):
    message: str = Field(..., min_length=1, max_length=5000)
    session_id: Optional[str] = None

class ChatResponse(BaseModel):
    response: str
    session_id: str
    tokens_used: int

# === Endpoints ===

@app.get("/health")
async def health():
    return {"status": "healthy", "version": "1.0.0"}

@app.post("/api/v1/research", response_model=ResearchResponse)
async def create_research(
    request: ResearchRequest,
    background_tasks: BackgroundTasks
):
    """Inicia una nueva investigación"""
    research_id = str(uuid.uuid4())

    # Encolar tarea
    await state.task_queue.enqueue({
        "research_id": research_id,
        "topic": request.topic,
        "depth": request.depth,
        "max_subtopics": request.max_subtopics
    })

    # Ejecutar en background
    background_tasks.add_task(
        run_research,
        research_id,
        request.topic,
        request.depth
    )

    return ResearchResponse(
        research_id=research_id,
        status="queued",
        message=f"Research started for: {request.topic}"
    )

@app.get("/api/v1/research/{research_id}")
async def get_research_status(research_id: str):
    """Obtiene estado de una investigación"""
    status = await state.task_queue.get_status(research_id)

    if not status:
        raise HTTPException(404, "Research not found")

    return status

@app.post("/api/v1/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """Chat directo con el agente"""
    model = genai.GenerativeModel("gemini-2.0-flash")
    response = model.generate_content(request.message)

    return ChatResponse(
        response=response.text,
        session_id=request.session_id or str(uuid.uuid4()),
        tokens_used=response.usage_metadata.total_token_count
    )

# === Background Tasks ===

async def run_research(
    research_id: str,
    topic: str,
    depth: str
):
    """Ejecuta investigación en background"""
    try:
        await state.task_queue.update_status(research_id, "running")

        result = await state.orchestrator.execute(
            task=f"Investiga a profundidad '{depth}': {topic}",
            context={"research_id": research_id, "depth": depth}
        )

        await state.task_queue.update_status(
            research_id,
            "completed" if result["success"] else "failed",
            result
        )

    except Exception as e:
        logger.error(f"Research {research_id} failed: {e}")
        await state.task_queue.update_status(
            research_id,
            "failed",
            {"error": str(e)}
        )
```

## Docker Compose Completo

```yaml
# docker-compose.yml
version: '3.8'

services:
  api:
    build:
      context: .
      dockerfile: docker/Dockerfile.dev
    ports:
      - "8080:8080"
    volumes:
      - ./src:/app/src
    environment:
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - REDIS_URL=redis://redis:6379/0
      - DATABASE_URL=postgresql://postgres:postgres@db:5432/research_db
      - CHROMADB_HOST=chromadb
      - LOG_LEVEL=DEBUG
    depends_on:
      redis:
        condition: service_healthy
      db:
        condition: service_healthy
    networks:
      - app-network

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
    networks:
      - app-network

  db:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: research_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 3s
      retries: 5
    networks:
      - app-network

  chromadb:
    image: chromadb/chroma:latest
    ports:
      - "8000:8000"
    networks:
      - app-network

networks:
  app-network:
    driver: bridge
```

## Test de Integración End-to-End

```python
# tests/integration/test_e2e_flow.py
import pytest
import httpx
import asyncio

BASE_URL = "http://localhost:8080"

@pytest.mark.integration
class TestEndToEndFlow:

    @pytest.fixture(autouse=True)
    async def setup(self):
        self.client = httpx.AsyncClient(base_url=BASE_URL, timeout=120)
        yield
        await self.client.aclose()

    async def test_health_check(self):
        response = await self.client.get("/health")
        assert response.status_code == 200
        assert response.json()["status"] == "healthy"

    async def test_full_research_flow(self):
        """Test del flujo completo de investigación"""

        # 1. Crear investigación
        response = await self.client.post(
            "/api/v1/research",
            json={
                "topic": "Beneficios del open source",
                "depth": "quick",
                "max_subtopics": 2
            }
        )
        assert response.status_code == 200
        data = response.json()
        research_id = data["research_id"]
        assert data["status"] == "queued"

        # 2. Esperar completitud
        for _ in range(60):
            status_response = await self.client.get(
                f"/api/v1/research/{research_id}"
            )
            status = status_response.json()

            if status["status"] in ["completed", "failed"]:
                break

            await asyncio.sleep(2)

        # 3. Verificar resultado
        assert status["status"] == "completed"
        assert "result" in status

    async def test_chat_endpoint(self):
        response = await self.client.post(
            "/api/v1/chat",
            json={"message": "¿Qué es Python?"}
        )
        assert response.status_code == 200
        data = response.json()
        assert len(data["response"]) > 0
        assert data["tokens_used"] > 0
```

## Ejercicios

### Ejercicio 1: Implementa WebSocket para progreso en tiempo real en lugar de polling.
### Ejercicio 2: Añade ejecución paralela de subtemas en el Orchestrator.
### Ejercicio 3: Implementa retry con exponential backoff en el MessageBroker.

## Resumen

| Componente | Tecnología | Función |
|-----------|-----------|---------|
| MessageBroker | Redis Pub/Sub | Comunicación inter-agente |
| TaskQueue | Redis Lists | Cola de tareas async |
| API REST | FastAPI | Interface externa |
| Background Tasks | asyncio | Ejecución no-bloqueante |
| Docker Compose | Docker | Orquestación local |

---

**Siguiente:** [11.2.3 Testing y Refinamiento](./11.2.3-testing-refinamiento.md)
