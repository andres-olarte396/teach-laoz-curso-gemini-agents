# Zero-Shot, One-Shot y Few-Shot Learning

**Tiempo estimado**: 45 minutos
**Nivel**: Intermedio
**Prerrequisitos**: Anatomía de un Prompt Efectivo (2.1.1)

## ¿Por qué importa este concepto?

Los paradigmas de prompting basados en ejemplos determinan cómo el modelo generaliza a nuevas tareas. Comprender la diferencia entre zero-shot, one-shot y few-shot learning te permite:

- Optimizar el uso de tokens cuando los ejemplos son costosos
- Mejorar drásticamente la precisión en tareas específicas
- Decidir cuándo invertir en ejemplos vs confiar en las capacidades innatas del modelo
- Diseñar sistemas que escalan eficientemente con diferentes volúmenes de datos

---

## Definiciones fundamentales

```
┌─────────────────────────────────────────────────────────────┐
│ ZERO-SHOT                                                   │
│ ─────────                                                   │
│ Sin ejemplos previos. El modelo usa solo su conocimiento    │
│ pre-entrenado para resolver la tarea.                       │
│                                                             │
│ Prompt: "Clasifica el sentimiento: 'Excelente producto'"    │
│ → Modelo infiere basándose en su entrenamiento              │
├─────────────────────────────────────────────────────────────┤
│ ONE-SHOT                                                    │
│ ─────────                                                   │
│ Un único ejemplo de demostración antes de la tarea.         │
│                                                             │
│ Prompt: "Ejemplo: 'Me encanta' → Positivo                   │
│          Clasifica: 'Excelente producto'"                   │
│ → Modelo aprende el patrón del ejemplo                      │
├─────────────────────────────────────────────────────────────┤
│ FEW-SHOT                                                    │
│ ─────────                                                   │
│ Múltiples ejemplos (típicamente 3-10) de demostración.      │
│                                                             │
│ Prompt: "Ejemplos:                                          │
│          'Me encanta' → Positivo                            │
│          'Terrible' → Negativo                              │
│          'Normal' → Neutral                                 │
│          Clasifica: 'Excelente producto'"                   │
│ → Modelo aprende patrones más robustos                      │
└─────────────────────────────────────────────────────────────┘
```

---

## Implementación práctica

### Clase base para prompting con ejemplos

```python
import google.generativeai as genai
from dataclasses import dataclass, field
from typing import Optional, List, Tuple
from enum import Enum


class PromptingMode(Enum):
    ZERO_SHOT = "zero_shot"
    ONE_SHOT = "one_shot"
    FEW_SHOT = "few_shot"


@dataclass
class Example:
    """Representa un ejemplo de entrada/salida."""
    input_text: str
    output_text: str
    explanation: Optional[str] = None  # Opcional: explicación del razonamiento


@dataclass
class ShotPromptBuilder:
    """Constructor de prompts con soporte para zero/one/few-shot."""

    task_description: str
    examples: List[Example] = field(default_factory=list)
    output_format: Optional[str] = None

    def add_example(self, input_text: str, output_text: str,
                    explanation: Optional[str] = None) -> "ShotPromptBuilder":
        """Agrega un ejemplo de demostración."""
        self.examples.append(Example(input_text, output_text, explanation))
        return self

    def with_format(self, format_spec: str) -> "ShotPromptBuilder":
        """Especifica el formato de salida esperado."""
        self.output_format = format_spec
        return self

    @property
    def mode(self) -> PromptingMode:
        """Determina el modo basado en número de ejemplos."""
        if len(self.examples) == 0:
            return PromptingMode.ZERO_SHOT
        elif len(self.examples) == 1:
            return PromptingMode.ONE_SHOT
        else:
            return PromptingMode.FEW_SHOT

    def build(self, query: str) -> str:
        """Construye el prompt completo."""
        sections = []

        # Descripción de la tarea
        sections.append(f"TAREA: {self.task_description}")

        # Ejemplos si existen
        if self.examples:
            examples_section = "EJEMPLOS:"
            for i, ex in enumerate(self.examples, 1):
                examples_section += f"\n\nEjemplo {i}:"
                examples_section += f"\nEntrada: {ex.input_text}"
                examples_section += f"\nSalida: {ex.output_text}"
                if ex.explanation:
                    examples_section += f"\nRazonamiento: {ex.explanation}"
            sections.append(examples_section)

        # Formato de salida
        if self.output_format:
            sections.append(f"FORMATO DE RESPUESTA: {self.output_format}")

        # Query actual
        sections.append(f"ENTRADA ACTUAL: {query}")
        sections.append("SALIDA:")

        return "\n\n".join(sections)


# Configurar modelo
genai.configure(api_key="TU_API_KEY")
model = genai.GenerativeModel("gemini-1.5-flash")
```

### Comparación práctica: Zero vs One vs Few-shot

```python
def compare_prompting_modes(
    task: str,
    test_input: str,
    examples: List[Tuple[str, str]],
    model: genai.GenerativeModel
) -> dict:
    """
    Compara los tres modos de prompting en la misma tarea.

    Args:
        task: Descripción de la tarea
        test_input: Entrada a evaluar
        examples: Lista de (input, output) para ejemplos
        model: Modelo de Gemini configurado

    Returns:
        Diccionario con resultados de cada modo
    """
    results = {}

    # Zero-shot
    zero_prompt = ShotPromptBuilder(task).build(test_input)
    results["zero_shot"] = {
        "prompt": zero_prompt,
        "response": model.generate_content(zero_prompt).text,
        "tokens_prompt": len(zero_prompt.split())  # Aproximación
    }

    # One-shot
    one_builder = ShotPromptBuilder(task)
    one_builder.add_example(examples[0][0], examples[0][1])
    one_prompt = one_builder.build(test_input)
    results["one_shot"] = {
        "prompt": one_prompt,
        "response": model.generate_content(one_prompt).text,
        "tokens_prompt": len(one_prompt.split())
    }

    # Few-shot
    few_builder = ShotPromptBuilder(task)
    for inp, out in examples:
        few_builder.add_example(inp, out)
    few_prompt = few_builder.build(test_input)
    results["few_shot"] = {
        "prompt": few_prompt,
        "response": model.generate_content(few_prompt).text,
        "tokens_prompt": len(few_prompt.split())
    }

    return results


# Ejemplo: Clasificación de sentimiento
examples = [
    ("Este producto superó mis expectativas", "POSITIVO"),
    ("Llegó roto y el servicio fue pésimo", "NEGATIVO"),
    ("Cumple su función, nada especial", "NEUTRAL"),
    ("Me arrepiento de esta compra", "NEGATIVO"),
    ("Lo mejor que he comprado este año", "POSITIVO"),
]

results = compare_prompting_modes(
    task="Clasifica el sentimiento del texto como POSITIVO, NEGATIVO o NEUTRAL",
    test_input="El envío fue rápido pero el producto tiene algunos defectos menores",
    examples=examples,
    model=model
)

for mode, data in results.items():
    print(f"\n{'='*50}")
    print(f"Modo: {mode}")
    print(f"Tokens aprox: {data['tokens_prompt']}")
    print(f"Respuesta: {data['response']}")
```

---

## Cuándo usar cada modo

### Zero-Shot: Ideal cuando...

```python
# Tareas con instrucciones claras y bien definidas
zero_shot_tasks = [
    # Traducción simple
    "Traduce 'Hello world' al español",

    # Extracción de información estructurada
    "Extrae el email de: 'Contáctame en juan@ejemplo.com para más info'",

    # Tareas con formato estándar
    "Convierte '15 de marzo de 2024' al formato ISO 8601",

    # Razonamiento general
    "¿Cuál es la capital de Francia?",
]

# Usar zero-shot para tareas simples ahorra tokens
for task in zero_shot_tasks:
    response = model.generate_content(task)
    print(f"Task: {task[:50]}...")
    print(f"Response: {response.text}\n")
```

### One-Shot: Ideal cuando...

```python
# Necesitas establecer un formato específico o tono
ONE_SHOT_USE_CASES = """
1. Establecer formato de salida no estándar
2. Demostrar un estilo de escritura específico
3. Tareas con convenciones no obvias
4. Cuando tienes restricción de tokens pero necesitas guía
"""

# Ejemplo: Generar títulos con estilo específico
one_shot_builder = ShotPromptBuilder(
    "Genera un título clickbait para el siguiente contenido"
)
one_shot_builder.add_example(
    input_text="Artículo sobre los beneficios del ayuno intermitente",
    output_text="Los Médicos No Quieren Que Sepas Esto: El Secreto de 16 Horas Que Transformará Tu Cuerpo"
)

prompt = one_shot_builder.build(
    "Artículo sobre técnicas de productividad matutina"
)
print(model.generate_content(prompt).text)
```

### Few-Shot: Ideal cuando...

```python
# Tareas complejas que requieren múltiples ejemplos para capturar patrones
class FewShotClassifier:
    """Clasificador basado en few-shot learning."""

    def __init__(self, task: str, model: genai.GenerativeModel):
        self.builder = ShotPromptBuilder(task)
        self.model = model

    def add_training_examples(self, examples: List[Tuple[str, str]]):
        """Agrega ejemplos de entrenamiento."""
        for inp, out in examples:
            self.builder.add_example(inp, out)
        return self

    def classify(self, text: str) -> str:
        """Clasifica un nuevo texto."""
        prompt = self.builder.build(text)
        return self.model.generate_content(prompt).text.strip()


# Ejemplo: Clasificador de intenciones de usuario
intent_classifier = FewShotClassifier(
    task="Clasifica la intención del usuario en una de estas categorías: "
         "CONSULTA_PRECIO, SOPORTE_TECNICO, QUEJA, COMPRA, OTRO",
    model=model
)

intent_classifier.add_training_examples([
    ("¿Cuánto cuesta el plan premium?", "CONSULTA_PRECIO"),
    ("No puedo iniciar sesión en mi cuenta", "SOPORTE_TECNICO"),
    ("El producto llegó dañado y nadie me responde", "QUEJA"),
    ("Quiero comprar 5 unidades del modelo X", "COMPRA"),
    ("¿Tienen tienda física en Madrid?", "OTRO"),
    ("Mi factura tiene un cargo incorrecto", "QUEJA"),
    ("¿Hay descuento por volumen?", "CONSULTA_PRECIO"),
    ("La aplicación se cierra sola constantemente", "SOPORTE_TECNICO"),
])

# Clasificar nuevos mensajes
test_messages = [
    "Necesito el precio de 100 licencias",
    "Llevo 3 días esperando respuesta del chat",
    "¿Aceptan transferencia bancaria?",
]

for msg in test_messages:
    intent = intent_classifier.classify(msg)
    print(f"Mensaje: {msg}")
    print(f"Intención: {intent}\n")
```

---

## Técnicas avanzadas de Few-Shot

### 1. Selección dinámica de ejemplos

```python
from typing import Callable
import numpy as np


class DynamicFewShotSelector:
    """
    Selecciona ejemplos dinámicamente basándose en similitud
    con la entrada actual.
    """

    def __init__(
        self,
        examples: List[Example],
        similarity_fn: Callable[[str, str], float],
        k: int = 5
    ):
        """
        Args:
            examples: Pool de ejemplos disponibles
            similarity_fn: Función que calcula similitud entre textos
            k: Número de ejemplos a seleccionar
        """
        self.examples = examples
        self.similarity_fn = similarity_fn
        self.k = k

    def select(self, query: str) -> List[Example]:
        """Selecciona los k ejemplos más similares al query."""
        similarities = [
            (ex, self.similarity_fn(query, ex.input_text))
            for ex in self.examples
        ]

        # Ordenar por similitud descendente
        similarities.sort(key=lambda x: x[1], reverse=True)

        return [ex for ex, _ in similarities[:self.k]]


# Función de similitud simple (en producción usar embeddings)
def jaccard_similarity(text1: str, text2: str) -> float:
    """Calcula similitud de Jaccard entre dos textos."""
    words1 = set(text1.lower().split())
    words2 = set(text2.lower().split())

    intersection = words1 & words2
    union = words1 | words2

    return len(intersection) / len(union) if union else 0.0


# Uso con embeddings de Gemini (más preciso)
def embedding_similarity(text1: str, text2: str) -> float:
    """Calcula similitud usando embeddings de Gemini."""
    embedding_model = "models/embedding-001"

    emb1 = genai.embed_content(
        model=embedding_model,
        content=text1,
        task_type="retrieval_query"
    )["embedding"]

    emb2 = genai.embed_content(
        model=embedding_model,
        content=text2,
        task_type="retrieval_document"
    )["embedding"]

    # Similitud coseno
    return np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))
```

### 2. Chain-of-Thought con Few-Shot

```python
class FewShotCoT:
    """
    Combina few-shot learning con chain-of-thought
    incluyendo el razonamiento en los ejemplos.
    """

    def __init__(self, task: str, model: genai.GenerativeModel):
        self.task = task
        self.model = model
        self.examples: List[Example] = []

    def add_example_with_reasoning(
        self,
        input_text: str,
        reasoning: str,
        output_text: str
    ):
        """Agrega ejemplo con razonamiento explícito."""
        self.examples.append(Example(
            input_text=input_text,
            output_text=output_text,
            explanation=reasoning
        ))
        return self

    def solve(self, query: str) -> dict:
        """Resuelve mostrando razonamiento."""
        prompt = f"TAREA: {self.task}\n\n"

        # Ejemplos con razonamiento
        prompt += "EJEMPLOS CON RAZONAMIENTO:\n"
        for i, ex in enumerate(self.examples, 1):
            prompt += f"\nEjemplo {i}:\n"
            prompt += f"Problema: {ex.input_text}\n"
            prompt += f"Razonamiento: {ex.explanation}\n"
            prompt += f"Respuesta: {ex.output_text}\n"

        # Query actual
        prompt += f"\nPROBLEMA ACTUAL: {query}\n"
        prompt += "Muestra tu razonamiento paso a paso y luego da la respuesta final.\n"
        prompt += "Razonamiento:"

        response = self.model.generate_content(prompt)
        return {
            "prompt": prompt,
            "full_response": response.text
        }


# Ejemplo: Problemas de matemáticas con razonamiento
math_solver = FewShotCoT(
    task="Resuelve el problema matemático mostrando cada paso",
    model=model
)

math_solver.add_example_with_reasoning(
    input_text="Si tengo 3 manzanas y compro el doble, ¿cuántas tengo?",
    reasoning="1. Manzanas iniciales: 3\n"
              "2. Compro el doble: 3 × 2 = 6 manzanas\n"
              "3. Total: 3 + 6 = 9 manzanas",
    output_text="9 manzanas"
)

math_solver.add_example_with_reasoning(
    input_text="Un tren viaja a 60 km/h durante 2.5 horas. ¿Qué distancia recorre?",
    reasoning="1. Velocidad: 60 km/h\n"
              "2. Tiempo: 2.5 horas\n"
              "3. Distancia = Velocidad × Tiempo\n"
              "4. Distancia = 60 × 2.5 = 150 km",
    output_text="150 kilómetros"
)

result = math_solver.solve(
    "Una tienda vende 45 productos al día. ¿Cuántos vende en una semana de 5 días laborales?"
)
print(result["full_response"])
```

### 3. Diversidad en ejemplos

```python
def select_diverse_examples(
    examples: List[Example],
    k: int,
    diversity_threshold: float = 0.3
) -> List[Example]:
    """
    Selecciona k ejemplos maximizando diversidad.
    Evita ejemplos demasiado similares entre sí.
    """
    if len(examples) <= k:
        return examples

    selected = [examples[0]]  # Empezar con el primero

    for _ in range(k - 1):
        max_min_distance = -1
        best_candidate = None

        for candidate in examples:
            if candidate in selected:
                continue

            # Calcular distancia mínima a ejemplos ya seleccionados
            min_distance = min(
                1 - jaccard_similarity(candidate.input_text, sel.input_text)
                for sel in selected
            )

            if min_distance > max_min_distance:
                max_min_distance = min_distance
                best_candidate = candidate

        if best_candidate and max_min_distance >= diversity_threshold:
            selected.append(best_candidate)

    return selected
```

---

## Errores frecuentes

### Error 1: Ejemplos inconsistentes

```python
# ❌ Formato inconsistente entre ejemplos
bad_examples = [
    ("texto positivo", "POSITIVO"),      # Mayúsculas
    ("texto negativo", "negativo"),      # Minúsculas
    ("texto neutral", "Neutral."),       # Con punto
]

# ✓ Formato consistente
good_examples = [
    ("texto positivo", "POSITIVO"),
    ("texto negativo", "NEGATIVO"),
    ("texto neutral", "NEUTRAL"),
]
```

### Error 2: Ejemplos no representativos

```python
# ❌ Todos los ejemplos son muy similares
bad_examples = [
    ("Me encanta este producto", "POSITIVO"),
    ("Me encanta esta tienda", "POSITIVO"),
    ("Me encanta el servicio", "POSITIVO"),
]
# El modelo no aprende casos negativos ni neutrales

# ✓ Ejemplos diversos y balanceados
good_examples = [
    ("Me encanta este producto", "POSITIVO"),
    ("Terrible experiencia", "NEGATIVO"),
    ("Cumple con lo esperado", "NEUTRAL"),
    ("Lo mejor que he comprado", "POSITIVO"),
    ("No lo recomiendo", "NEGATIVO"),
]
```

### Error 3: Demasiados ejemplos

```python
# ❌ Usar 20 ejemplos cuando 5 son suficientes
# - Desperdicio de tokens
# - Posible confusión del modelo
# - Mayor latencia

# ✓ Encontrar el número óptimo
def find_optimal_k(
    task: str,
    examples: List[Example],
    test_cases: List[Tuple[str, str]],
    model: genai.GenerativeModel,
    max_k: int = 10
) -> int:
    """
    Encuentra el número óptimo de ejemplos
    evaluando accuracy en casos de prueba.
    """
    best_k = 0
    best_accuracy = 0

    for k in range(max_k + 1):
        builder = ShotPromptBuilder(task)
        for ex in examples[:k]:
            builder.add_example(ex.input_text, ex.output_text)

        correct = 0
        for test_input, expected in test_cases:
            prompt = builder.build(test_input)
            response = model.generate_content(prompt).text.strip()
            if response == expected:
                correct += 1

        accuracy = correct / len(test_cases)
        print(f"k={k}: accuracy={accuracy:.2%}")

        if accuracy > best_accuracy:
            best_accuracy = accuracy
            best_k = k

    return best_k
```

---

## Comparación de rendimiento

| Aspecto | Zero-Shot | One-Shot | Few-Shot |
|---------|-----------|----------|----------|
| Tokens de prompt | Mínimo | Bajo | Alto |
| Precisión en tareas simples | Alta | Alta | Alta |
| Precisión en tareas complejas | Variable | Media | Alta |
| Consistencia de formato | Variable | Buena | Excelente |
| Latencia | Mínima | Baja | Media |
| Costo por llamada | Bajo | Bajo | Medio-Alto |
| Adaptabilidad a dominios nuevos | Baja | Media | Alta |

---

## Aplicaciones reales

### Aplicación 1: Sistema de clasificación de tickets

```python
class TicketClassificationSystem:
    """Sistema de clasificación de tickets de soporte."""

    CATEGORIES = [
        "FACTURACION",
        "SOPORTE_TECNICO",
        "ENVIO",
        "DEVOLUCION",
        "CONSULTA_PRODUCTO",
        "OTRO"
    ]

    def __init__(self, model: genai.GenerativeModel):
        self.model = model
        self.builder = ShotPromptBuilder(
            f"Clasifica el ticket de soporte en una categoría: {', '.join(self.CATEGORIES)}"
        )
        self._load_examples()

    def _load_examples(self):
        """Carga ejemplos representativos por categoría."""
        examples = [
            ("Mi tarjeta fue cobrada dos veces", "FACTURACION"),
            ("La aplicación no carga mis datos", "SOPORTE_TECNICO"),
            ("¿Cuándo llegará mi pedido #12345?", "ENVIO"),
            ("Quiero devolver el producto, no era lo que esperaba", "DEVOLUCION"),
            ("¿Este modelo es compatible con iPhone?", "CONSULTA_PRODUCTO"),
            ("¿Tienen programa de afiliados?", "OTRO"),
        ]
        for inp, out in examples:
            self.builder.add_example(inp, out)

    def classify(self, ticket_text: str) -> dict:
        """Clasifica un ticket."""
        prompt = self.builder.build(ticket_text)
        response = self.model.generate_content(prompt).text.strip()

        # Validar categoría
        category = response if response in self.CATEGORIES else "OTRO"

        return {
            "ticket": ticket_text,
            "category": category,
            "confidence": "high" if response in self.CATEGORIES else "low"
        }
```

### Aplicación 2: Extractor de entidades configurab

```python
class ConfigurableEntityExtractor:
    """Extractor de entidades usando few-shot."""

    def __init__(self, entity_type: str, model: genai.GenerativeModel):
        self.model = model
        self.builder = ShotPromptBuilder(
            f"Extrae todas las entidades de tipo '{entity_type}' del texto. "
            "Devuelve una lista JSON."
        )
        self.builder.with_format('["entidad1", "entidad2", ...]')

    def add_training_example(self, text: str, entities: List[str]):
        """Agrega ejemplo de entrenamiento."""
        import json
        self.builder.add_example(text, json.dumps(entities, ensure_ascii=False))
        return self

    def extract(self, text: str) -> List[str]:
        """Extrae entidades del texto."""
        import json
        prompt = self.builder.build(text)
        response = self.model.generate_content(prompt).text.strip()

        try:
            return json.loads(response)
        except json.JSONDecodeError:
            return []


# Ejemplo: Extractor de tecnologías
tech_extractor = ConfigurableEntityExtractor("tecnología de software", model)
tech_extractor.add_training_example(
    "Usamos Python y Django para el backend, React para el frontend",
    ["Python", "Django", "React"]
)
tech_extractor.add_training_example(
    "La infraestructura corre en AWS con Kubernetes y Docker",
    ["AWS", "Kubernetes", "Docker"]
)

technologies = tech_extractor.extract(
    "Migramos de Java a Go y desplegamos en Google Cloud con Terraform"
)
print(technologies)  # ["Java", "Go", "Google Cloud", "Terraform"]
```

---

## Resumen del concepto

**En una frase**: Zero-shot no usa ejemplos, one-shot usa uno, y few-shot usa varios ejemplos para guiar al modelo en la tarea.

**Regla de decisión**:
- **Zero-shot**: Tareas simples con instrucciones claras
- **One-shot**: Establecer formato o estilo específico
- **Few-shot**: Tareas complejas, clasificación, o cuando necesitas alta consistencia

**Trade-off principal**: Más ejemplos = mayor precisión pero más tokens y latencia

**Siguiente paso**: Tema 2.1.3 - Role Prompting y Personas.
