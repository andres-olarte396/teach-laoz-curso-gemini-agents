# Chain of Thought (CoT) Prompting

**Tiempo estimado**: 45 minutos
**Nivel**: Intermedio
**Prerrequisitos**: Anatomía de prompts (2.1.1)

## ¿Por qué importa este concepto?

Chain of Thought (CoT) mejora dramáticamente el rendimiento del modelo en tareas que requieren razonamiento. En lugar de saltar directamente a la respuesta, el modelo muestra su proceso de pensamiento paso a paso.

**Impacto demostrado**:
- Problemas matemáticos: +40% de precisión
- Razonamiento lógico: +30% de precisión
- Tareas complejas multi-paso: Mejoras significativas

---

## El problema sin CoT

```python
# Sin CoT: El modelo salta a la respuesta
prompt_bad = "¿Cuántas pelotas de tenis caben en un autobús escolar?"

# El modelo puede adivinar o dar números sin fundamento
```

## La solución con CoT

```python
# Con CoT: El modelo razona paso a paso
prompt_cot = """
¿Cuántas pelotas de tenis caben en un autobús escolar?

Piensa paso a paso:
1. Primero, estima las dimensiones del autobús
2. Calcula el volumen interior
3. Estima el tamaño de una pelota de tenis
4. Divide el volumen del autobús entre el volumen de una pelota
5. Ajusta por el factor de empaquetamiento

Muestra tu razonamiento completo antes de dar la respuesta final.
"""
```

---

## Técnicas de CoT

### 1. Zero-Shot CoT

Simplemente agregar "Piensa paso a paso" activa el razonamiento.

```python
def zero_shot_cot(question: str) -> str:
    """Aplica Zero-Shot Chain of Thought."""
    return f"""
{question}

Piensa paso a paso y muestra tu razonamiento antes de dar la respuesta final.
"""


# Uso
prompt = zero_shot_cot("Si tengo 3 manzanas y le doy 1/3 a Juan, ¿cuántas me quedan?")
```

### 2. Few-Shot CoT

Proporcionar ejemplos de razonamiento completo.

```python
FEW_SHOT_COT_TEMPLATE = """
Responde la pregunta mostrando tu razonamiento paso a paso.

Ejemplo 1:
Pregunta: Un tren viaja a 60 km/h. ¿Cuánto tarda en recorrer 150 km?
Razonamiento:
- Velocidad = 60 km/h
- Distancia = 150 km
- Tiempo = Distancia / Velocidad
- Tiempo = 150 km / 60 km/h = 2.5 horas
Respuesta: 2.5 horas

Ejemplo 2:
Pregunta: Si un libro cuesta $20 y tiene 25% de descuento, ¿cuánto pagas?
Razonamiento:
- Precio original = $20
- Descuento = 25% = 0.25
- Monto del descuento = $20 × 0.25 = $5
- Precio final = $20 - $5 = $15
Respuesta: $15

Ahora responde:
Pregunta: {question}
Razonamiento:
"""

def few_shot_cot(question: str) -> str:
    return FEW_SHOT_COT_TEMPLATE.format(question=question)
```

### 3. Self-Ask CoT

El modelo se hace preguntas intermedias.

```python
SELF_ASK_TEMPLATE = """
Responde la pregunta haciéndote preguntas intermedias necesarias.

Pregunta: {question}

Para responder, pregúntate:
- ¿Qué información necesito?
- ¿Qué sub-preguntas debo responder primero?
- ¿Cómo se conectan las respuestas intermedias?

Formato:
Sub-pregunta 1: [pregunta]
Respuesta 1: [respuesta]

Sub-pregunta 2: [pregunta]
Respuesta 2: [respuesta]

...

Respuesta final: [respuesta a la pregunta original]
"""

def self_ask_cot(question: str) -> str:
    return SELF_ASK_TEMPLATE.format(question=question)
```

---

## Implementación con Gemini

```python
import google.generativeai as genai
import os
import re
from dataclasses import dataclass
from typing import Optional, List

genai.configure(api_key=os.environ["GOOGLE_API_KEY"])


@dataclass
class CoTResponse:
    """Respuesta estructurada con Chain of Thought."""
    question: str
    reasoning_steps: List[str]
    final_answer: str
    confidence: Optional[float] = None
    raw_response: str = ""


class ChainOfThoughtPrompt:
    """Generador de respuestas con Chain of Thought."""

    def __init__(self, model_name: str = "gemini-1.5-flash"):
        self.model = genai.GenerativeModel(
            model_name,
            generation_config=genai.GenerationConfig(
                temperature=0.3,  # Más bajo para razonamiento
                max_output_tokens=2048,
            )
        )

    def solve_with_cot(self, question: str) -> CoTResponse:
        """
        Resuelve una pregunta usando Chain of Thought.
        """
        prompt = f"""
Resuelve el siguiente problema paso a paso.

PROBLEMA:
{question}

INSTRUCCIONES:
1. Identifica qué tipo de problema es
2. Lista los datos conocidos
3. Determina qué necesitas encontrar
4. Resuelve paso a paso, mostrando cada cálculo
5. Verifica tu respuesta si es posible
6. Da la respuesta final claramente

FORMATO DE RESPUESTA:
## Tipo de problema
[identificación]

## Datos conocidos
[lista de datos]

## Objetivo
[qué necesitas encontrar]

## Resolución
Paso 1: [descripción y cálculo]
Paso 2: [descripción y cálculo]
...

## Verificación
[verificación opcional]

## Respuesta Final
[respuesta clara y concisa]
"""

        response = self.model.generate_content(prompt)
        return self._parse_response(question, response.text)

    def _parse_response(self, question: str, text: str) -> CoTResponse:
        """Parsea la respuesta en componentes estructurados."""
        # Extraer pasos de razonamiento
        steps = []
        step_pattern = r"Paso \d+:(.+?)(?=Paso \d+:|## |$)"
        matches = re.findall(step_pattern, text, re.DOTALL)
        for match in matches:
            steps.append(match.strip())

        # Extraer respuesta final
        final_pattern = r"## Respuesta Final\s*(.+?)(?=$|##)"
        final_match = re.search(final_pattern, text, re.DOTALL)
        final_answer = final_match.group(1).strip() if final_match else ""

        return CoTResponse(
            question=question,
            reasoning_steps=steps,
            final_answer=final_answer,
            raw_response=text
        )

    def compare_methods(self, question: str) -> dict:
        """
        Compara respuesta directa vs CoT.
        """
        # Sin CoT
        direct_response = self.model.generate_content(question)

        # Con CoT
        cot_response = self.solve_with_cot(question)

        return {
            "question": question,
            "direct_answer": direct_response.text,
            "cot_answer": cot_response.final_answer,
            "cot_steps": cot_response.reasoning_steps,
            "cot_full": cot_response.raw_response
        }


# Uso
cot = ChainOfThoughtPrompt()

# Problema matemático
result = cot.solve_with_cot(
    "Una tienda vende camisas a $25 cada una. Si compras 3 o más, "
    "tienes 20% de descuento. ¿Cuánto pagas por 4 camisas?"
)

print("Pasos de razonamiento:")
for i, step in enumerate(result.reasoning_steps, 1):
    print(f"  {i}. {step[:80]}...")

print(f"\nRespuesta final: {result.final_answer}")
```

---

## CoT para diferentes tipos de tareas

### Razonamiento matemático

```python
MATH_COT = """
Resuelve este problema matemático:

{problem}

Proceso:
1. **Identificar**: ¿Qué tipo de problema es? (aritmética, álgebra, geometría, etc.)
2. **Variables**: Define las variables y lo que representan
3. **Ecuaciones**: Plantea las ecuaciones necesarias
4. **Resolver**: Resuelve paso a paso, mostrando cada operación
5. **Unidades**: Verifica que las unidades sean correctas
6. **Verificar**: Comprueba la respuesta sustituyendo valores

Muestra TODO tu trabajo.
"""
```

### Razonamiento lógico

```python
LOGIC_COT = """
Analiza este problema de lógica:

{problem}

Proceso:
1. **Premisas**: Lista todas las premisas dadas
2. **Relaciones**: Identifica las relaciones entre elementos
3. **Deducciones**: Qué puedes deducir de cada premisa
4. **Contradicciones**: ¿Hay alguna contradicción?
5. **Conclusión**: Llega a la conclusión lógica

Para cada deducción, indica de qué premisas se deriva.
"""
```

### Análisis de código

```python
CODE_ANALYSIS_COT = """
Analiza este código y encuentra el error:

```{language}
{code}
```

Proceso de debugging:
1. **Propósito**: ¿Qué debería hacer este código?
2. **Flujo**: Traza la ejecución paso a paso
3. **Variables**: ¿Qué valor tiene cada variable en cada paso?
4. **Condiciones**: ¿Se evalúan correctamente las condiciones?
5. **Error**: ¿Dónde falla y por qué?
6. **Solución**: ¿Cómo se corrige?

Muestra la traza de ejecución con valores concretos.
"""
```

---

## Validación de razonamiento

```python
def validate_cot_response(question: str, cot_response: str) -> dict:
    """
    Valida que el razonamiento del CoT sea coherente.
    """
    model = genai.GenerativeModel("gemini-1.5-flash")

    validation_prompt = f"""
Evalúa si el siguiente razonamiento es correcto y coherente.

PREGUNTA ORIGINAL:
{question}

RAZONAMIENTO:
{cot_response}

Evalúa:
1. ¿Los pasos siguen lógicamente uno del otro?
2. ¿Hay errores de cálculo?
3. ¿La conclusión se deriva de los pasos?
4. ¿Falta algún paso importante?

Responde en JSON:
{{
    "is_valid": true/false,
    "logical_flow": "correcto/incorrecto",
    "calculation_errors": ["lista de errores" o []],
    "missing_steps": ["pasos faltantes" o []],
    "confidence_in_answer": 0.0-1.0,
    "feedback": "explicación breve"
}}
"""

    response = model.generate_content(validation_prompt)

    import json
    try:
        text = response.text.strip()
        if "```" in text:
            text = text.split("```")[1].replace("json", "").strip()
        return json.loads(text)
    except:
        return {"raw": response.text, "parse_error": True}
```

---

## Casos de prueba

```python
# test_chain_of_thought.py
import pytest


def test_cot_improves_math():
    """Test que CoT mejora respuestas matemáticas."""
    cot = ChainOfThoughtPrompt()

    result = cot.compare_methods(
        "Si un rectángulo tiene perímetro 24cm y el largo es el doble del ancho, ¿cuáles son sus dimensiones?"
    )

    # Verificar que CoT produce pasos
    assert len(result["cot_steps"]) > 0
    print(f"✓ CoT produjo {len(result['cot_steps'])} pasos")

    # La respuesta debería ser 4cm x 8cm
    assert "4" in result["cot_answer"] or "8" in result["cot_answer"]
    print(f"✓ Respuesta incluye dimensiones correctas")


def test_cot_shows_reasoning():
    """Test que CoT muestra razonamiento."""
    cot = ChainOfThoughtPrompt()

    result = cot.solve_with_cot("¿Cuántos segundos hay en una semana?")

    # Debe mostrar pasos intermedios
    assert result.reasoning_steps
    print(f"✓ Pasos de razonamiento: {len(result.reasoning_steps)}")

    # La respuesta correcta es 604,800
    assert "604" in result.final_answer.replace(",", "")
    print(f"✓ Respuesta: {result.final_answer}")


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
```

---

## Resumen del concepto

**En una frase**: Chain of Thought hace que el modelo muestre su razonamiento paso a paso, mejorando significativamente la precisión en tareas complejas.

**Técnicas principales**:
1. **Zero-Shot CoT**: "Piensa paso a paso"
2. **Few-Shot CoT**: Ejemplos con razonamiento
3. **Self-Ask**: Preguntas intermedias

**Cuándo usar CoT**:
- Problemas matemáticos
- Razonamiento lógico
- Análisis multi-paso
- Debugging de código
- Cualquier tarea que requiera pensamiento estructurado

**Siguiente paso**: Tema 2.2.2 - Self-Consistency y Majority Voting.
