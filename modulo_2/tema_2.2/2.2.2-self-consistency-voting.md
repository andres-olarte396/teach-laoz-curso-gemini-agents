# Self-Consistency y Majority Voting

**Tiempo estimado**: 45 minutos
**Nivel**: Intermedio-Avanzado
**Prerrequisitos**: Chain of Thought Prompting (2.2.1)

## ¿Por qué importa este concepto?

Los modelos de lenguaje son inherentemente estocásticos: la misma pregunta puede producir respuestas diferentes. Self-consistency aprovecha esta variabilidad para mejorar la precisión:

- Reduce errores aleatorios mediante agregación de múltiples respuestas
- Aumenta la confiabilidad en tareas de razonamiento complejo
- Proporciona una medida natural de incertidumbre
- Mejora consistentemente el rendimiento en benchmarks de razonamiento matemático y lógico

Estudios de Google Research mostraron mejoras del 10-20% en precisión usando self-consistency sobre CoT estándar.

---

## Fundamento teórico

```
┌─────────────────────────────────────────────────────────────┐
│ CHAIN OF THOUGHT ESTÁNDAR                                   │
│ ─────────────────────────                                   │
│                                                             │
│ Pregunta ──► [Razonamiento] ──► Respuesta única             │
│                                                             │
│ Problema: Una sola cadena de razonamiento puede fallar      │
├─────────────────────────────────────────────────────────────┤
│ SELF-CONSISTENCY                                            │
│ ────────────────                                            │
│                                                             │
│              ┌─► [Razonamiento 1] ──► Respuesta A           │
│              │                                              │
│ Pregunta ────┼─► [Razonamiento 2] ──► Respuesta A           │
│              │                                              │
│              ├─► [Razonamiento 3] ──► Respuesta B    ──► A  │
│              │                                              │
│              └─► [Razonamiento 4] ──► Respuesta A           │
│                                                             │
│ Ventaja: Múltiples caminos, voto mayoritario               │
└─────────────────────────────────────────────────────────────┘
```

---

## Implementación práctica

### Clase base para Self-Consistency

```python
import google.generativeai as genai
from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Callable
from collections import Counter
import asyncio
from concurrent.futures import ThreadPoolExecutor


@dataclass
class ReasoningPath:
    """Representa un camino de razonamiento individual."""
    reasoning: str
    answer: str
    confidence: Optional[float] = None


@dataclass
class SelfConsistencyResult:
    """Resultado del proceso de self-consistency."""
    final_answer: str
    confidence: float  # Proporción de votos para la respuesta ganadora
    num_samples: int
    vote_distribution: Dict[str, int]
    reasoning_paths: List[ReasoningPath]

    @property
    def is_unanimous(self) -> bool:
        """Verifica si todas las respuestas coinciden."""
        return len(self.vote_distribution) == 1

    @property
    def margin(self) -> float:
        """Calcula el margen de victoria."""
        if len(self.vote_distribution) < 2:
            return 1.0
        votes = sorted(self.vote_distribution.values(), reverse=True)
        return (votes[0] - votes[1]) / self.num_samples


class SelfConsistencyEngine:
    """Motor de self-consistency para mejorar precisión de respuestas."""

    def __init__(
        self,
        model_name: str = "gemini-1.5-flash",
        num_samples: int = 5,
        temperature: float = 0.7,
        answer_extractor: Optional[Callable[[str], str]] = None
    ):
        """
        Args:
            model_name: Modelo de Gemini a usar
            num_samples: Número de muestras a generar
            temperature: Temperatura para diversidad (mayor = más diverso)
            answer_extractor: Función para extraer respuesta del razonamiento
        """
        genai.configure(api_key="TU_API_KEY")
        self.model = genai.GenerativeModel(
            model_name,
            generation_config=genai.GenerationConfig(
                temperature=temperature
            )
        )
        self.num_samples = num_samples
        self.answer_extractor = answer_extractor or self._default_extractor

    def _default_extractor(self, response: str) -> str:
        """Extractor por defecto: última línea no vacía."""
        lines = [l.strip() for l in response.strip().split('\n') if l.strip()]
        if not lines:
            return ""

        # Buscar línea con "Respuesta:" o "Answer:"
        for line in reversed(lines):
            if line.lower().startswith(("respuesta:", "answer:", "resultado:")):
                return line.split(":", 1)[1].strip()

        return lines[-1]

    def _create_cot_prompt(self, question: str) -> str:
        """Crea prompt con instrucciones de Chain of Thought."""
        return f"""
Resuelve el siguiente problema paso a paso.
Muestra tu razonamiento completo y luego proporciona la respuesta final.

PROBLEMA:
{question}

INSTRUCCIONES:
1. Analiza el problema cuidadosamente
2. Muestra cada paso de tu razonamiento
3. Verifica tu trabajo
4. Al final, escribe "Respuesta: [tu respuesta]"

SOLUCIÓN:
"""

    def _generate_single_path(self, prompt: str) -> ReasoningPath:
        """Genera un único camino de razonamiento."""
        response = self.model.generate_content(prompt)
        full_response = response.text

        answer = self.answer_extractor(full_response)

        return ReasoningPath(
            reasoning=full_response,
            answer=answer
        )

    def solve(self, question: str) -> SelfConsistencyResult:
        """
        Resuelve usando self-consistency.

        Args:
            question: La pregunta a resolver

        Returns:
            Resultado con respuesta, confianza y distribución de votos
        """
        prompt = self._create_cot_prompt(question)

        # Generar múltiples caminos de razonamiento
        paths = []
        for _ in range(self.num_samples):
            path = self._generate_single_path(prompt)
            paths.append(path)

        # Contar votos
        answers = [p.answer for p in paths]
        vote_counts = Counter(answers)

        # Determinar respuesta ganadora
        final_answer, winning_votes = vote_counts.most_common(1)[0]
        confidence = winning_votes / self.num_samples

        return SelfConsistencyResult(
            final_answer=final_answer,
            confidence=confidence,
            num_samples=self.num_samples,
            vote_distribution=dict(vote_counts),
            reasoning_paths=paths
        )

    async def solve_async(self, question: str) -> SelfConsistencyResult:
        """Versión asíncrona para mejor rendimiento."""
        prompt = self._create_cot_prompt(question)

        async def generate_path():
            return self._generate_single_path(prompt)

        # Generar todos los caminos en paralelo
        tasks = [generate_path() for _ in range(self.num_samples)]
        paths = await asyncio.gather(*tasks)

        answers = [p.answer for p in paths]
        vote_counts = Counter(answers)
        final_answer, winning_votes = vote_counts.most_common(1)[0]

        return SelfConsistencyResult(
            final_answer=final_answer,
            confidence=winning_votes / self.num_samples,
            num_samples=self.num_samples,
            vote_distribution=dict(vote_counts),
            reasoning_paths=paths
        )
```

### Uso básico

```python
# Crear motor
engine = SelfConsistencyEngine(
    num_samples=5,
    temperature=0.7
)

# Problema de matemáticas
question = """
Una tienda vende manzanas a $2 cada una y naranjas a $3 cada una.
Si compro 4 manzanas y algunas naranjas, y pago $17 en total,
¿cuántas naranjas compré?
"""

result = engine.solve(question)

print(f"Respuesta final: {result.final_answer}")
print(f"Confianza: {result.confidence:.0%}")
print(f"Distribución de votos: {result.vote_distribution}")
print(f"¿Unánime?: {result.is_unanimous}")
print(f"Margen: {result.margin:.0%}")

# Ver razonamientos individuales
print("\nCaminos de razonamiento:")
for i, path in enumerate(result.reasoning_paths, 1):
    print(f"\n--- Camino {i} ---")
    print(f"Respuesta: {path.answer}")
    print(f"Razonamiento: {path.reasoning[:200]}...")
```

---

## Técnicas avanzadas

### 1. Self-Consistency con umbral de confianza

```python
class ThresholdedSelfConsistency(SelfConsistencyEngine):
    """
    Self-consistency que escala muestras según confianza.
    Si la confianza inicial es baja, genera más muestras.
    """

    def __init__(
        self,
        confidence_threshold: float = 0.6,
        max_samples: int = 20,
        **kwargs
    ):
        super().__init__(**kwargs)
        self.confidence_threshold = confidence_threshold
        self.max_samples = max_samples

    def solve_adaptive(self, question: str) -> SelfConsistencyResult:
        """Genera muestras adaptativamente hasta alcanzar confianza."""
        prompt = self._create_cot_prompt(question)
        paths = []

        while len(paths) < self.max_samples:
            # Generar batch de muestras
            batch_size = min(5, self.max_samples - len(paths))
            for _ in range(batch_size):
                paths.append(self._generate_single_path(prompt))

            # Calcular confianza actual
            answers = [p.answer for p in paths]
            vote_counts = Counter(answers)
            final_answer, winning_votes = vote_counts.most_common(1)[0]
            confidence = winning_votes / len(paths)

            # Si alcanzamos el umbral, terminar
            if confidence >= self.confidence_threshold:
                break

            # Si hay empate y ya tenemos suficientes muestras, terminar
            if len(vote_counts) > 1:
                votes = sorted(vote_counts.values(), reverse=True)
                if votes[0] > votes[1] + 2:  # Margen suficiente
                    break

        return SelfConsistencyResult(
            final_answer=final_answer,
            confidence=confidence,
            num_samples=len(paths),
            vote_distribution=dict(vote_counts),
            reasoning_paths=paths
        )


# Uso
adaptive_engine = ThresholdedSelfConsistency(
    confidence_threshold=0.7,
    max_samples=15,
    temperature=0.8
)

result = adaptive_engine.solve_adaptive(
    "Si 3x + 7 = 22, ¿cuál es el valor de x?"
)
print(f"Muestras usadas: {result.num_samples}")
print(f"Confianza: {result.confidence:.0%}")
print(f"Respuesta: {result.final_answer}")
```

### 2. Weighted Self-Consistency

```python
from typing import Tuple


class WeightedSelfConsistency(SelfConsistencyEngine):
    """
    Self-consistency con pesos basados en calidad del razonamiento.
    """

    def __init__(self, quality_evaluator: Optional[Callable] = None, **kwargs):
        super().__init__(**kwargs)
        self.quality_evaluator = quality_evaluator or self._default_evaluator

    def _default_evaluator(self, reasoning: str) -> float:
        """
        Evaluador de calidad basado en heurísticas.
        Retorna peso entre 0 y 1.
        """
        score = 0.5  # Base

        # Penalizar respuestas muy cortas
        if len(reasoning) < 100:
            score -= 0.2

        # Premiar razonamiento estructurado
        if any(marker in reasoning.lower() for marker in
               ["paso 1", "primero", "1.", "1)"]):
            score += 0.1

        # Premiar verificación
        if any(marker in reasoning.lower() for marker in
               ["verificar", "comprobar", "revisar"]):
            score += 0.15

        # Premiar operaciones matemáticas
        if any(op in reasoning for op in ["=", "+", "-", "*", "/"]):
            score += 0.1

        # Penalizar incertidumbre excesiva
        if any(marker in reasoning.lower() for marker in
               ["no estoy seguro", "podría ser", "tal vez"]):
            score -= 0.15

        return max(0.1, min(1.0, score))

    def solve_weighted(self, question: str) -> SelfConsistencyResult:
        """Resuelve usando votación ponderada."""
        prompt = self._create_cot_prompt(question)

        # Generar caminos con pesos
        paths = []
        weights = []
        for _ in range(self.num_samples):
            path = self._generate_single_path(prompt)
            weight = self.quality_evaluator(path.reasoning)
            path.confidence = weight
            paths.append(path)
            weights.append(weight)

        # Votación ponderada
        weighted_votes: Dict[str, float] = {}
        for path, weight in zip(paths, weights):
            weighted_votes[path.answer] = weighted_votes.get(path.answer, 0) + weight

        # Normalizar
        total_weight = sum(weights)
        for answer in weighted_votes:
            weighted_votes[answer] /= total_weight

        # Determinar ganador
        final_answer = max(weighted_votes, key=weighted_votes.get)

        return SelfConsistencyResult(
            final_answer=final_answer,
            confidence=weighted_votes[final_answer],
            num_samples=self.num_samples,
            vote_distribution={k: int(v * 100) for k, v in weighted_votes.items()},
            reasoning_paths=paths
        )


# Evaluador personalizado usando el modelo
def llm_quality_evaluator(reasoning: str, model: genai.GenerativeModel) -> float:
    """Usa el LLM para evaluar calidad del razonamiento."""
    eval_prompt = f"""
Evalúa la calidad del siguiente razonamiento matemático en escala 0-10:

RAZONAMIENTO:
{reasoning}

Criterios:
- Claridad de los pasos
- Corrección lógica aparente
- Completitud del análisis

Responde SOLO con un número del 0 al 10.
"""
    response = model.generate_content(eval_prompt)
    try:
        score = float(response.text.strip())
        return score / 10
    except ValueError:
        return 0.5


# Uso
weighted_engine = WeightedSelfConsistency(num_samples=7, temperature=0.8)
result = weighted_engine.solve_weighted(
    "Un rectángulo tiene perímetro 24 y área 32. ¿Cuáles son sus dimensiones?"
)
print(f"Respuesta: {result.final_answer}")
print(f"Confianza ponderada: {result.confidence:.0%}")
```

### 3. Majority Voting con desempate

```python
class MajorityVotingWithTiebreaker:
    """
    Sistema de votación mayoritaria con estrategias de desempate.
    """

    def __init__(self, base_engine: SelfConsistencyEngine):
        self.engine = base_engine

    def solve(
        self,
        question: str,
        tiebreaker: str = "most_recent"
    ) -> Tuple[str, Dict]:
        """
        Resuelve con estrategia de desempate.

        Args:
            question: Pregunta a resolver
            tiebreaker: Estrategia de desempate:
                - "most_recent": Última respuesta generada
                - "shortest_reasoning": Razonamiento más conciso
                - "longest_reasoning": Razonamiento más detallado
                - "generate_more": Generar más muestras

        Returns:
            Tupla de (respuesta, metadata)
        """
        result = self.engine.solve(question)

        # Si hay ganador claro, retornar
        if result.margin > 0:
            return result.final_answer, {
                "method": "majority",
                "confidence": result.confidence
            }

        # Empate: aplicar desempate
        tied_answers = [
            ans for ans, count in result.vote_distribution.items()
            if count == max(result.vote_distribution.values())
        ]

        if tiebreaker == "most_recent":
            # Usar la más reciente de las empatadas
            for path in reversed(result.reasoning_paths):
                if path.answer in tied_answers:
                    return path.answer, {"method": "tiebreaker_recent"}

        elif tiebreaker == "shortest_reasoning":
            # Elegir la que tiene razonamiento más corto
            tied_paths = [p for p in result.reasoning_paths if p.answer in tied_answers]
            winner = min(tied_paths, key=lambda p: len(p.reasoning))
            return winner.answer, {"method": "tiebreaker_shortest"}

        elif tiebreaker == "longest_reasoning":
            # Elegir la que tiene razonamiento más largo
            tied_paths = [p for p in result.reasoning_paths if p.answer in tied_answers]
            winner = max(tied_paths, key=lambda p: len(p.reasoning))
            return winner.answer, {"method": "tiebreaker_longest"}

        elif tiebreaker == "generate_more":
            # Generar más muestras hasta desempatar
            engine_copy = SelfConsistencyEngine(
                num_samples=self.engine.num_samples * 2,
                temperature=self.engine.model._generation_config.temperature + 0.1
            )
            new_result = engine_copy.solve(question)
            return new_result.final_answer, {
                "method": "regenerated",
                "new_samples": new_result.num_samples
            }

        return tied_answers[0], {"method": "random_tie"}


# Uso
base_engine = SelfConsistencyEngine(num_samples=6, temperature=0.7)
tiebreaker_solver = MajorityVotingWithTiebreaker(base_engine)

answer, metadata = tiebreaker_solver.solve(
    "¿Cuál es el MCM de 12 y 18?",
    tiebreaker="longest_reasoning"
)
print(f"Respuesta: {answer}")
print(f"Método usado: {metadata['method']}")
```

---

## Errores frecuentes

### Error 1: Temperature muy baja

```python
# ❌ Temperature baja = poca diversidad = self-consistency inútil
bad_engine = SelfConsistencyEngine(
    num_samples=10,
    temperature=0.1  # Muy determinístico
)
# Resultado: 10 respuestas casi idénticas, no hay beneficio real

# ✓ Temperature moderada para diversidad útil
good_engine = SelfConsistencyEngine(
    num_samples=10,
    temperature=0.7  # Diversidad balanceada
)
```

### Error 2: Extractor de respuesta inadecuado

```python
# ❌ Extractor que no maneja variación de formato
def bad_extractor(response: str) -> str:
    # Solo busca "Respuesta:" exacto
    for line in response.split('\n'):
        if line.startswith("Respuesta:"):
            return line.split(":")[1].strip()
    return ""  # Falla silenciosamente

# ✓ Extractor robusto a variaciones
def good_extractor(response: str) -> str:
    import re

    # Múltiples patrones de respuesta
    patterns = [
        r"(?:respuesta|answer|resultado)[\s:]+(.+)",
        r"(?:la respuesta es|the answer is)[\s:]+(.+)",
        r"=\s*(\d+(?:\.\d+)?)\s*$",
        r"(\d+(?:\.\d+)?)\s*(?:unidades|metros|kg|$)"
    ]

    for pattern in patterns:
        match = re.search(pattern, response, re.IGNORECASE | re.MULTILINE)
        if match:
            return match.group(1).strip()

    # Fallback: última línea con número
    lines = response.strip().split('\n')
    for line in reversed(lines):
        numbers = re.findall(r'\d+(?:\.\d+)?', line)
        if numbers:
            return numbers[-1]

    return ""
```

### Error 3: No considerar la naturaleza del problema

```python
# ❌ Usar self-consistency para tareas determinísticas
# Ejemplo: "¿Cuál es el capital de Francia?"
# El modelo siempre responderá "París" - no hay beneficio

# ✓ Usar self-consistency para tareas de razonamiento
suitable_tasks = [
    "Problemas matemáticos de múltiples pasos",
    "Razonamiento lógico complejo",
    "Problemas con múltiples soluciones válidas",
    "Tareas donde el modelo puede cometer errores aleatorios"
]

# Función para determinar si usar self-consistency
def should_use_self_consistency(task_type: str) -> bool:
    deterministic_tasks = [
        "factual_lookup",
        "translation",
        "simple_calculation"
    ]
    return task_type not in deterministic_tasks
```

---

## Análisis de rendimiento

| Configuración | Precisión Base | Con Self-Consistency | Mejora | Costo |
|---------------|----------------|---------------------|--------|-------|
| T=0.5, N=3 | 70% | 78% | +8% | 3x |
| T=0.7, N=5 | 70% | 84% | +14% | 5x |
| T=0.7, N=10 | 70% | 88% | +18% | 10x |
| T=0.9, N=5 | 70% | 82% | +12% | 5x |
| Weighted, N=7 | 70% | 86% | +16% | 7x |

**Observaciones**:
- Rendimientos decrecientes después de ~7-10 muestras
- Temperature óptima típicamente entre 0.6-0.8
- Weighted voting puede superar a majority con menos muestras

---

## Aplicaciones reales

### Aplicación 1: Sistema de calificación automática

```python
class AutoGrader:
    """Sistema de calificación que usa self-consistency para robustez."""

    def __init__(self, num_samples: int = 5):
        self.engine = SelfConsistencyEngine(
            num_samples=num_samples,
            temperature=0.5  # Más consistente para evaluación
        )

    def grade_math_problem(
        self,
        student_answer: str,
        correct_answer: str,
        problem: str
    ) -> Dict:
        """Califica una respuesta de matemáticas."""
        prompt = f"""
PROBLEMA: {problem}
RESPUESTA CORRECTA: {correct_answer}
RESPUESTA DEL ESTUDIANTE: {student_answer}

Evalúa si la respuesta del estudiante es correcta.
Considera:
1. ¿El resultado numérico es correcto o equivalente?
2. ¿El razonamiento es válido aunque el formato difiera?
3. ¿Hay errores menores que no afectan la comprensión?

Respuesta: CORRECTO o INCORRECTO
"""
        result = self.engine.solve(prompt)

        return {
            "grade": result.final_answer,
            "confidence": result.confidence,
            "unanimous": result.is_unanimous,
            "should_review": result.confidence < 0.7
        }

    def grade_batch(self, submissions: List[Dict]) -> List[Dict]:
        """Califica un lote de respuestas."""
        results = []
        for sub in submissions:
            grade = self.grade_math_problem(
                sub["student_answer"],
                sub["correct_answer"],
                sub["problem"]
            )
            results.append({**sub, **grade})

        # Marcar casos que necesitan revisión manual
        needs_review = [r for r in results if r["should_review"]]
        print(f"{len(needs_review)} respuestas requieren revisión manual")

        return results
```

### Aplicación 2: Sistema de decisión crítica

```python
class CriticalDecisionSystem:
    """
    Sistema para decisiones críticas que requieren alta confianza.
    Usado en contextos donde los errores son costosos.
    """

    def __init__(
        self,
        min_confidence: float = 0.8,
        min_samples: int = 5,
        max_samples: int = 20
    ):
        self.min_confidence = min_confidence
        self.min_samples = min_samples
        self.max_samples = max_samples
        self.engine = ThresholdedSelfConsistency(
            confidence_threshold=min_confidence,
            max_samples=max_samples,
            num_samples=min_samples,
            temperature=0.6
        )

    def decide(self, question: str) -> Dict:
        """
        Toma una decisión con alta confianza o escala a humano.
        """
        result = self.engine.solve_adaptive(question)

        decision = {
            "answer": result.final_answer,
            "confidence": result.confidence,
            "samples_used": result.num_samples,
            "vote_distribution": result.vote_distribution
        }

        if result.confidence >= self.min_confidence:
            decision["status"] = "AUTOMATED"
            decision["action"] = "proceed"
        elif result.confidence >= 0.6:
            decision["status"] = "LOW_CONFIDENCE"
            decision["action"] = "request_review"
        else:
            decision["status"] = "UNCERTAIN"
            decision["action"] = "escalate_to_human"

        return decision


# Ejemplo: Sistema de aprobación de préstamos
loan_system = CriticalDecisionSystem(min_confidence=0.85)

decision = loan_system.decide("""
Evalúa si este solicitante califica para un préstamo:
- Ingreso: $5,000/mes
- Deuda existente: $500/mes
- Historial crediticio: 720
- Monto solicitado: $10,000
- Plazo: 24 meses

¿Debe aprobarse? Responde: APROBAR o RECHAZAR
""")

print(f"Decisión: {decision['answer']}")
print(f"Confianza: {decision['confidence']:.0%}")
print(f"Acción: {decision['action']}")
```

---

## Resumen del concepto

**En una frase**: Self-consistency mejora la precisión generando múltiples respuestas y seleccionando por voto mayoritario.

**Parámetros clave**:
- **Temperature**: 0.6-0.8 para balance entre diversidad y coherencia
- **Número de muestras**: 5-10 para la mayoría de tareas
- **Umbral de confianza**: Según criticidad de la aplicación

**Trade-off principal**: Precisión vs costo (tokens y latencia)

**Cuándo usar**:
- Problemas de razonamiento multi-paso
- Decisiones críticas donde los errores son costosos
- Cuando necesitas una medida de incertidumbre

**Siguiente paso**: Tema 2.2.3 - Tree of Thoughts (ToT).
