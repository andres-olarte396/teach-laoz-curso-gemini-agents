# Tree of Thoughts (ToT)

**Tiempo estimado**: 50 minutos
**Nivel**: Avanzado
**Prerrequisitos**: Self-Consistency y Majority Voting (2.2.2)

## ¿Por qué importa este concepto?

Tree of Thoughts representa el estado del arte en prompting para razonamiento complejo. Mientras Chain of Thought genera una secuencia lineal y Self-Consistency muestrea múltiples secuencias independientes, ToT:

- Explora múltiples caminos de razonamiento de forma estructurada
- Permite backtracking cuando un camino no es prometedor
- Evalúa estados intermedios para podar ramas improductivas
- Combina la exploración de árboles de búsqueda con el razonamiento de LLMs

En benchmarks como Game of 24 y Creative Writing, ToT supera a CoT por márgenes del 20-70%.

---

## Arquitectura conceptual

```
┌─────────────────────────────────────────────────────────────────┐
│ CHAIN OF THOUGHT (LINEAL)                                       │
│                                                                 │
│ Problema ──► Paso1 ──► Paso2 ──► Paso3 ──► Respuesta           │
│                                                                 │
├─────────────────────────────────────────────────────────────────┤
│ SELF-CONSISTENCY (MÚLTIPLES CADENAS INDEPENDIENTES)             │
│                                                                 │
│              ┌─► Cadena 1 ──► Respuesta A                       │
│ Problema ────┼─► Cadena 2 ──► Respuesta A  ──► Voto ──► A      │
│              └─► Cadena 3 ──► Respuesta B                       │
│                                                                 │
├─────────────────────────────────────────────────────────────────┤
│ TREE OF THOUGHTS (EXPLORACIÓN ESTRUCTURADA)                     │
│                                                                 │
│                        ┌── Estado 2a ─┬─ Estado 3a ✓           │
│                        │              └─ Estado 3b ✗ (podado)  │
│ Problema ── Estado 1 ──┤                                        │
│                        │              ┌─ Estado 3c ✓ → Solución│
│                        └── Estado 2b ─┤                         │
│                                       └─ Estado 3d ✗ (podado)  │
│                                                                 │
│ Características:                                                │
│ • Evalúa estados intermedios                                    │
│ • Poda ramas no prometedoras                                    │
│ • Permite backtracking                                          │
│ • Búsqueda BFS o DFS                                           │
└─────────────────────────────────────────────────────────────────┘
```

---

## Implementación práctica

### Estructura base de Tree of Thoughts

```python
import google.generativeai as genai
from dataclasses import dataclass, field
from typing import List, Dict, Optional, Callable, Tuple
from enum import Enum
from abc import ABC, abstractmethod
import heapq


class SearchStrategy(Enum):
    BFS = "breadth_first"
    DFS = "depth_first"
    BEST_FIRST = "best_first"


@dataclass
class ThoughtNode:
    """Representa un nodo en el árbol de pensamientos."""
    state: str  # Estado actual del razonamiento
    parent: Optional['ThoughtNode'] = None
    children: List['ThoughtNode'] = field(default_factory=list)
    score: float = 0.0  # Evaluación del estado
    depth: int = 0
    is_terminal: bool = False
    is_solution: bool = False

    def get_path(self) -> List[str]:
        """Obtiene el camino desde la raíz hasta este nodo."""
        path = []
        node = self
        while node is not None:
            path.append(node.state)
            node = node.parent
        return list(reversed(path))

    def __lt__(self, other):
        """Para comparación en heap (best-first search)."""
        return self.score > other.score  # Mayor score = mayor prioridad


class TreeOfThoughts:
    """
    Implementación de Tree of Thoughts para razonamiento complejo.
    """

    def __init__(
        self,
        model_name: str = "gemini-1.5-flash",
        max_depth: int = 5,
        branching_factor: int = 3,
        search_strategy: SearchStrategy = SearchStrategy.BFS,
        pruning_threshold: float = 0.3
    ):
        """
        Args:
            model_name: Modelo de Gemini
            max_depth: Profundidad máxima del árbol
            branching_factor: Número de pensamientos a generar por nodo
            search_strategy: Estrategia de búsqueda
            pruning_threshold: Umbral de score para podar ramas
        """
        genai.configure(api_key="TU_API_KEY")
        self.model = genai.GenerativeModel(
            model_name,
            generation_config=genai.GenerationConfig(temperature=0.8)
        )
        self.max_depth = max_depth
        self.branching_factor = branching_factor
        self.search_strategy = search_strategy
        self.pruning_threshold = pruning_threshold

    def _generate_thoughts(
        self,
        problem: str,
        current_state: str,
        num_thoughts: int
    ) -> List[str]:
        """
        Genera múltiples pensamientos (pasos de razonamiento) desde el estado actual.
        """
        prompt = f"""
PROBLEMA: {problem}

RAZONAMIENTO HASTA AHORA:
{current_state}

Genera {num_thoughts} posibles PRÓXIMOS PASOS de razonamiento.
Cada paso debe ser diferente y explorar una dirección distinta.
Sé creativo pero lógico.

Formato:
PENSAMIENTO 1: [paso de razonamiento]
PENSAMIENTO 2: [paso de razonamiento]
PENSAMIENTO 3: [paso de razonamiento]
"""
        response = self.model.generate_content(prompt)

        # Parsear pensamientos
        thoughts = []
        for line in response.text.split('\n'):
            if line.strip().startswith("PENSAMIENTO"):
                thought = line.split(":", 1)[1].strip() if ":" in line else ""
                if thought:
                    thoughts.append(thought)

        # Si no se generaron suficientes, rellenar
        while len(thoughts) < num_thoughts:
            thoughts.append(f"Continuar análisis del problema desde otra perspectiva")

        return thoughts[:num_thoughts]

    def _evaluate_state(self, problem: str, state: str) -> Tuple[float, bool]:
        """
        Evalúa un estado de razonamiento.

        Returns:
            Tupla de (score 0-1, es_solucion_completa)
        """
        prompt = f"""
PROBLEMA: {problem}

RAZONAMIENTO ACTUAL:
{state}

Evalúa este razonamiento:
1. ¿Qué tan prometedor es este camino? (0-10)
2. ¿Tiene errores lógicos obvios? (sí/no)
3. ¿Resuelve completamente el problema? (sí/no)

Responde en formato:
SCORE: [0-10]
ERRORES: [sí/no]
COMPLETO: [sí/no]
"""
        response = self.model.generate_content(prompt)
        text = response.text.lower()

        # Parsear respuesta
        score = 5.0
        is_complete = False

        for line in text.split('\n'):
            if 'score' in line:
                try:
                    score = float(line.split(':')[1].strip().split()[0])
                except (ValueError, IndexError):
                    pass
            if 'completo' in line and 'sí' in line:
                is_complete = True
            if 'errores' in line and 'sí' in line:
                score *= 0.5  # Penalizar errores

        return score / 10, is_complete

    def _is_terminal(self, node: ThoughtNode, problem: str) -> bool:
        """Determina si un nodo es terminal."""
        if node.depth >= self.max_depth:
            return True
        if node.is_solution:
            return True
        return False

    def solve_bfs(self, problem: str) -> ThoughtNode:
        """Resuelve usando Breadth-First Search."""
        root = ThoughtNode(state="Inicio del análisis", depth=0)
        root.score, root.is_solution = self._evaluate_state(problem, root.state)

        queue = [root]
        best_solution = root

        while queue:
            current = queue.pop(0)

            if current.is_solution:
                if current.score > best_solution.score:
                    best_solution = current
                continue

            if self._is_terminal(current, problem):
                continue

            # Generar pensamientos hijos
            thoughts = self._generate_thoughts(
                problem,
                "\n".join(current.get_path()),
                self.branching_factor
            )

            for thought in thoughts:
                new_state = f"{current.state}\n→ {thought}"
                child = ThoughtNode(
                    state=new_state,
                    parent=current,
                    depth=current.depth + 1
                )
                child.score, child.is_solution = self._evaluate_state(
                    problem, "\n".join(child.get_path())
                )

                # Podar si el score es muy bajo
                if child.score >= self.pruning_threshold:
                    current.children.append(child)
                    queue.append(child)

                if child.is_solution and child.score > best_solution.score:
                    best_solution = child

        return best_solution

    def solve_best_first(self, problem: str) -> ThoughtNode:
        """Resuelve usando Best-First Search."""
        root = ThoughtNode(state="Inicio del análisis", depth=0)
        root.score, root.is_solution = self._evaluate_state(problem, root.state)

        # Heap ordenado por score (mayor primero)
        heap = [root]
        best_solution = root
        visited_states = set()

        while heap:
            current = heapq.heappop(heap)

            state_hash = hash(current.state)
            if state_hash in visited_states:
                continue
            visited_states.add(state_hash)

            if current.is_solution:
                return current  # Retornar primera solución encontrada

            if self._is_terminal(current, problem):
                continue

            thoughts = self._generate_thoughts(
                problem,
                "\n".join(current.get_path()),
                self.branching_factor
            )

            for thought in thoughts:
                new_state = f"{current.state}\n→ {thought}"
                child = ThoughtNode(
                    state=new_state,
                    parent=current,
                    depth=current.depth + 1
                )
                child.score, child.is_solution = self._evaluate_state(
                    problem, "\n".join(child.get_path())
                )

                if child.score >= self.pruning_threshold:
                    current.children.append(child)
                    heapq.heappush(heap, child)

        return best_solution

    def solve(self, problem: str) -> Dict:
        """
        Resuelve el problema usando la estrategia configurada.

        Returns:
            Diccionario con solución, camino y metadata
        """
        if self.search_strategy == SearchStrategy.BFS:
            solution_node = self.solve_bfs(problem)
        elif self.search_strategy == SearchStrategy.BEST_FIRST:
            solution_node = self.solve_best_first(problem)
        else:
            solution_node = self.solve_bfs(problem)  # Default

        path = solution_node.get_path()

        return {
            "problem": problem,
            "solution_path": path,
            "final_state": solution_node.state,
            "score": solution_node.score,
            "is_complete": solution_node.is_solution,
            "depth_reached": solution_node.depth,
            "reasoning": "\n\n".join(path)
        }
```

### Uso básico

```python
# Crear instancia de ToT
tot = TreeOfThoughts(
    max_depth=4,
    branching_factor=3,
    search_strategy=SearchStrategy.BEST_FIRST,
    pruning_threshold=0.3
)

# Problema del Game of 24
problem = """
Usando los números 4, 5, 6, 10 y las operaciones +, -, *, /,
forma una expresión que resulte en 24.
Cada número debe usarse exactamente una vez.
"""

result = tot.solve(problem)

print("="*50)
print("PROBLEMA:", problem)
print("="*50)
print("\nCAMINO DE RAZONAMIENTO:")
for i, step in enumerate(result["solution_path"]):
    print(f"\n[Paso {i}] {step}")
print("\n" + "="*50)
print(f"Score final: {result['score']:.2f}")
print(f"Solución completa: {result['is_complete']}")
```

---

## Variantes especializadas

### 1. ToT con evaluación por votación

```python
class ToTWithVotingEvaluation(TreeOfThoughts):
    """
    Variante que usa múltiples evaluaciones y votación
    para determinar el score de un estado.
    """

    def __init__(self, num_evaluations: int = 3, **kwargs):
        super().__init__(**kwargs)
        self.num_evaluations = num_evaluations

    def _evaluate_state(self, problem: str, state: str) -> Tuple[float, bool]:
        """Evalúa con múltiples muestras y vota."""
        scores = []
        completions = []

        for _ in range(self.num_evaluations):
            score, is_complete = super()._evaluate_state(problem, state)
            scores.append(score)
            completions.append(is_complete)

        # Promedio de scores
        avg_score = sum(scores) / len(scores)

        # Votación mayoritaria para completitud
        is_complete = sum(completions) > len(completions) / 2

        return avg_score, is_complete
```

### 2. ToT con backtracking explícito

```python
class ToTWithBacktracking(TreeOfThoughts):
    """
    Variante con backtracking explícito cuando se detectan
    callejones sin salida.
    """

    def __init__(self, backtrack_threshold: float = 0.2, **kwargs):
        super().__init__(**kwargs)
        self.backtrack_threshold = backtrack_threshold

    def solve_with_backtrack(self, problem: str) -> Dict:
        """Resuelve con capacidad de backtracking."""
        root = ThoughtNode(state="Inicio", depth=0)
        root.score, _ = self._evaluate_state(problem, root.state)

        current = root
        path_stack = [root]
        best_solution = None
        backtrack_count = 0

        while current.depth < self.max_depth:
            # Generar pensamientos
            thoughts = self._generate_thoughts(
                problem,
                "\n".join(current.get_path()),
                self.branching_factor
            )

            best_child = None
            best_score = self.backtrack_threshold

            for thought in thoughts:
                new_state = f"{current.state}\n→ {thought}"
                child = ThoughtNode(
                    state=new_state,
                    parent=current,
                    depth=current.depth + 1
                )
                child.score, child.is_solution = self._evaluate_state(
                    problem, "\n".join(child.get_path())
                )

                if child.is_solution:
                    return {
                        "solution_path": child.get_path(),
                        "score": child.score,
                        "backtrack_count": backtrack_count,
                        "is_complete": True
                    }

                if child.score > best_score:
                    best_score = child.score
                    best_child = child

            if best_child is not None:
                # Avanzar al mejor hijo
                current.children.append(best_child)
                path_stack.append(best_child)
                current = best_child
            else:
                # Backtrack: no hay hijos prometedores
                backtrack_count += 1
                if len(path_stack) > 1:
                    path_stack.pop()
                    current = path_stack[-1]
                else:
                    break  # No hay más opciones

        # Retornar mejor solución encontrada
        return {
            "solution_path": current.get_path(),
            "score": current.score,
            "backtrack_count": backtrack_count,
            "is_complete": False
        }
```

### 3. ToT para problemas creativos

```python
class CreativeToT(TreeOfThoughts):
    """
    ToT especializado para tareas creativas como
    escritura, brainstorming, diseño.
    """

    def __init__(self, creativity_boost: float = 0.3, **kwargs):
        super().__init__(**kwargs)
        self.creativity_boost = creativity_boost
        # Aumentar temperatura para creatividad
        self.model = genai.GenerativeModel(
            "gemini-1.5-flash",
            generation_config=genai.GenerationConfig(temperature=0.9)
        )

    def _generate_thoughts(
        self,
        problem: str,
        current_state: str,
        num_thoughts: int
    ) -> List[str]:
        """Genera pensamientos con enfoque creativo."""
        prompt = f"""
DESAFÍO CREATIVO: {problem}

DESARROLLO ACTUAL:
{current_state}

Genera {num_thoughts} direcciones CREATIVAS y DIVERGENTES para continuar.
Busca originalidad, sorpresa y profundidad.
No te limites a lo obvio.

DIRECCIONES CREATIVAS:
"""
        response = self.model.generate_content(prompt)

        thoughts = []
        for line in response.text.split('\n'):
            line = line.strip()
            if line and not line.startswith('#'):
                # Limpiar numeración si existe
                if line[0].isdigit() and '.' in line[:3]:
                    line = line.split('.', 1)[1].strip()
                if line:
                    thoughts.append(line)

        return thoughts[:num_thoughts]

    def _evaluate_state(self, problem: str, state: str) -> Tuple[float, bool]:
        """Evalúa con criterios creativos."""
        prompt = f"""
DESAFÍO: {problem}

DESARROLLO:
{state}

Evalúa creativamente:
1. ORIGINALIDAD (0-10): ¿Es una idea fresca?
2. COHERENCIA (0-10): ¿Tiene sentido interno?
3. IMPACTO (0-10): ¿Es memorable/significativo?
4. POTENCIAL (0-10): ¿Puede desarrollarse más?

¿Está completo? (sí/no)

SCORES:
"""
        response = self.model.generate_content(prompt)
        text = response.text.lower()

        # Extraer scores
        scores = []
        for line in text.split('\n'):
            for keyword in ['originalidad', 'coherencia', 'impacto', 'potencial']:
                if keyword in line:
                    try:
                        num = float(''.join(c for c in line if c.isdigit() or c == '.'))
                        scores.append(num / 10)
                    except ValueError:
                        pass

        avg_score = sum(scores) / len(scores) if scores else 0.5
        is_complete = 'completo' in text and 'sí' in text

        return avg_score, is_complete


# Uso para escritura creativa
creative_tot = CreativeToT(
    max_depth=5,
    branching_factor=4,
    creativity_boost=0.3
)

story_prompt = """
Desarrolla una historia corta (200 palabras) que explore el tema:
"Un robot que descubre que puede soñar"
La historia debe tener un giro inesperado al final.
"""

result = creative_tot.solve(story_prompt)
print("HISTORIA DESARROLLADA:")
print(result["reasoning"])
```

---

## Errores frecuentes

### Error 1: Branching factor muy alto

```python
# ❌ Demasiadas ramas = explosión combinatoria
bad_tot = TreeOfThoughts(
    branching_factor=10,  # Muy alto
    max_depth=5
)
# 10^5 = 100,000 posibles nodos!

# ✓ Branching factor moderado con buena evaluación
good_tot = TreeOfThoughts(
    branching_factor=3,
    max_depth=5,
    pruning_threshold=0.4  # Poda agresiva
)
# 3^5 = 243 nodos máximo, menos con poda
```

### Error 2: Evaluador que no discrimina

```python
# ❌ Evaluador que siempre da scores similares
def bad_evaluator(problem: str, state: str) -> Tuple[float, bool]:
    return 0.5, False  # No discrimina entre estados

# ✓ Evaluador con criterios claros y discriminantes
def good_evaluator(problem: str, state: str) -> Tuple[float, bool]:
    score = 0.5

    # Criterios específicos que suman/restan
    if "error" in state.lower() or "imposible" in state.lower():
        score -= 0.2
    if any(op in state for op in ["=", "por lo tanto", "entonces"]):
        score += 0.15
    if len(state) > 500:  # Razonamiento sustancial
        score += 0.1

    # Verificar completitud con criterios claros
    is_complete = "respuesta final" in state.lower() or "solución:" in state.lower()

    return max(0, min(1, score)), is_complete
```

### Error 3: No manejar estados repetidos

```python
# ❌ Sin detección de ciclos
class BadToT(TreeOfThoughts):
    def solve_bfs(self, problem):
        queue = [root]
        while queue:
            current = queue.pop(0)
            # Puede re-explorar el mismo estado muchas veces

# ✓ Con detección de estados visitados
class GoodToT(TreeOfThoughts):
    def solve_bfs(self, problem):
        queue = [root]
        visited = set()

        while queue:
            current = queue.pop(0)
            state_hash = hash(current.state[:100])  # Hash de estado

            if state_hash in visited:
                continue
            visited.add(state_hash)
            # Continuar procesamiento...
```

---

## Comparación de estrategias

| Estrategia | Completitud | Optimalidad | Memoria | Mejor para |
|------------|-------------|-------------|---------|------------|
| BFS | Sí | Sí (profundidad) | O(b^d) | Soluciones superficiales |
| DFS | Sí* | No | O(bd) | Memoria limitada |
| Best-First | No** | Heurística | O(b^d) | Problemas con buena heurística |
| Iterative Deepening | Sí | Sí | O(bd) | Balance general |

\* Con límite de profundidad
\** Puede quedar atrapado en máximo local

---

## Aplicaciones reales

### Aplicación 1: Planificador de proyectos

```python
class ProjectPlannerToT:
    """
    Usa ToT para generar planes de proyecto explorando
    diferentes secuencias de tareas.
    """

    def __init__(self):
        self.tot = TreeOfThoughts(
            max_depth=6,
            branching_factor=3,
            search_strategy=SearchStrategy.BEST_FIRST
        )

    def plan_project(
        self,
        project_description: str,
        constraints: List[str],
        resources: Dict[str, int]
    ) -> Dict:
        """
        Genera un plan de proyecto óptimo.
        """
        problem = f"""
PROYECTO: {project_description}

RESTRICCIONES:
{chr(10).join(f'- {c}' for c in constraints)}

RECURSOS DISPONIBLES:
{chr(10).join(f'- {k}: {v}' for k, v in resources.items())}

Genera un plan de proyecto detallado que:
1. Divida el proyecto en fases claras
2. Identifique dependencias entre tareas
3. Asigne recursos de manera eficiente
4. Incluya hitos y entregables
5. Considere riesgos y mitigaciones

El plan debe ser realista y ejecutable.
"""
        result = self.tot.solve(problem)

        return {
            "plan": result["reasoning"],
            "phases": self._extract_phases(result["reasoning"]),
            "confidence": result["score"]
        }

    def _extract_phases(self, plan: str) -> List[Dict]:
        """Extrae fases estructuradas del plan."""
        # Implementación simplificada
        phases = []
        current_phase = None

        for line in plan.split('\n'):
            if 'fase' in line.lower() or 'phase' in line.lower():
                if current_phase:
                    phases.append(current_phase)
                current_phase = {"name": line.strip(), "tasks": []}
            elif current_phase and line.strip().startswith('-'):
                current_phase["tasks"].append(line.strip()[1:].strip())

        if current_phase:
            phases.append(current_phase)

        return phases


# Uso
planner = ProjectPlannerToT()

plan = planner.plan_project(
    project_description="Desarrollar una aplicación móvil de delivery de comida",
    constraints=[
        "Presupuesto máximo: $50,000",
        "Tiempo: 4 meses",
        "Equipo: 3 desarrolladores, 1 diseñador"
    ],
    resources={
        "desarrolladores": 3,
        "diseñadores": 1,
        "presupuesto_usd": 50000,
        "meses": 4
    }
)

print("PLAN DE PROYECTO:")
print(plan["plan"])
```

### Aplicación 2: Debugger inteligente

```python
class IntelligentDebugger:
    """
    Usa ToT para explorar diferentes hipótesis de bugs
    y estrategias de debugging.
    """

    def __init__(self):
        self.tot = ToTWithBacktracking(
            max_depth=5,
            branching_factor=3,
            backtrack_threshold=0.25
        )

    def debug(
        self,
        error_description: str,
        code_snippet: str,
        stack_trace: str = ""
    ) -> Dict:
        """
        Analiza un bug explorando múltiples hipótesis.
        """
        problem = f"""
ERROR REPORTADO:
{error_description}

CÓDIGO:
```
{code_snippet}
```

{f'STACK TRACE: {stack_trace}' if stack_trace else ''}

Diagnóstica el problema:
1. Identifica posibles causas
2. Analiza cada hipótesis
3. Propón soluciones específicas
4. Prioriza por probabilidad

Objetivo: Encontrar la causa raíz y la solución más probable.
"""
        result = self.tot.solve_with_backtrack(problem)

        return {
            "diagnosis": result["solution_path"],
            "root_cause": self._extract_root_cause(result),
            "suggested_fix": self._extract_fix(result),
            "confidence": result["score"],
            "hypotheses_explored": result["backtrack_count"] + 1
        }

    def _extract_root_cause(self, result: Dict) -> str:
        """Extrae la causa raíz identificada."""
        for step in reversed(result["solution_path"]):
            if "causa" in step.lower() or "problema" in step.lower():
                return step
        return result["solution_path"][-1] if result["solution_path"] else "No identificada"

    def _extract_fix(self, result: Dict) -> str:
        """Extrae la solución sugerida."""
        for step in reversed(result["solution_path"]):
            if "solución" in step.lower() or "corregir" in step.lower():
                return step
        return "Revisar el diagnóstico completo"


# Uso
debugger = IntelligentDebugger()

result = debugger.debug(
    error_description="La función devuelve None cuando debería devolver una lista",
    code_snippet="""
def get_users(db, filters):
    query = build_query(filters)
    if not query:
        return
    results = db.execute(query)
    return [User(r) for r in results]
""",
    stack_trace="TypeError: 'NoneType' object is not iterable"
)

print("DIAGNÓSTICO:")
for i, step in enumerate(result["diagnosis"]):
    print(f"{i+1}. {step}")
print(f"\nCAUSA RAÍZ: {result['root_cause']}")
print(f"SOLUCIÓN: {result['suggested_fix']}")
```

---

## Resumen del concepto

**En una frase**: Tree of Thoughts explora múltiples caminos de razonamiento en estructura de árbol, evaluando y podando para encontrar soluciones óptimas.

**Componentes clave**:
1. **Generador de pensamientos**: Produce múltiples continuaciones
2. **Evaluador de estados**: Puntúa la promisoriedad de cada estado
3. **Estrategia de búsqueda**: BFS, DFS, o Best-First
4. **Mecanismo de poda**: Elimina ramas no prometedoras

**Cuándo usar ToT**:
- Problemas con múltiples caminos de solución
- Tareas que requieren exploración creativa
- Razonamiento complejo donde CoT simple falla
- Problemas donde backtracking es valioso

**Trade-offs**:
- Mayor precisión pero mucho más costo computacional
- Mejor para problemas difíciles, overkill para simples

**Siguiente paso**: Tema 2.3.1 - Prompts de Planificación y Descomposición.
