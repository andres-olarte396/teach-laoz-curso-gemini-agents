# 6.2.1 Hybrid Search: Dense + Sparse

## Objetivo de Aprendizaje

Al finalizar este subtema, serás capaz de implementar sistemas de búsqueda híbrida que combinan búsqueda semántica (dense) con búsqueda por keywords (sparse) para maximizar la relevancia en sistemas RAG.

## Introducción

La **búsqueda híbrida** combina lo mejor de dos mundos:

- **Dense (Semántica)**: Entiende el significado, captura sinónimos y contexto
- **Sparse (Keywords)**: Encuentra coincidencias exactas, nombres propios, códigos

### Por qué Híbrido es Mejor

```
┌─────────────────────────────────────────────────────────────────┐
│                    LIMITACIONES DE CADA ENFOQUE                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  DENSE (Embeddings) solo:                                        │
│  ────────────────────────                                        │
│  ✓ "automóvil" encuentra "carro", "vehículo"                    │
│  ✗ "Error ABC-123" puede no encontrar exacto                    │
│  ✗ Nombres propios pueden perderse en el embedding              │
│  ✗ Códigos específicos diluidos semánticamente                  │
│                                                                  │
│  SPARSE (BM25/TF-IDF) solo:                                      │
│  ────────────────────────────                                    │
│  ✓ "Error ABC-123" encuentra exactamente                        │
│  ✗ "carro" NO encuentra "automóvil"                             │
│  ✗ Sinónimos y paráfrasis no se capturan                       │
│  ✗ Contexto semántico ignorado                                  │
│                                                                  │
│  HÍBRIDO:                                                        │
│  ────────                                                        │
│  ✓ "automóvil" encuentra "carro" (dense)                        │
│  ✓ "Error ABC-123" encuentra exacto (sparse)                    │
│  ✓ Mejor cobertura de casos de uso                              │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

## Fundamentos de Búsqueda Sparse

### BM25 (Best Matching 25)

BM25 es el algoritmo más usado para búsqueda por keywords. Mejora TF-IDF considerando la longitud del documento.

```python
"""
Implementación de BM25 para búsqueda sparse
"""
import math
from collections import Counter
from typing import List, Dict, Tuple
import re


class BM25:
    """
    Implementación de BM25 para búsqueda por keywords.
    """

    def __init__(
        self,
        k1: float = 1.5,  # Saturación de frecuencia de términos
        b: float = 0.75   # Normalización por longitud de documento
    ):
        self.k1 = k1
        self.b = b
        self.documents: List[str] = []
        self.doc_tokens: List[List[str]] = []
        self.doc_freqs: List[Counter] = []
        self.idf: Dict[str, float] = {}
        self.avgdl: float = 0
        self.N: int = 0

    def _tokenize(self, text: str) -> List[str]:
        """Tokeniza texto en palabras."""
        # Convertir a minúsculas y extraer palabras
        text = text.lower()
        tokens = re.findall(r'\b\w+\b', text)
        return tokens

    def fit(self, documents: List[str]):
        """Indexa los documentos."""
        self.documents = documents
        self.N = len(documents)

        # Tokenizar documentos
        self.doc_tokens = [self._tokenize(doc) for doc in documents]
        self.doc_freqs = [Counter(tokens) for tokens in self.doc_tokens]

        # Calcular longitud promedio
        total_length = sum(len(tokens) for tokens in self.doc_tokens)
        self.avgdl = total_length / self.N if self.N > 0 else 0

        # Calcular IDF para cada término
        df = Counter()  # Document frequency
        for tokens in self.doc_tokens:
            unique_tokens = set(tokens)
            for token in unique_tokens:
                df[token] += 1

        # IDF = log((N - df + 0.5) / (df + 0.5))
        for term, freq in df.items():
            self.idf[term] = math.log(
                (self.N - freq + 0.5) / (freq + 0.5) + 1
            )

    def score(self, query: str, doc_idx: int) -> float:
        """Calcula score BM25 para un documento."""
        query_tokens = self._tokenize(query)
        doc_freq = self.doc_freqs[doc_idx]
        doc_len = len(self.doc_tokens[doc_idx])

        score = 0.0
        for term in query_tokens:
            if term not in self.idf:
                continue

            tf = doc_freq.get(term, 0)
            idf = self.idf[term]

            # BM25 formula
            numerator = tf * (self.k1 + 1)
            denominator = tf + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl)

            score += idf * (numerator / denominator)

        return score

    def search(
        self,
        query: str,
        top_k: int = 5
    ) -> List[Tuple[int, float, str]]:
        """
        Busca documentos relevantes.

        Returns:
            Lista de (índice, score, documento)
        """
        scores = []
        for i in range(self.N):
            score = self.score(query, i)
            if score > 0:
                scores.append((i, score, self.documents[i]))

        # Ordenar por score descendente
        scores.sort(key=lambda x: x[1], reverse=True)

        return scores[:top_k]


# Ejemplo de uso
def demo_bm25():
    bm25 = BM25()

    documents = [
        "Python es un lenguaje de programación versátil",
        "JavaScript domina el desarrollo web frontend",
        "Error ABC-123: Conexión rechazada al servidor",
        "El servidor respondió con código HTTP 500",
        "Python y JavaScript son lenguajes populares"
    ]

    bm25.fit(documents)

    # Búsqueda por keyword exacto
    print("Búsqueda: 'Error ABC-123'")
    results = bm25.search("Error ABC-123")
    for idx, score, doc in results:
        print(f"  [{score:.3f}] {doc}")

    # Búsqueda por términos
    print("\nBúsqueda: 'lenguaje programación'")
    results = bm25.search("lenguaje programación")
    for idx, score, doc in results:
        print(f"  [{score:.3f}] {doc}")


if __name__ == "__main__":
    demo_bm25()
```

## Implementación de Búsqueda Híbrida

### Arquitectura del Sistema Híbrido

```
┌─────────────────────────────────────────────────────────────────┐
│                    HYBRID SEARCH PIPELINE                        │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│                         ┌─────────┐                             │
│                         │  Query  │                             │
│                         └────┬────┘                             │
│                              │                                   │
│              ┌───────────────┼───────────────┐                  │
│              ▼               │               ▼                   │
│     ┌─────────────┐          │      ┌─────────────┐             │
│     │   Dense     │          │      │   Sparse    │             │
│     │  (Gemini)   │          │      │   (BM25)    │             │
│     └──────┬──────┘          │      └──────┬──────┘             │
│            │                 │              │                    │
│            ▼                 │              ▼                    │
│     ┌─────────────┐          │      ┌─────────────┐             │
│     │  Results A  │          │      │  Results B  │             │
│     │  [d1: 0.9]  │          │      │  [d3: 8.5]  │             │
│     │  [d2: 0.85] │          │      │  [d1: 6.2]  │             │
│     │  [d4: 0.7]  │          │      │  [d5: 4.1]  │             │
│     └──────┬──────┘          │      └──────┬──────┘             │
│            │                 │              │                    │
│            └────────┬────────┼──────────────┘                   │
│                     │        │                                   │
│                     ▼        ▼                                   │
│            ┌─────────────────────────┐                          │
│            │   Fusion Algorithm      │                          │
│            │   (RRF / Weighted Sum)  │                          │
│            └───────────┬─────────────┘                          │
│                        │                                         │
│                        ▼                                         │
│               ┌─────────────────┐                               │
│               │ Combined Results│                               │
│               │ [d1: 0.92]      │                               │
│               │ [d3: 0.88]      │                               │
│               │ [d2: 0.75]      │                               │
│               └─────────────────┘                               │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### Implementación Completa

```python
"""
Sistema de Búsqueda Híbrida con Gemini
"""
import google.generativeai as genai
from dataclasses import dataclass
from typing import List, Dict, Any, Optional, Tuple
import numpy as np


@dataclass
class HybridSearchResult:
    """Resultado de búsqueda híbrida."""
    doc_id: str
    document: str
    dense_score: float
    sparse_score: float
    hybrid_score: float
    metadata: Dict[str, Any]


class HybridSearchEngine:
    """
    Motor de búsqueda híbrida que combina:
    - Dense search (embeddings semánticos con Gemini)
    - Sparse search (BM25 para keywords)
    """

    def __init__(
        self,
        api_key: str,
        alpha: float = 0.5  # Peso del dense search (1-alpha = peso sparse)
    ):
        genai.configure(api_key=api_key)
        self.alpha = alpha

        # Componentes
        self.bm25 = BM25()
        self.documents: List[str] = []
        self.doc_ids: List[str] = []
        self.metadatas: List[Dict] = []
        self.embeddings: List[List[float]] = []

    def _get_embedding(self, text: str, task_type: str = "retrieval_document") -> List[float]:
        """Genera embedding con Gemini."""
        result = genai.embed_content(
            model="models/text-embedding-004",
            content=text,
            task_type=task_type
        )
        return result['embedding']

    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """Calcula similitud coseno."""
        v1 = np.array(vec1)
        v2 = np.array(vec2)
        return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))

    def add_documents(
        self,
        documents: List[str],
        doc_ids: List[str] = None,
        metadatas: List[Dict] = None
    ):
        """Indexa documentos para búsqueda híbrida."""
        if doc_ids is None:
            doc_ids = [f"doc_{i}" for i in range(len(documents))]

        if metadatas is None:
            metadatas = [{} for _ in documents]

        # Almacenar documentos
        self.documents.extend(documents)
        self.doc_ids.extend(doc_ids)
        self.metadatas.extend(metadatas)

        # Indexar para BM25 (sparse)
        self.bm25.fit(self.documents)

        # Generar embeddings (dense)
        for doc in documents:
            embedding = self._get_embedding(doc)
            self.embeddings.append(embedding)

        print(f"Indexados {len(documents)} documentos")

    def _dense_search(
        self,
        query: str,
        top_k: int
    ) -> List[Tuple[int, float]]:
        """Búsqueda semántica con embeddings."""
        query_embedding = self._get_embedding(query, task_type="retrieval_query")

        scores = []
        for i, doc_embedding in enumerate(self.embeddings):
            score = self._cosine_similarity(query_embedding, doc_embedding)
            scores.append((i, score))

        scores.sort(key=lambda x: x[1], reverse=True)
        return scores[:top_k]

    def _sparse_search(
        self,
        query: str,
        top_k: int
    ) -> List[Tuple[int, float]]:
        """Búsqueda por keywords con BM25."""
        results = self.bm25.search(query, top_k=top_k)
        return [(idx, score) for idx, score, _ in results]

    def _normalize_scores(
        self,
        scores: List[Tuple[int, float]]
    ) -> Dict[int, float]:
        """Normaliza scores al rango [0, 1]."""
        if not scores:
            return {}

        max_score = max(s for _, s in scores)
        min_score = min(s for _, s in scores)

        if max_score == min_score:
            return {idx: 1.0 for idx, _ in scores}

        return {
            idx: (score - min_score) / (max_score - min_score)
            for idx, score in scores
        }

    def _reciprocal_rank_fusion(
        self,
        dense_results: List[Tuple[int, float]],
        sparse_results: List[Tuple[int, float]],
        k: int = 60
    ) -> List[Tuple[int, float]]:
        """
        Reciprocal Rank Fusion (RRF) para combinar rankings.
        RRF_score = sum(1 / (k + rank))
        """
        rrf_scores = {}

        # Procesar resultados dense
        for rank, (doc_idx, _) in enumerate(dense_results, 1):
            if doc_idx not in rrf_scores:
                rrf_scores[doc_idx] = 0
            rrf_scores[doc_idx] += 1 / (k + rank)

        # Procesar resultados sparse
        for rank, (doc_idx, _) in enumerate(sparse_results, 1):
            if doc_idx not in rrf_scores:
                rrf_scores[doc_idx] = 0
            rrf_scores[doc_idx] += 1 / (k + rank)

        # Ordenar por RRF score
        sorted_results = sorted(
            rrf_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )

        return sorted_results

    def _weighted_fusion(
        self,
        dense_results: List[Tuple[int, float]],
        sparse_results: List[Tuple[int, float]]
    ) -> List[Tuple[int, float]]:
        """
        Fusión ponderada de scores normalizados.
        hybrid_score = alpha * dense_score + (1-alpha) * sparse_score
        """
        # Normalizar scores
        dense_normalized = self._normalize_scores(dense_results)
        sparse_normalized = self._normalize_scores(sparse_results)

        # Combinar todos los documentos encontrados
        all_docs = set(dense_normalized.keys()) | set(sparse_normalized.keys())

        hybrid_scores = []
        for doc_idx in all_docs:
            dense_score = dense_normalized.get(doc_idx, 0)
            sparse_score = sparse_normalized.get(doc_idx, 0)

            hybrid_score = (
                self.alpha * dense_score +
                (1 - self.alpha) * sparse_score
            )
            hybrid_scores.append((doc_idx, hybrid_score))

        hybrid_scores.sort(key=lambda x: x[1], reverse=True)
        return hybrid_scores

    def search(
        self,
        query: str,
        top_k: int = 5,
        fusion_method: str = "weighted"  # "weighted" o "rrf"
    ) -> List[HybridSearchResult]:
        """
        Ejecuta búsqueda híbrida.

        Args:
            query: Texto de búsqueda
            top_k: Número de resultados
            fusion_method: Método de fusión ("weighted" o "rrf")

        Returns:
            Lista de resultados híbridos
        """
        # Obtener más resultados que top_k para la fusión
        search_k = top_k * 2

        # Búsquedas paralelas
        dense_results = self._dense_search(query, search_k)
        sparse_results = self._sparse_search(query, search_k)

        # Guardar scores originales para el resultado
        dense_scores = dict(dense_results)
        sparse_scores = dict(sparse_results)

        # Fusionar resultados
        if fusion_method == "rrf":
            fused = self._reciprocal_rank_fusion(dense_results, sparse_results)
        else:  # weighted
            fused = self._weighted_fusion(dense_results, sparse_results)

        # Construir resultados
        results = []
        for doc_idx, hybrid_score in fused[:top_k]:
            results.append(HybridSearchResult(
                doc_id=self.doc_ids[doc_idx],
                document=self.documents[doc_idx],
                dense_score=dense_scores.get(doc_idx, 0),
                sparse_score=sparse_scores.get(doc_idx, 0),
                hybrid_score=hybrid_score,
                metadata=self.metadatas[doc_idx]
            ))

        return results


# Demostración
def demo_hybrid_search():
    engine = HybridSearchEngine(
        api_key="TU_API_KEY",
        alpha=0.6  # 60% dense, 40% sparse
    )

    # Documentos con mezcla de contenido semántico y técnico
    documents = [
        "El vehículo automotor requiere mantenimiento preventivo cada 10,000 km",
        "Error ERR-5001: Falla de conexión con el servidor de autenticación",
        "Python es un lenguaje de programación ideal para ciencia de datos",
        "El automóvil Toyota Corolla 2024 tiene excelente rendimiento",
        "Código de error HTTP 503: Servicio no disponible temporalmente",
        "JavaScript y TypeScript dominan el desarrollo web moderno",
        "Problema de red: timeout al conectar con API gateway",
        "El carro necesita cambio de aceite cada 5,000 kilómetros"
    ]

    engine.add_documents(documents)

    # Búsquedas de prueba
    queries = [
        # Semántica (sinónimos)
        ("carro mantenimiento", "Busca sinónimos de carro"),

        # Exacta (código de error)
        ("ERR-5001", "Busca código exacto"),

        # Mixta
        ("error conexión servidor", "Busca concepto + términos técnicos")
    ]

    for query, description in queries:
        print(f"\n{'='*60}")
        print(f"Query: '{query}' ({description})")
        print('='*60)

        results = engine.search(query, top_k=3, fusion_method="weighted")

        for r in results:
            print(f"\n[Hybrid: {r.hybrid_score:.3f}]")
            print(f"  Dense: {r.dense_score:.3f} | Sparse: {r.sparse_score:.3f}")
            print(f"  {r.document}")


if __name__ == "__main__":
    demo_hybrid_search()
```

## Ajuste del Parámetro Alpha

```python
"""
Estrategias para ajustar el balance dense/sparse
"""


class AdaptiveHybridSearch(HybridSearchEngine):
    """
    Búsqueda híbrida con alpha adaptativo según el tipo de query.
    """

    def _classify_query(self, query: str) -> str:
        """
        Clasifica el tipo de query para ajustar alpha.

        Returns:
            "technical": Códigos, IDs, errores específicos
            "semantic": Conceptos, descripciones generales
            "mixed": Combinación
        """
        import re

        # Patrones técnicos
        has_code = bool(re.search(r'[A-Z]{2,}-\d+', query))  # ERR-123
        has_version = bool(re.search(r'\d+\.\d+', query))    # 2.0
        has_special = bool(re.search(r'[_\-]{2,}', query))   # __init__

        # Métricas
        word_count = len(query.split())
        avg_word_len = sum(len(w) for w in query.split()) / word_count if word_count else 0

        # Clasificar
        technical_signals = sum([has_code, has_version, has_special])

        if technical_signals >= 2:
            return "technical"
        elif technical_signals == 0 and word_count >= 3 and avg_word_len < 8:
            return "semantic"
        else:
            return "mixed"

    def _get_adaptive_alpha(self, query_type: str) -> float:
        """Retorna alpha según tipo de query."""
        alpha_map = {
            "technical": 0.2,   # Más peso a sparse (keywords exactos)
            "semantic": 0.8,    # Más peso a dense (significado)
            "mixed": 0.5        # Balance
        }
        return alpha_map.get(query_type, 0.5)

    def search_adaptive(
        self,
        query: str,
        top_k: int = 5
    ) -> List[HybridSearchResult]:
        """Búsqueda con alpha adaptativo."""
        query_type = self._classify_query(query)
        original_alpha = self.alpha
        self.alpha = self._get_adaptive_alpha(query_type)

        print(f"Query type: {query_type}, Alpha: {self.alpha}")

        results = self.search(query, top_k)

        self.alpha = original_alpha  # Restaurar
        return results


# Demostración de alpha adaptativo
def demo_adaptive():
    engine = AdaptiveHybridSearch(api_key="TU_API_KEY")

    # ... agregar documentos ...

    queries = [
        "ERR-5001 authentication failure",  # Technical
        "cómo mejorar el rendimiento de mi aplicación",  # Semantic
        "error 500 servidor lento"  # Mixed
    ]

    for query in queries:
        results = engine.search_adaptive(query, top_k=3)
        # ... mostrar resultados ...
```

## Integración con ChromaDB

```python
"""
Búsqueda híbrida con ChromaDB
ChromaDB soporta hybrid search nativo desde v0.4.0
"""
import chromadb
from chromadb.config import Settings
import google.generativeai as genai


class ChromaHybridSearch:
    """
    Búsqueda híbrida usando ChromaDB con embeddings de Gemini.
    """

    def __init__(
        self,
        api_key: str,
        collection_name: str = "hybrid_collection",
        persist_dir: str = "./chroma_hybrid"
    ):
        genai.configure(api_key=api_key)

        self.client = chromadb.PersistentClient(path=persist_dir)

        # Crear colección con embeddings personalizados
        self.collection = self.client.get_or_create_collection(
            name=collection_name,
            metadata={
                "hnsw:space": "cosine"
            }
        )

    def _get_embedding(self, text: str, task_type: str = "retrieval_document") -> List[float]:
        result = genai.embed_content(
            model="models/text-embedding-004",
            content=text,
            task_type=task_type
        )
        return result['embedding']

    def add_documents(
        self,
        documents: List[str],
        ids: List[str] = None,
        metadatas: List[Dict] = None
    ):
        """Agrega documentos con embeddings."""
        if ids is None:
            ids = [f"doc_{i}" for i in range(len(documents))]

        embeddings = [self._get_embedding(doc) for doc in documents]

        self.collection.add(
            documents=documents,
            embeddings=embeddings,
            ids=ids,
            metadatas=metadatas
        )

    def hybrid_search(
        self,
        query: str,
        n_results: int = 5,
        where_document: Dict = None
    ) -> Dict:
        """
        Búsqueda híbrida combinando:
        - Búsqueda vectorial (dense)
        - Filtro por contenido (sparse-like)
        """
        query_embedding = self._get_embedding(query, "retrieval_query")

        # ChromaDB permite filtrar por contenido del documento
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=n_results,
            where_document=where_document,  # Filtro por keywords
            include=["documents", "metadatas", "distances"]
        )

        return {
            "ids": results["ids"][0],
            "documents": results["documents"][0],
            "distances": results["distances"][0],
            "metadatas": results["metadatas"][0]
        }

    def search_with_keyword_boost(
        self,
        query: str,
        keywords: List[str],
        n_results: int = 5,
        boost_factor: float = 0.1
    ) -> List[Dict]:
        """
        Búsqueda vectorial con boost para documentos que contienen keywords.
        """
        query_embedding = self._get_embedding(query, "retrieval_query")

        # Obtener más resultados para re-rankear
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=n_results * 2,
            include=["documents", "metadatas", "distances"]
        )

        # Re-rankear con boost por keywords
        boosted_results = []
        for i, (doc, dist) in enumerate(zip(
            results["documents"][0],
            results["distances"][0]
        )):
            # Contar keywords presentes
            keyword_matches = sum(
                1 for kw in keywords
                if kw.lower() in doc.lower()
            )

            # Aplicar boost (reducir distancia = aumentar relevancia)
            boosted_distance = dist - (keyword_matches * boost_factor)

            boosted_results.append({
                "document": doc,
                "original_distance": dist,
                "boosted_distance": boosted_distance,
                "keyword_matches": keyword_matches,
                "metadata": results["metadatas"][0][i] if results["metadatas"] else {}
            })

        # Ordenar por distancia boosteada
        boosted_results.sort(key=lambda x: x["boosted_distance"])

        return boosted_results[:n_results]


# Ejemplo de uso
def demo_chroma_hybrid():
    engine = ChromaHybridSearch(
        api_key="TU_API_KEY",
        collection_name="support_kb"
    )

    # Documentos de soporte técnico
    docs = [
        "Error ERR-001: Usuario no encontrado en el sistema",
        "Error ERR-002: Contraseña incorrecta, intente nuevamente",
        "Para recuperar contraseña, use el enlace de recuperación",
        "El sistema de autenticación usa tokens JWT",
        "Error ERR-003: Token expirado, debe iniciar sesión nuevamente"
    ]

    engine.add_documents(docs)

    # Búsqueda con keywords específicos
    print("Búsqueda con boost de keywords:")
    results = engine.search_with_keyword_boost(
        query="problema de inicio de sesión",
        keywords=["ERR-001", "ERR-002", "contraseña"],
        n_results=3
    )

    for r in results:
        print(f"\n[Dist: {r['original_distance']:.3f} -> {r['boosted_distance']:.3f}]")
        print(f"  Keywords: {r['keyword_matches']}")
        print(f"  {r['document']}")


if __name__ == "__main__":
    demo_chroma_hybrid()
```

## Evaluación de Búsqueda Híbrida

```python
"""
Métricas para evaluar y ajustar búsqueda híbrida
"""
from typing import List, Dict, Set
import numpy as np


class HybridSearchEvaluator:
    """
    Evaluador de rendimiento de búsqueda híbrida.
    """

    @staticmethod
    def precision_at_k(
        retrieved: List[str],
        relevant: Set[str],
        k: int
    ) -> float:
        """
        Precision@K: proporción de relevantes en top-K.
        """
        retrieved_k = retrieved[:k]
        relevant_retrieved = len([r for r in retrieved_k if r in relevant])
        return relevant_retrieved / k

    @staticmethod
    def recall_at_k(
        retrieved: List[str],
        relevant: Set[str],
        k: int
    ) -> float:
        """
        Recall@K: proporción de relevantes recuperados.
        """
        retrieved_k = set(retrieved[:k])
        relevant_retrieved = len(retrieved_k.intersection(relevant))
        return relevant_retrieved / len(relevant) if relevant else 0

    @staticmethod
    def mrr(
        retrieved: List[str],
        relevant: Set[str]
    ) -> float:
        """
        Mean Reciprocal Rank: 1/posición del primer relevante.
        """
        for i, doc_id in enumerate(retrieved, 1):
            if doc_id in relevant:
                return 1 / i
        return 0

    @staticmethod
    def ndcg_at_k(
        retrieved: List[str],
        relevance_scores: Dict[str, float],
        k: int
    ) -> float:
        """
        Normalized Discounted Cumulative Gain.
        """
        def dcg(scores: List[float]) -> float:
            return sum(
                score / np.log2(i + 2)
                for i, score in enumerate(scores)
            )

        retrieved_k = retrieved[:k]
        actual_scores = [
            relevance_scores.get(doc_id, 0)
            for doc_id in retrieved_k
        ]

        ideal_scores = sorted(relevance_scores.values(), reverse=True)[:k]

        dcg_actual = dcg(actual_scores)
        dcg_ideal = dcg(ideal_scores)

        return dcg_actual / dcg_ideal if dcg_ideal > 0 else 0

    def evaluate_alpha_range(
        self,
        engine: HybridSearchEngine,
        test_queries: List[Dict],
        alpha_values: List[float] = None
    ) -> Dict[float, Dict[str, float]]:
        """
        Evalúa diferentes valores de alpha.

        test_queries: [
            {"query": "...", "relevant_ids": ["id1", "id2"]}
        ]
        """
        if alpha_values is None:
            alpha_values = [0.0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0]

        results = {}
        original_alpha = engine.alpha

        for alpha in alpha_values:
            engine.alpha = alpha
            metrics = {"precision@5": [], "recall@5": [], "mrr": []}

            for test in test_queries:
                search_results = engine.search(test["query"], top_k=5)
                retrieved_ids = [r.doc_id for r in search_results]
                relevant = set(test["relevant_ids"])

                metrics["precision@5"].append(
                    self.precision_at_k(retrieved_ids, relevant, 5)
                )
                metrics["recall@5"].append(
                    self.recall_at_k(retrieved_ids, relevant, 5)
                )
                metrics["mrr"].append(
                    self.mrr(retrieved_ids, relevant)
                )

            results[alpha] = {
                k: np.mean(v) for k, v in metrics.items()
            }

        engine.alpha = original_alpha
        return results


# Ejemplo de evaluación
def demo_evaluation():
    engine = HybridSearchEngine(api_key="TU_API_KEY")

    # Agregar documentos con IDs conocidos
    documents = [
        "Python para ciencia de datos",
        "JavaScript desarrollo web",
        "Error ERR-100 conexión",
        "Machine learning con TensorFlow",
        "Error ERR-200 autenticación"
    ]
    engine.add_documents(
        documents,
        doc_ids=["d1", "d2", "d3", "d4", "d5"]
    )

    # Queries de prueba con ground truth
    test_queries = [
        {
            "query": "lenguajes programación",
            "relevant_ids": ["d1", "d2"]  # Python y JavaScript
        },
        {
            "query": "ERR-100",
            "relevant_ids": ["d3"]  # Solo el documento con ese error
        },
        {
            "query": "inteligencia artificial",
            "relevant_ids": ["d1", "d4"]  # Data science y ML
        }
    ]

    evaluator = HybridSearchEvaluator()
    results = evaluator.evaluate_alpha_range(engine, test_queries)

    print("\nResultados de evaluación por alpha:")
    print("="*50)

    for alpha, metrics in sorted(results.items()):
        print(f"\nAlpha = {alpha}:")
        for metric, value in metrics.items():
            print(f"  {metric}: {value:.3f}")


if __name__ == "__main__":
    demo_evaluation()
```

## Ejercicio Práctico

```python
"""
EJERCICIO: Sistema de FAQ con Búsqueda Híbrida

Construye un sistema de FAQ que maneje tanto preguntas
semánticas como búsquedas de códigos de error específicos.
"""


class HybridFAQSystem:
    """
    Sistema de FAQ con búsqueda híbrida.

    TODO: Implementar las funcionalidades marcadas.
    """

    def __init__(self, api_key: str):
        """
        TODO:
        1. Inicializar motor de búsqueda híbrida
        2. Configurar modelo de generación
        """
        pass

    def add_faqs(self, faqs: List[Dict]):
        """
        Agrega FAQs al sistema.

        faqs = [
            {
                "id": "faq_1",
                "question": "¿Cómo reseteo mi contraseña?",
                "answer": "Vaya a Configuración > Seguridad...",
                "tags": ["cuenta", "contraseña"],
                "error_codes": []
            },
            {
                "id": "faq_2",
                "question": "Error ERR-401: No autorizado",
                "answer": "Este error indica que su sesión expiró...",
                "tags": ["errores", "autenticación"],
                "error_codes": ["ERR-401"]
            }
        ]

        TODO:
        1. Procesar cada FAQ
        2. Crear documento combinando question + answer
        3. Agregar metadata con tags y error_codes
        """
        pass

    def search_faq(
        self,
        query: str,
        top_k: int = 3
    ) -> List[Dict]:
        """
        Busca FAQs relevantes con búsqueda híbrida.

        TODO:
        1. Detectar si query contiene código de error
        2. Ajustar alpha según tipo de query
        3. Ejecutar búsqueda híbrida
        4. Retornar resultados formateados
        """
        pass

    def answer_question(
        self,
        question: str
    ) -> Dict:
        """
        Responde una pregunta usando FAQs como contexto.

        TODO:
        1. Buscar FAQs relevantes
        2. Construir contexto con las mejores respuestas
        3. Generar respuesta con Gemini
        4. Incluir referencias a FAQs usados
        """
        pass


def test_hybrid_faq():
    """Prueba el sistema de FAQ híbrido."""

    faqs = [
        {
            "id": "faq_1",
            "question": "¿Cómo cambio mi contraseña?",
            "answer": "Para cambiar su contraseña: 1) Vaya a Configuración, 2) Seleccione Seguridad, 3) Click en Cambiar Contraseña",
            "tags": ["cuenta", "seguridad"],
            "error_codes": []
        },
        {
            "id": "faq_2",
            "question": "Error ERR-401: Sesión no autorizada",
            "answer": "El error ERR-401 indica que su sesión ha expirado. Solución: Cierre sesión y vuelva a iniciar.",
            "tags": ["errores", "sesión"],
            "error_codes": ["ERR-401"]
        },
        {
            "id": "faq_3",
            "question": "Error ERR-500: Error interno del servidor",
            "answer": "El error ERR-500 indica un problema en nuestros servidores. Espere unos minutos y reintente.",
            "tags": ["errores", "servidor"],
            "error_codes": ["ERR-500"]
        },
        {
            "id": "faq_4",
            "question": "¿Puedo recuperar mi cuenta sin email?",
            "answer": "Sí, puede recuperar su cuenta mediante verificación telefónica. Contacte a soporte.",
            "tags": ["cuenta", "recuperación"],
            "error_codes": []
        }
    ]

    # TODO: Implementar prueba
    # system = HybridFAQSystem(api_key="TU_KEY")
    # system.add_faqs(faqs)
    #
    # # Prueba semántica
    # result = system.search_faq("olvidé mi clave de acceso")
    # print("Semántica:", result)
    #
    # # Prueba código exacto
    # result = system.search_faq("ERR-401")
    # print("Código exacto:", result)
    #
    # # Prueba mixta
    # result = system.search_faq("error 500 qué significa")
    # print("Mixta:", result)


if __name__ == "__main__":
    test_hybrid_faq()
```

## Resumen

| Aspecto | Dense (Embeddings) | Sparse (BM25) | Híbrido |
|---------|-------------------|---------------|---------|
| Sinónimos | Excelente | Malo | Excelente |
| Códigos exactos | Medio | Excelente | Excelente |
| Velocidad | Rápido | Muy rápido | Medio |
| Complejidad | Media | Baja | Alta |

### Checklist de Implementación

- [ ] Implementar componentes dense y sparse por separado
- [ ] Elegir método de fusión (RRF o weighted)
- [ ] Calibrar alpha con datos de evaluación
- [ ] Considerar alpha adaptativo por tipo de query
- [ ] Implementar métricas de evaluación
- [ ] Monitorear distribución de tipos de query

## Siguiente Paso

En el próximo subtema exploraremos **Re-ranking y Filtering**, técnicas para mejorar la relevancia de los resultados después de la búsqueda inicial.
