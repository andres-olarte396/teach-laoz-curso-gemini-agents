# 9.1.3 Calidad de Razonamiento (Chain Quality)

## Objetivo de Aprendizaje

Al finalizar este subtema, serás capaz de evaluar la calidad del razonamiento de un agente, analizando coherencia lógica, corrección de pasos intermedios y solidez de las conclusiones.

## Introducción

La calidad del razonamiento va más allá del resultado final. Un agente puede llegar a una respuesta correcta por caminos incorrectos, o fallar por errores específicos en su cadena de pensamiento. Evaluar la calidad del razonamiento permite identificar debilidades y mejorar sistemáticamente.

```
┌─────────────────────────────────────────────────────────────────┐
│              EVALUACIÓN DE CADENA DE RAZONAMIENTO               │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  INPUT ──► PASO 1 ──► PASO 2 ──► PASO 3 ──► ... ──► OUTPUT     │
│              │          │          │                            │
│              ▼          ▼          ▼                            │
│           ┌─────┐    ┌─────┐    ┌─────┐                        │
│           │EVAL │    │EVAL │    │EVAL │                        │
│           └──┬──┘    └──┬──┘    └──┬──┘                        │
│              │          │          │                            │
│  ┌───────────┴──────────┴──────────┴────────────────┐          │
│  │           MÉTRICAS DE CHAIN QUALITY              │          │
│  │  • Coherencia    • Fundamentación   • Progreso   │          │
│  │  • Relevancia    • Completitud      • Eficiencia │          │
│  └──────────────────────────────────────────────────┘          │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

## Modelo de Cadena de Razonamiento

```python
import google.generativeai as genai
from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Tuple
from enum import Enum
from abc import ABC, abstractmethod
import json

class ReasoningStepType(Enum):
    OBSERVATION = "observation"       # Observación de datos
    HYPOTHESIS = "hypothesis"         # Formulación de hipótesis
    INFERENCE = "inference"           # Inferencia lógica
    CALCULATION = "calculation"       # Cálculo numérico
    RETRIEVAL = "retrieval"          # Recuperación de información
    TOOL_CALL = "tool_call"          # Llamada a herramienta
    VERIFICATION = "verification"    # Verificación de resultado
    CONCLUSION = "conclusion"        # Conclusión final
    REFLECTION = "reflection"        # Reflexión sobre el proceso

@dataclass
class ReasoningStep:
    """Representa un paso en la cadena de razonamiento"""
    step_number: int
    step_type: ReasoningStepType
    content: str
    evidence: List[str] = field(default_factory=list)  # Evidencia que soporta el paso
    dependencies: List[int] = field(default_factory=list)  # Pasos de los que depende
    confidence: float = 1.0  # Confianza del agente en este paso
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class ReasoningChain:
    """Cadena completa de razonamiento"""
    task: str
    steps: List[ReasoningStep]
    final_answer: Any
    total_time: float

    def get_step(self, step_number: int) -> Optional[ReasoningStep]:
        """Obtiene un paso por número"""
        for step in self.steps:
            if step.step_number == step_number:
                return step
        return None

    def get_dependency_graph(self) -> Dict[int, List[int]]:
        """Obtiene grafo de dependencias"""
        return {
            step.step_number: step.dependencies
            for step in self.steps
        }

@dataclass
class StepEvaluation:
    """Evaluación de un paso individual"""
    step_number: int
    is_valid: bool
    coherence_score: float  # 0-1: Coherencia con pasos anteriores
    relevance_score: float  # 0-1: Relevancia para el objetivo
    correctness_score: float  # 0-1: Corrección factual/lógica
    grounding_score: float  # 0-1: Fundamentación en evidencia
    issues: List[str] = field(default_factory=list)
    suggestions: List[str] = field(default_factory=list)

@dataclass
class ChainQualityReport:
    """Reporte de calidad de la cadena completa"""
    task: str
    overall_score: float
    step_evaluations: List[StepEvaluation]
    chain_metrics: Dict[str, float]
    critical_issues: List[str]
    strengths: List[str]
    improvement_suggestions: List[str]
```

## Evaluador de Calidad de Razonamiento

```python
class ChainQualityEvaluator:
    """Evalúa la calidad de cadenas de razonamiento"""

    def __init__(self, model_name: str = "gemini-2.0-flash"):
        self.model = genai.GenerativeModel(model_name)
        self.evaluation_cache: Dict[str, ChainQualityReport] = {}

    async def evaluate_chain(
        self,
        chain: ReasoningChain,
        ground_truth: Optional[Any] = None,
        domain_context: Optional[str] = None
    ) -> ChainQualityReport:
        """
        Evalúa una cadena de razonamiento completa

        Args:
            chain: Cadena a evaluar
            ground_truth: Respuesta correcta si se conoce
            domain_context: Contexto del dominio para evaluación
        """

        # Evaluar cada paso
        step_evaluations = []
        for step in chain.steps:
            previous_steps = [
                s for s in chain.steps
                if s.step_number < step.step_number
            ]

            step_eval = await self._evaluate_step(
                step=step,
                previous_steps=previous_steps,
                task=chain.task,
                domain_context=domain_context
            )
            step_evaluations.append(step_eval)

        # Calcular métricas de cadena
        chain_metrics = self._calculate_chain_metrics(
            chain=chain,
            step_evaluations=step_evaluations
        )

        # Evaluar respuesta final si hay ground truth
        if ground_truth is not None:
            answer_score = await self._evaluate_answer(
                answer=chain.final_answer,
                ground_truth=ground_truth,
                chain=chain
            )
            chain_metrics["answer_correctness"] = answer_score

        # Identificar issues y fortalezas
        critical_issues = self._identify_critical_issues(step_evaluations)
        strengths = self._identify_strengths(step_evaluations, chain_metrics)
        suggestions = self._generate_improvement_suggestions(
            step_evaluations,
            chain_metrics
        )

        # Calcular score general
        overall_score = self._calculate_overall_score(
            step_evaluations,
            chain_metrics
        )

        report = ChainQualityReport(
            task=chain.task,
            overall_score=overall_score,
            step_evaluations=step_evaluations,
            chain_metrics=chain_metrics,
            critical_issues=critical_issues,
            strengths=strengths,
            improvement_suggestions=suggestions
        )

        return report

    async def _evaluate_step(
        self,
        step: ReasoningStep,
        previous_steps: List[ReasoningStep],
        task: str,
        domain_context: Optional[str]
    ) -> StepEvaluation:
        """Evalúa un paso individual"""

        context_summary = "\n".join([
            f"Paso {s.step_number} ({s.step_type.value}): {s.content[:200]}"
            for s in previous_steps[-5:]  # Últimos 5 pasos
        ])

        prompt = f"""Evalúa el siguiente paso de razonamiento de un agente.

TAREA ORIGINAL: {task}

{f"CONTEXTO DEL DOMINIO: {domain_context}" if domain_context else ""}

PASOS ANTERIORES:
{context_summary if context_summary else "(Este es el primer paso)"}

PASO A EVALUAR:
- Número: {step.step_number}
- Tipo: {step.step_type.value}
- Contenido: {step.content}
- Evidencia citada: {step.evidence if step.evidence else "Ninguna"}
- Dependencias: Pasos {step.dependencies if step.dependencies else "Ninguna"}

Evalúa este paso según los siguientes criterios (0.0 a 1.0):

1. COHERENCIA: ¿El paso sigue lógicamente de los anteriores?
2. RELEVANCIA: ¿El paso contribuye al objetivo de la tarea?
3. CORRECTITUD: ¿El contenido es factual y lógicamente correcto?
4. FUNDAMENTACIÓN: ¿El paso está bien fundamentado en evidencia?

Responde en JSON:
{{
    "coherence_score": <float>,
    "relevance_score": <float>,
    "correctness_score": <float>,
    "grounding_score": <float>,
    "is_valid": <bool>,
    "issues": ["<problema 1>", ...],
    "suggestions": ["<sugerencia 1>", ...]
}}"""

        response = self.model.generate_content(prompt)

        try:
            eval_data = json.loads(response.text)
            return StepEvaluation(
                step_number=step.step_number,
                is_valid=eval_data.get("is_valid", True),
                coherence_score=eval_data.get("coherence_score", 0.5),
                relevance_score=eval_data.get("relevance_score", 0.5),
                correctness_score=eval_data.get("correctness_score", 0.5),
                grounding_score=eval_data.get("grounding_score", 0.5),
                issues=eval_data.get("issues", []),
                suggestions=eval_data.get("suggestions", [])
            )
        except json.JSONDecodeError:
            return StepEvaluation(
                step_number=step.step_number,
                is_valid=True,
                coherence_score=0.5,
                relevance_score=0.5,
                correctness_score=0.5,
                grounding_score=0.5,
                issues=["Error parsing evaluation"],
                suggestions=[]
            )

    def _calculate_chain_metrics(
        self,
        chain: ReasoningChain,
        step_evaluations: List[StepEvaluation]
    ) -> Dict[str, float]:
        """Calcula métricas agregadas de la cadena"""

        if not step_evaluations:
            return {}

        # Promedios de scores
        avg_coherence = sum(e.coherence_score for e in step_evaluations) / len(step_evaluations)
        avg_relevance = sum(e.relevance_score for e in step_evaluations) / len(step_evaluations)
        avg_correctness = sum(e.correctness_score for e in step_evaluations) / len(step_evaluations)
        avg_grounding = sum(e.grounding_score for e in step_evaluations) / len(step_evaluations)

        # Métricas de estructura
        step_count = len(chain.steps)
        valid_steps = sum(1 for e in step_evaluations if e.is_valid)

        # Diversidad de tipos de pasos
        step_types = set(s.step_type for s in chain.steps)
        type_diversity = len(step_types) / len(ReasoningStepType)

        # Profundidad de dependencias
        max_depth = self._calculate_dependency_depth(chain)

        # Eficiencia (resultado vs pasos)
        efficiency = 1.0 / (1 + step_count * 0.1)  # Penaliza cadenas muy largas

        # Progresión de confianza
        confidences = [s.confidence for s in chain.steps]
        confidence_trend = self._calculate_trend(confidences)

        return {
            "avg_coherence": avg_coherence,
            "avg_relevance": avg_relevance,
            "avg_correctness": avg_correctness,
            "avg_grounding": avg_grounding,
            "validity_rate": valid_steps / step_count,
            "step_count": step_count,
            "type_diversity": type_diversity,
            "dependency_depth": max_depth,
            "efficiency": efficiency,
            "confidence_trend": confidence_trend,
            "has_verification": any(
                s.step_type == ReasoningStepType.VERIFICATION
                for s in chain.steps
            ),
            "has_reflection": any(
                s.step_type == ReasoningStepType.REFLECTION
                for s in chain.steps
            )
        }

    def _calculate_dependency_depth(self, chain: ReasoningChain) -> int:
        """Calcula la profundidad máxima del grafo de dependencias"""

        depths = {step.step_number: 0 for step in chain.steps}

        for step in chain.steps:
            if step.dependencies:
                max_dep_depth = max(
                    depths.get(d, 0) for d in step.dependencies
                )
                depths[step.step_number] = max_dep_depth + 1

        return max(depths.values()) if depths else 0

    def _calculate_trend(self, values: List[float]) -> float:
        """Calcula tendencia de una serie (positiva = mejorando)"""
        if len(values) < 2:
            return 0.0

        n = len(values)
        x_mean = (n - 1) / 2
        y_mean = sum(values) / n

        numerator = sum((i - x_mean) * (v - y_mean) for i, v in enumerate(values))
        denominator = sum((i - x_mean) ** 2 for i in range(n))

        if denominator == 0:
            return 0.0

        return numerator / denominator

    async def _evaluate_answer(
        self,
        answer: Any,
        ground_truth: Any,
        chain: ReasoningChain
    ) -> float:
        """Evalúa si la respuesta final es correcta"""

        prompt = f"""Compara la respuesta del agente con la respuesta correcta.

TAREA: {chain.task}

RESPUESTA DEL AGENTE:
{json.dumps(answer, default=str)[:1000]}

RESPUESTA CORRECTA:
{json.dumps(ground_truth, default=str)[:1000]}

¿Qué tan correcta es la respuesta del agente?
Considera: exactitud, completitud, y formato.

Responde SOLO con un número entre 0.0 y 1.0"""

        response = self.model.generate_content(prompt)

        try:
            return float(response.text.strip())
        except ValueError:
            return 0.5

    def _identify_critical_issues(
        self,
        evaluations: List[StepEvaluation]
    ) -> List[str]:
        """Identifica problemas críticos en la cadena"""

        issues = []

        # Pasos inválidos
        invalid_steps = [e for e in evaluations if not e.is_valid]
        if invalid_steps:
            issues.append(
                f"Pasos inválidos: {[e.step_number for e in invalid_steps]}"
            )

        # Pasos con correctitud muy baja
        incorrect_steps = [e for e in evaluations if e.correctness_score < 0.3]
        if incorrect_steps:
            issues.append(
                f"Pasos con errores graves: {[e.step_number for e in incorrect_steps]}"
            )

        # Falta de coherencia
        incoherent = [e for e in evaluations if e.coherence_score < 0.4]
        if len(incoherent) > len(evaluations) * 0.3:
            issues.append("Falta de coherencia general en el razonamiento")

        # Pasos irrelevantes
        irrelevant = [e for e in evaluations if e.relevance_score < 0.3]
        if irrelevant:
            issues.append(
                f"Pasos irrelevantes: {[e.step_number for e in irrelevant]}"
            )

        # Agregar issues específicos de cada paso
        for e in evaluations:
            for issue in e.issues[:2]:  # Limitar a 2 por paso
                if "crítico" in issue.lower() or "error" in issue.lower():
                    issues.append(f"Paso {e.step_number}: {issue}")

        return issues[:10]  # Limitar total

    def _identify_strengths(
        self,
        evaluations: List[StepEvaluation],
        metrics: Dict[str, float]
    ) -> List[str]:
        """Identifica fortalezas del razonamiento"""

        strengths = []

        if metrics.get("avg_coherence", 0) > 0.8:
            strengths.append("Excelente coherencia lógica")

        if metrics.get("avg_correctness", 0) > 0.85:
            strengths.append("Alta precisión en los pasos")

        if metrics.get("has_verification"):
            strengths.append("Incluye verificación de resultados")

        if metrics.get("has_reflection"):
            strengths.append("Demuestra meta-cognición")

        if metrics.get("avg_grounding", 0) > 0.8:
            strengths.append("Bien fundamentado en evidencia")

        if metrics.get("validity_rate", 0) == 1.0:
            strengths.append("Todos los pasos son válidos")

        if metrics.get("type_diversity", 0) > 0.5:
            strengths.append("Usa variedad de tipos de razonamiento")

        return strengths

    def _generate_improvement_suggestions(
        self,
        evaluations: List[StepEvaluation],
        metrics: Dict[str, float]
    ) -> List[str]:
        """Genera sugerencias de mejora"""

        suggestions = []

        if metrics.get("avg_grounding", 1) < 0.6:
            suggestions.append(
                "Fortalecer la fundamentación citando más evidencia"
            )

        if not metrics.get("has_verification"):
            suggestions.append(
                "Añadir paso de verificación antes de la conclusión"
            )

        if metrics.get("efficiency", 1) < 0.5:
            suggestions.append(
                "Reducir pasos redundantes para mayor eficiencia"
            )

        if metrics.get("avg_coherence", 1) < 0.7:
            suggestions.append(
                "Mejorar transiciones lógicas entre pasos"
            )

        # Agregar sugerencias específicas de pasos
        for e in evaluations:
            for sug in e.suggestions[:1]:
                suggestions.append(f"Paso {e.step_number}: {sug}")

        return suggestions[:8]

    def _calculate_overall_score(
        self,
        evaluations: List[StepEvaluation],
        metrics: Dict[str, float]
    ) -> float:
        """Calcula score general ponderado"""

        # Pesos para cada componente
        weights = {
            "avg_coherence": 0.2,
            "avg_relevance": 0.15,
            "avg_correctness": 0.25,
            "avg_grounding": 0.15,
            "validity_rate": 0.15,
            "efficiency": 0.1
        }

        score = 0.0
        total_weight = 0.0

        for metric, weight in weights.items():
            if metric in metrics:
                score += metrics[metric] * weight
                total_weight += weight

        # Bonus por verificación y reflexión
        if metrics.get("has_verification"):
            score += 0.05
        if metrics.get("has_reflection"):
            score += 0.03

        # Penalización por respuesta incorrecta
        if "answer_correctness" in metrics:
            answer_weight = 0.3
            score = score * (1 - answer_weight) + metrics["answer_correctness"] * answer_weight

        return min(1.0, score)
```

## Analizador de Patrones de Razonamiento

```python
class ReasoningPatternAnalyzer:
    """Analiza patrones comunes en el razonamiento"""

    def __init__(self):
        self.pattern_templates = self._define_patterns()

    def _define_patterns(self) -> Dict[str, List[ReasoningStepType]]:
        """Define patrones de razonamiento conocidos"""
        return {
            "basic_deduction": [
                ReasoningStepType.OBSERVATION,
                ReasoningStepType.INFERENCE,
                ReasoningStepType.CONCLUSION
            ],
            "hypothesis_testing": [
                ReasoningStepType.OBSERVATION,
                ReasoningStepType.HYPOTHESIS,
                ReasoningStepType.VERIFICATION,
                ReasoningStepType.CONCLUSION
            ],
            "iterative_refinement": [
                ReasoningStepType.HYPOTHESIS,
                ReasoningStepType.VERIFICATION,
                ReasoningStepType.REFLECTION,
                ReasoningStepType.HYPOTHESIS,
                ReasoningStepType.CONCLUSION
            ],
            "evidence_based": [
                ReasoningStepType.RETRIEVAL,
                ReasoningStepType.OBSERVATION,
                ReasoningStepType.INFERENCE,
                ReasoningStepType.VERIFICATION,
                ReasoningStepType.CONCLUSION
            ],
            "tool_assisted": [
                ReasoningStepType.OBSERVATION,
                ReasoningStepType.TOOL_CALL,
                ReasoningStepType.OBSERVATION,
                ReasoningStepType.CONCLUSION
            ]
        }

    def identify_pattern(
        self,
        chain: ReasoningChain
    ) -> Tuple[str, float]:
        """
        Identifica el patrón de razonamiento más similar

        Returns:
            Tuple de (nombre_patrón, score_similitud)
        """
        chain_types = [s.step_type for s in chain.steps]

        best_match = None
        best_score = 0.0

        for pattern_name, pattern_types in self.pattern_templates.items():
            score = self._pattern_similarity(chain_types, pattern_types)
            if score > best_score:
                best_score = score
                best_match = pattern_name

        return best_match or "unknown", best_score

    def _pattern_similarity(
        self,
        chain_types: List[ReasoningStepType],
        pattern_types: List[ReasoningStepType]
    ) -> float:
        """Calcula similitud entre secuencias de tipos"""

        if not chain_types or not pattern_types:
            return 0.0

        # Usar Longest Common Subsequence
        m, n = len(chain_types), len(pattern_types)
        dp = [[0] * (n + 1) for _ in range(m + 1)]

        for i in range(1, m + 1):
            for j in range(1, n + 1):
                if chain_types[i-1] == pattern_types[j-1]:
                    dp[i][j] = dp[i-1][j-1] + 1
                else:
                    dp[i][j] = max(dp[i-1][j], dp[i][j-1])

        lcs_length = dp[m][n]

        # Normalizar por longitud promedio
        return 2 * lcs_length / (m + n)

    def analyze_step_distribution(
        self,
        chains: List[ReasoningChain]
    ) -> Dict[str, Any]:
        """Analiza distribución de tipos de pasos"""

        from collections import Counter

        all_types = []
        for chain in chains:
            all_types.extend([s.step_type.value for s in chain.steps])

        type_counts = Counter(all_types)
        total = len(all_types)

        return {
            "type_distribution": {
                t: count / total for t, count in type_counts.items()
            },
            "most_common": type_counts.most_common(3),
            "least_common": type_counts.most_common()[-3:] if len(type_counts) >= 3 else [],
            "total_steps": total,
            "unique_types": len(type_counts)
        }

    def detect_antipatterns(
        self,
        chain: ReasoningChain
    ) -> List[Dict[str, Any]]:
        """Detecta anti-patrones en el razonamiento"""

        antipatterns = []

        # Anti-patrón: Conclusión sin verificación
        has_verification = any(
            s.step_type == ReasoningStepType.VERIFICATION
            for s in chain.steps
        )
        if not has_verification and len(chain.steps) > 3:
            antipatterns.append({
                "name": "unverified_conclusion",
                "description": "Conclusión sin paso de verificación",
                "severity": "medium",
                "suggestion": "Agregar verificación antes de concluir"
            })

        # Anti-patrón: Inferencias consecutivas sin evidencia
        consecutive_inferences = 0
        for step in chain.steps:
            if step.step_type == ReasoningStepType.INFERENCE:
                consecutive_inferences += 1
                if consecutive_inferences >= 3:
                    antipatterns.append({
                        "name": "chained_unsupported_inferences",
                        "description": f"Múltiples inferencias sin evidencia (paso {step.step_number})",
                        "severity": "high",
                        "suggestion": "Intercalar observaciones o retrieval"
                    })
            else:
                consecutive_inferences = 0

        # Anti-patrón: Loops de dependencia
        dependency_graph = chain.get_dependency_graph()
        if self._has_cycles(dependency_graph):
            antipatterns.append({
                "name": "circular_dependencies",
                "description": "Dependencias circulares en pasos",
                "severity": "critical",
                "suggestion": "Reestructurar flujo de razonamiento"
            })

        # Anti-patrón: Salto directo a conclusión
        if len(chain.steps) <= 2:
            antipatterns.append({
                "name": "premature_conclusion",
                "description": "Conclusión prematura sin análisis suficiente",
                "severity": "medium",
                "suggestion": "Desarrollar razonamiento intermedio"
            })

        # Anti-patrón: Exceso de reflexión sin acción
        reflection_count = sum(
            1 for s in chain.steps
            if s.step_type == ReasoningStepType.REFLECTION
        )
        if reflection_count > len(chain.steps) * 0.4:
            antipatterns.append({
                "name": "over_reflection",
                "description": "Exceso de reflexión sin progreso",
                "severity": "low",
                "suggestion": "Balancear reflexión con acción"
            })

        return antipatterns

    def _has_cycles(self, graph: Dict[int, List[int]]) -> bool:
        """Detecta ciclos en grafo de dependencias"""

        visited = set()
        rec_stack = set()

        def dfs(node):
            visited.add(node)
            rec_stack.add(node)

            for neighbor in graph.get(node, []):
                if neighbor not in visited:
                    if dfs(neighbor):
                        return True
                elif neighbor in rec_stack:
                    return True

            rec_stack.remove(node)
            return False

        for node in graph:
            if node not in visited:
                if dfs(node):
                    return True

        return False
```

## Ejemplo Práctico

```python
import asyncio

async def main():
    genai.configure(api_key="YOUR_API_KEY")

    # Crear una cadena de razonamiento de ejemplo
    chain = ReasoningChain(
        task="Determinar si un número N es primo",
        steps=[
            ReasoningStep(
                step_number=1,
                step_type=ReasoningStepType.OBSERVATION,
                content="El número a evaluar es N=17",
                evidence=["Input del usuario"],
                dependencies=[],
                confidence=1.0
            ),
            ReasoningStep(
                step_number=2,
                step_type=ReasoningStepType.HYPOTHESIS,
                content="17 podría ser primo si no tiene divisores entre 2 y sqrt(17)≈4.1",
                evidence=["Definición de número primo"],
                dependencies=[1],
                confidence=0.9
            ),
            ReasoningStep(
                step_number=3,
                step_type=ReasoningStepType.CALCULATION,
                content="Verificar divisibilidad: 17/2=8.5, 17/3=5.67, 17/4=4.25. Ninguno es entero.",
                evidence=["Cálculos aritméticos"],
                dependencies=[2],
                confidence=0.95
            ),
            ReasoningStep(
                step_number=4,
                step_type=ReasoningStepType.VERIFICATION,
                content="Confirmado: 17 no es divisible por 2, 3, ni 4",
                evidence=["Resultados del paso 3"],
                dependencies=[3],
                confidence=0.98
            ),
            ReasoningStep(
                step_number=5,
                step_type=ReasoningStepType.CONCLUSION,
                content="17 es un número primo",
                evidence=["Verificación del paso 4", "Definición de primo"],
                dependencies=[4],
                confidence=0.99
            )
        ],
        final_answer=True,
        total_time=2.5
    )

    # Evaluar la cadena
    evaluator = ChainQualityEvaluator()
    report = await evaluator.evaluate_chain(
        chain=chain,
        ground_truth=True,  # 17 sí es primo
        domain_context="Matemáticas: Teoría de números"
    )

    # Imprimir resultados
    print("=" * 60)
    print("EVALUACIÓN DE CALIDAD DE RAZONAMIENTO")
    print("=" * 60)
    print(f"\nTarea: {report.task}")
    print(f"Score General: {report.overall_score:.2f}")

    print("\n--- Métricas de Cadena ---")
    for metric, value in report.chain_metrics.items():
        if isinstance(value, float):
            print(f"  {metric}: {value:.2f}")
        else:
            print(f"  {metric}: {value}")

    print("\n--- Evaluación por Paso ---")
    for step_eval in report.step_evaluations:
        print(f"\n  Paso {step_eval.step_number}:")
        print(f"    Válido: {step_eval.is_valid}")
        print(f"    Coherencia: {step_eval.coherence_score:.2f}")
        print(f"    Relevancia: {step_eval.relevance_score:.2f}")
        print(f"    Correctitud: {step_eval.correctness_score:.2f}")
        if step_eval.issues:
            print(f"    Issues: {step_eval.issues}")

    if report.critical_issues:
        print("\n--- Problemas Críticos ---")
        for issue in report.critical_issues:
            print(f"  • {issue}")

    if report.strengths:
        print("\n--- Fortalezas ---")
        for strength in report.strengths:
            print(f"  ✓ {strength}")

    if report.improvement_suggestions:
        print("\n--- Sugerencias ---")
        for sug in report.improvement_suggestions:
            print(f"  → {sug}")

    # Análisis de patrones
    analyzer = ReasoningPatternAnalyzer()
    pattern, similarity = analyzer.identify_pattern(chain)
    print(f"\n--- Patrón Identificado ---")
    print(f"  Patrón: {pattern} (similitud: {similarity:.2f})")

    antipatterns = analyzer.detect_antipatterns(chain)
    if antipatterns:
        print("\n--- Anti-patrones Detectados ---")
        for ap in antipatterns:
            print(f"  • {ap['name']} ({ap['severity']}): {ap['description']}")

if __name__ == "__main__":
    asyncio.run(main())
```

## Ejercicios Prácticos

### Ejercicio 1: Extractor de Cadenas
Implementa un sistema que extraiga automáticamente la cadena de razonamiento del output de un agente:
- Parsear texto libre para identificar pasos
- Clasificar cada paso por tipo
- Reconstruir dependencias

### Ejercicio 2: Comparador de Cadenas
Crea un sistema para comparar calidad entre:
- Diferentes agentes en la misma tarea
- Mismo agente con diferentes prompts
- Diferentes modelos base

### Ejercicio 3: Entrenador de Razonamiento
Diseña un sistema que use las evaluaciones para:
- Identificar debilidades sistemáticas
- Generar ejemplos de entrenamiento
- Sugerir modificaciones al prompt del agente

## Resumen

| Concepto | Descripción |
|----------|-------------|
| Reasoning Chain | Secuencia de pasos de pensamiento del agente |
| Step Types | Categorías: observación, inferencia, verificación, etc. |
| Coherence | Continuidad lógica entre pasos |
| Grounding | Fundamentación en evidencia |
| Chain Metrics | Métricas agregadas de toda la cadena |
| Anti-patterns | Patrones problemáticos de razonamiento |

---

**Siguiente:** [9.2.1 Unit Testing de Tools y Functions](../tema_9.2/9.2.1-unit-testing-tools.md)
