# 9.2.1 Unit Testing de Tools y Functions

## Objetivo de Aprendizaje

Al finalizar este subtema, serás capaz de diseñar e implementar unit tests robustos para las herramientas y funciones que usan los agentes, asegurando que cada componente funcione correctamente de forma aislada.

## Introducción

El testing de tools es fundamental porque son el punto de contacto entre el agente y el mundo real. Una tool mal testeada puede causar fallos silenciosos, resultados incorrectos, o problemas de seguridad.

```
┌─────────────────────────────────────────────────────────────────┐
│                    PIRÁMIDE DE TESTING                          │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│                        /\                                       │
│                       /  \                                      │
│                      /E2E \     ← Tests de flujo completo      │
│                     /──────\                                    │
│                    /        \                                   │
│                   /Integration\  ← Tests de integración        │
│                  /──────────────\                               │
│                 /                \                              │
│                /   UNIT TESTS     \  ← Tests de tools          │
│               /____________________\                            │
│                                                                 │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │  UNIT TESTS DE TOOLS CUBREN:                            │   │
│  │  • Validación de inputs    • Manejo de errores          │   │
│  │  • Transformación de datos • Casos edge                 │   │
│  │  • Contratos de API        • Mocking de dependencias    │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

## Estructura de Tools Testeable

### Diseño de Tools para Testabilidad

```python
import google.generativeai as genai
from dataclasses import dataclass
from typing import Dict, Any, Optional, List, Callable, TypeVar, Generic
from abc import ABC, abstractmethod
from enum import Enum
import json

# Tipos genéricos para tools
T = TypeVar('T')
R = TypeVar('R')

class ToolError(Exception):
    """Error base para tools"""
    def __init__(self, message: str, error_code: str, details: Optional[Dict] = None):
        super().__init__(message)
        self.error_code = error_code
        self.details = details or {}

class ValidationError(ToolError):
    """Error de validación de inputs"""
    pass

class ExecutionError(ToolError):
    """Error durante ejecución"""
    pass

@dataclass
class ToolInput(Generic[T]):
    """Input tipado para tools"""
    data: T
    context: Dict[str, Any] = None

    def validate(self) -> bool:
        return self.data is not None

@dataclass
class ToolOutput(Generic[R]):
    """Output tipado de tools"""
    success: bool
    result: Optional[R]
    error: Optional[str] = None
    metadata: Dict[str, Any] = None

class BaseTool(ABC, Generic[T, R]):
    """Clase base para tools testeables"""

    def __init__(self, name: str, description: str):
        self.name = name
        self.description = description
        self._validators: List[Callable[[T], bool]] = []
        self._transformers: List[Callable[[T], T]] = []

    def add_validator(self, validator: Callable[[T], bool]) -> 'BaseTool':
        """Añade validador de input"""
        self._validators.append(validator)
        return self

    def add_transformer(self, transformer: Callable[[T], T]) -> 'BaseTool':
        """Añade transformador de input"""
        self._transformers.append(transformer)
        return self

    def validate_input(self, input_data: T) -> List[str]:
        """Valida input y retorna lista de errores"""
        errors = []
        for i, validator in enumerate(self._validators):
            try:
                if not validator(input_data):
                    errors.append(f"Validation {i} failed")
            except Exception as e:
                errors.append(f"Validation {i} error: {str(e)}")
        return errors

    def transform_input(self, input_data: T) -> T:
        """Aplica transformaciones al input"""
        result = input_data
        for transformer in self._transformers:
            result = transformer(result)
        return result

    @abstractmethod
    def execute(self, input_data: T) -> R:
        """Ejecuta la tool - debe ser implementado"""
        pass

    def __call__(self, input_data: T) -> ToolOutput[R]:
        """Ejecuta tool con validación y manejo de errores"""
        try:
            # Validar
            errors = self.validate_input(input_data)
            if errors:
                return ToolOutput(
                    success=False,
                    result=None,
                    error=f"Validation errors: {errors}"
                )

            # Transformar
            transformed = self.transform_input(input_data)

            # Ejecutar
            result = self.execute(transformed)

            return ToolOutput(
                success=True,
                result=result,
                metadata={"tool": self.name}
            )

        except ToolError as e:
            return ToolOutput(
                success=False,
                result=None,
                error=f"{e.error_code}: {str(e)}",
                metadata=e.details
            )
        except Exception as e:
            return ToolOutput(
                success=False,
                result=None,
                error=f"UNEXPECTED: {str(e)}"
            )

    def get_schema(self) -> Dict[str, Any]:
        """Retorna schema JSON para Gemini"""
        return {
            "name": self.name,
            "description": self.description,
            "parameters": self._get_parameters_schema()
        }

    @abstractmethod
    def _get_parameters_schema(self) -> Dict[str, Any]:
        """Retorna schema de parámetros"""
        pass


# Ejemplo de tool concreta
@dataclass
class SearchInput:
    query: str
    max_results: int = 10
    filters: Optional[Dict[str, Any]] = None

@dataclass
class SearchResult:
    title: str
    url: str
    snippet: str
    score: float

class SearchTool(BaseTool[SearchInput, List[SearchResult]]):
    """Tool de búsqueda testeable"""

    def __init__(self, search_backend: Callable[[str], List[Dict]]):
        super().__init__(
            name="search",
            description="Busca información en la web"
        )
        self.search_backend = search_backend

        # Configurar validadores
        self.add_validator(lambda x: len(x.query) > 0)
        self.add_validator(lambda x: x.max_results > 0 and x.max_results <= 100)

        # Configurar transformadores
        self.add_transformer(lambda x: SearchInput(
            query=x.query.strip(),
            max_results=x.max_results,
            filters=x.filters
        ))

    def execute(self, input_data: SearchInput) -> List[SearchResult]:
        """Ejecuta búsqueda"""
        raw_results = self.search_backend(input_data.query)

        results = []
        for item in raw_results[:input_data.max_results]:
            results.append(SearchResult(
                title=item.get("title", ""),
                url=item.get("url", ""),
                snippet=item.get("snippet", ""),
                score=item.get("score", 0.0)
            ))

        return results

    def _get_parameters_schema(self) -> Dict[str, Any]:
        return {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "Consulta de búsqueda"
                },
                "max_results": {
                    "type": "integer",
                    "description": "Número máximo de resultados",
                    "default": 10
                }
            },
            "required": ["query"]
        }
```

## Framework de Unit Testing

### Test Suite para Tools

```python
import pytest
from unittest.mock import Mock, patch, MagicMock
from typing import List
import asyncio

class ToolTestCase:
    """Caso de test para una tool"""

    def __init__(
        self,
        name: str,
        input_data: Any,
        expected_success: bool,
        expected_result: Any = None,
        expected_error_contains: str = None
    ):
        self.name = name
        self.input_data = input_data
        self.expected_success = expected_success
        self.expected_result = expected_result
        self.expected_error_contains = expected_error_contains


class ToolTestRunner:
    """Ejecutor de tests para tools"""

    def __init__(self, tool: BaseTool):
        self.tool = tool
        self.results: List[Dict[str, Any]] = []

    def run_test_case(self, test_case: ToolTestCase) -> bool:
        """Ejecuta un caso de test"""
        output = self.tool(test_case.input_data)

        passed = True
        details = {
            "test_name": test_case.name,
            "input": str(test_case.input_data),
            "output": str(output)
        }

        # Verificar éxito/fallo
        if output.success != test_case.expected_success:
            passed = False
            details["failure"] = f"Expected success={test_case.expected_success}, got {output.success}"

        # Verificar resultado esperado
        if test_case.expected_result is not None and output.result != test_case.expected_result:
            passed = False
            details["failure"] = f"Expected result {test_case.expected_result}, got {output.result}"

        # Verificar mensaje de error
        if test_case.expected_error_contains and output.error:
            if test_case.expected_error_contains not in output.error:
                passed = False
                details["failure"] = f"Error message should contain '{test_case.expected_error_contains}'"

        details["passed"] = passed
        self.results.append(details)

        return passed

    def run_all(self, test_cases: List[ToolTestCase]) -> Dict[str, Any]:
        """Ejecuta todos los casos de test"""
        passed = 0
        failed = 0

        for tc in test_cases:
            if self.run_test_case(tc):
                passed += 1
            else:
                failed += 1

        return {
            "total": len(test_cases),
            "passed": passed,
            "failed": failed,
            "success_rate": passed / len(test_cases) if test_cases else 0,
            "details": self.results
        }


# Tests usando pytest
class TestSearchTool:
    """Tests unitarios para SearchTool"""

    @pytest.fixture
    def mock_backend(self):
        """Backend de búsqueda mockeado"""
        def _backend(query: str) -> List[Dict]:
            return [
                {"title": f"Result for {query}", "url": "http://example.com", "snippet": "...", "score": 0.9},
                {"title": "Second result", "url": "http://example2.com", "snippet": "...", "score": 0.8}
            ]
        return _backend

    @pytest.fixture
    def search_tool(self, mock_backend):
        """Tool de búsqueda con backend mockeado"""
        return SearchTool(search_backend=mock_backend)

    # Tests de validación de inputs
    def test_empty_query_fails(self, search_tool):
        """Query vacío debe fallar validación"""
        input_data = SearchInput(query="", max_results=10)
        output = search_tool(input_data)

        assert output.success is False
        assert "Validation" in output.error

    def test_negative_max_results_fails(self, search_tool):
        """max_results negativo debe fallar"""
        input_data = SearchInput(query="test", max_results=-1)
        output = search_tool(input_data)

        assert output.success is False

    def test_excessive_max_results_fails(self, search_tool):
        """max_results > 100 debe fallar"""
        input_data = SearchInput(query="test", max_results=500)
        output = search_tool(input_data)

        assert output.success is False

    # Tests de ejecución exitosa
    def test_valid_search_succeeds(self, search_tool):
        """Búsqueda válida debe retornar resultados"""
        input_data = SearchInput(query="machine learning", max_results=5)
        output = search_tool(input_data)

        assert output.success is True
        assert output.result is not None
        assert len(output.result) <= 5

    def test_query_trimming(self, search_tool):
        """Query con espacios debe ser trimmeado"""
        input_data = SearchInput(query="  test query  ", max_results=10)
        output = search_tool(input_data)

        assert output.success is True

    def test_results_structure(self, search_tool):
        """Resultados deben tener estructura correcta"""
        input_data = SearchInput(query="test", max_results=10)
        output = search_tool(input_data)

        assert output.success is True
        for result in output.result:
            assert hasattr(result, 'title')
            assert hasattr(result, 'url')
            assert hasattr(result, 'snippet')
            assert hasattr(result, 'score')

    # Tests de manejo de errores
    def test_backend_error_handled(self):
        """Error en backend debe ser manejado"""
        def failing_backend(query: str):
            raise Exception("Backend error")

        tool = SearchTool(search_backend=failing_backend)
        input_data = SearchInput(query="test", max_results=10)
        output = tool(input_data)

        assert output.success is False
        assert "error" in output.error.lower()

    # Tests de schema
    def test_schema_validity(self, search_tool):
        """Schema debe ser válido para Gemini"""
        schema = search_tool.get_schema()

        assert "name" in schema
        assert "description" in schema
        assert "parameters" in schema
        assert schema["parameters"]["type"] == "object"
        assert "query" in schema["parameters"]["properties"]
```

## Testing de Function Calling

### Simulador de Function Calling

```python
class FunctionCallSimulator:
    """Simula el ciclo de function calling de Gemini"""

    def __init__(self, tools: List[BaseTool]):
        self.tools = {tool.name: tool for tool in tools}
        self.call_history: List[Dict] = []

    def simulate_call(
        self,
        function_name: str,
        arguments: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Simula una llamada a función como la haría Gemini

        Returns:
            Dict con estructura de respuesta de tool
        """
        if function_name not in self.tools:
            return {
                "error": f"Unknown function: {function_name}",
                "success": False
            }

        tool = self.tools[function_name]

        # Reconstruir input desde argumentos
        # (En producción, usar el schema para esto)
        try:
            # Intentar crear el input apropiado
            if function_name == "search":
                input_data = SearchInput(**arguments)
            else:
                input_data = arguments

            output = tool(input_data)

            call_record = {
                "function": function_name,
                "arguments": arguments,
                "success": output.success,
                "result": output.result if output.success else None,
                "error": output.error
            }
            self.call_history.append(call_record)

            return call_record

        except Exception as e:
            return {
                "function": function_name,
                "arguments": arguments,
                "success": False,
                "error": str(e)
            }

    def verify_call_sequence(
        self,
        expected_calls: List[Dict[str, Any]]
    ) -> bool:
        """Verifica que las llamadas coincidan con lo esperado"""

        if len(self.call_history) != len(expected_calls):
            return False

        for actual, expected in zip(self.call_history, expected_calls):
            if actual["function"] != expected.get("function"):
                return False
            if expected.get("success") is not None:
                if actual["success"] != expected["success"]:
                    return False

        return True

    def reset(self):
        """Reinicia historial"""
        self.call_history = []


class TestFunctionCalling:
    """Tests de integración function calling"""

    @pytest.fixture
    def simulator(self):
        mock_backend = lambda q: [{"title": "Test", "url": "http://test.com", "snippet": "...", "score": 0.9}]
        search_tool = SearchTool(search_backend=mock_backend)
        return FunctionCallSimulator(tools=[search_tool])

    def test_valid_function_call(self, simulator):
        """Llamada válida debe ejecutarse correctamente"""
        result = simulator.simulate_call(
            function_name="search",
            arguments={"query": "test query", "max_results": 5}
        )

        assert result["success"] is True
        assert result["result"] is not None

    def test_invalid_function_name(self, simulator):
        """Función desconocida debe fallar"""
        result = simulator.simulate_call(
            function_name="unknown_function",
            arguments={}
        )

        assert result["success"] is False
        assert "Unknown function" in result["error"]

    def test_missing_required_argument(self, simulator):
        """Argumento requerido faltante debe fallar"""
        result = simulator.simulate_call(
            function_name="search",
            arguments={"max_results": 5}  # Falta 'query'
        )

        assert result["success"] is False

    def test_call_history_tracking(self, simulator):
        """Historial de llamadas debe registrarse"""
        simulator.simulate_call("search", {"query": "first", "max_results": 5})
        simulator.simulate_call("search", {"query": "second", "max_results": 5})

        assert len(simulator.call_history) == 2
        assert simulator.call_history[0]["arguments"]["query"] == "first"
        assert simulator.call_history[1]["arguments"]["query"] == "second"
```

## Mocking de Dependencias Externas

```python
from unittest.mock import AsyncMock, patch
import aiohttp

class ExternalAPITool(BaseTool[Dict, Dict]):
    """Tool que llama a API externa"""

    def __init__(self, api_url: str, api_key: str):
        super().__init__(
            name="external_api",
            description="Llama a API externa"
        )
        self.api_url = api_url
        self.api_key = api_key

    def execute(self, input_data: Dict) -> Dict:
        """Ejecuta llamada a API"""
        import requests

        response = requests.post(
            self.api_url,
            headers={"Authorization": f"Bearer {self.api_key}"},
            json=input_data,
            timeout=30
        )
        response.raise_for_status()
        return response.json()

    def _get_parameters_schema(self) -> Dict:
        return {"type": "object", "properties": {}}


class TestExternalAPITool:
    """Tests con mocking de API externa"""

    @pytest.fixture
    def tool(self):
        return ExternalAPITool(
            api_url="https://api.example.com/endpoint",
            api_key="test-key"
        )

    def test_successful_api_call(self, tool):
        """API call exitoso"""
        mock_response = Mock()
        mock_response.json.return_value = {"result": "success"}
        mock_response.raise_for_status = Mock()

        with patch('requests.post', return_value=mock_response) as mock_post:
            output = tool({"param": "value"})

            assert output.success is True
            assert output.result == {"result": "success"}
            mock_post.assert_called_once()

    def test_api_error_handling(self, tool):
        """Error de API debe ser manejado"""
        with patch('requests.post') as mock_post:
            mock_post.side_effect = Exception("Connection error")

            output = tool({"param": "value"})

            assert output.success is False
            assert "Connection error" in output.error

    def test_api_timeout_handling(self, tool):
        """Timeout debe ser manejado"""
        import requests

        with patch('requests.post') as mock_post:
            mock_post.side_effect = requests.Timeout("Request timed out")

            output = tool({"param": "value"})

            assert output.success is False

    def test_api_auth_header(self, tool):
        """Header de auth debe enviarse correctamente"""
        mock_response = Mock()
        mock_response.json.return_value = {}
        mock_response.raise_for_status = Mock()

        with patch('requests.post', return_value=mock_response) as mock_post:
            tool({"param": "value"})

            call_args = mock_post.call_args
            headers = call_args.kwargs.get('headers', {})
            assert "Authorization" in headers
            assert "Bearer test-key" in headers["Authorization"]
```

## Generador de Tests Automático

```python
class ToolTestGenerator:
    """Genera tests automáticamente basado en schema"""

    def __init__(self, tool: BaseTool):
        self.tool = tool
        self.schema = tool.get_schema()

    def generate_test_cases(self) -> List[ToolTestCase]:
        """Genera casos de test automáticamente"""

        cases = []

        # Test de inputs válidos básicos
        cases.append(self._generate_valid_input_case())

        # Tests de validación por campo
        for field, field_schema in self._get_properties().items():
            cases.extend(self._generate_field_validation_cases(field, field_schema))

        # Tests de campos requeridos
        cases.extend(self._generate_required_field_cases())

        # Tests de edge cases
        cases.extend(self._generate_edge_cases())

        return cases

    def _get_properties(self) -> Dict:
        """Obtiene propiedades del schema"""
        params = self.schema.get("parameters", {})
        return params.get("properties", {})

    def _generate_valid_input_case(self) -> ToolTestCase:
        """Genera caso con input válido"""
        valid_input = {}
        for field, field_schema in self._get_properties().items():
            valid_input[field] = self._generate_valid_value(field_schema)

        return ToolTestCase(
            name="valid_basic_input",
            input_data=valid_input,
            expected_success=True
        )

    def _generate_valid_value(self, field_schema: Dict) -> Any:
        """Genera valor válido para un campo"""
        field_type = field_schema.get("type", "string")

        if field_type == "string":
            return "test_value"
        elif field_type == "integer":
            return 10
        elif field_type == "number":
            return 10.5
        elif field_type == "boolean":
            return True
        elif field_type == "array":
            return []
        elif field_type == "object":
            return {}
        else:
            return None

    def _generate_field_validation_cases(
        self,
        field: str,
        field_schema: Dict
    ) -> List[ToolTestCase]:
        """Genera casos de validación para un campo"""

        cases = []
        field_type = field_schema.get("type", "string")

        # Tipo incorrecto
        if field_type == "string":
            cases.append(ToolTestCase(
                name=f"{field}_wrong_type_number",
                input_data={field: 12345},
                expected_success=False,
                expected_error_contains="type"
            ))

        if field_type == "integer":
            cases.append(ToolTestCase(
                name=f"{field}_wrong_type_string",
                input_data={field: "not a number"},
                expected_success=False
            ))

        # Constraints
        if "minimum" in field_schema:
            cases.append(ToolTestCase(
                name=f"{field}_below_minimum",
                input_data={field: field_schema["minimum"] - 1},
                expected_success=False
            ))

        if "maximum" in field_schema:
            cases.append(ToolTestCase(
                name=f"{field}_above_maximum",
                input_data={field: field_schema["maximum"] + 1},
                expected_success=False
            ))

        return cases

    def _generate_required_field_cases(self) -> List[ToolTestCase]:
        """Genera tests para campos requeridos"""

        cases = []
        params = self.schema.get("parameters", {})
        required = params.get("required", [])

        for field in required:
            # Test sin el campo requerido
            input_data = {}
            for f, fs in self._get_properties().items():
                if f != field:
                    input_data[f] = self._generate_valid_value(fs)

            cases.append(ToolTestCase(
                name=f"missing_required_{field}",
                input_data=input_data,
                expected_success=False,
                expected_error_contains="required"
            ))

        return cases

    def _generate_edge_cases(self) -> List[ToolTestCase]:
        """Genera edge cases comunes"""

        cases = []

        # Input vacío
        cases.append(ToolTestCase(
            name="empty_input",
            input_data={},
            expected_success=False
        ))

        # Input None
        cases.append(ToolTestCase(
            name="none_input",
            input_data=None,
            expected_success=False
        ))

        # Strings vacíos para campos string requeridos
        params = self.schema.get("parameters", {})
        required = params.get("required", [])
        properties = self._get_properties()

        for field in required:
            if properties.get(field, {}).get("type") == "string":
                input_data = {f: self._generate_valid_value(fs) for f, fs in properties.items()}
                input_data[field] = ""

                cases.append(ToolTestCase(
                    name=f"empty_string_{field}",
                    input_data=input_data,
                    expected_success=False
                ))

        return cases


# Uso del generador
def test_generated_cases():
    """Ejecuta tests generados automáticamente"""
    mock_backend = lambda q: []
    tool = SearchTool(search_backend=mock_backend)

    generator = ToolTestGenerator(tool)
    test_cases = generator.generate_test_cases()

    runner = ToolTestRunner(tool)
    results = runner.run_all(test_cases)

    print(f"Tests ejecutados: {results['total']}")
    print(f"Pasados: {results['passed']}")
    print(f"Fallidos: {results['failed']}")

    assert results['success_rate'] > 0.8, "Más del 80% de tests deben pasar"
```

## Ejemplo Práctico Completo

```python
import pytest

# Ejecutar tests
if __name__ == "__main__":
    # Configurar mocks
    mock_search_backend = lambda q: [
        {"title": f"Result: {q}", "url": "http://test.com", "snippet": "Test snippet", "score": 0.95}
    ]

    # Crear tool
    search_tool = SearchTool(search_backend=mock_search_backend)

    # Ejecutar con framework custom
    print("=== Tests con Framework Custom ===\n")

    test_cases = [
        ToolTestCase("valid_search", SearchInput("python", 5), True),
        ToolTestCase("empty_query", SearchInput("", 5), False),
        ToolTestCase("high_max_results", SearchInput("test", 200), False),
        ToolTestCase("zero_max_results", SearchInput("test", 0), False),
    ]

    runner = ToolTestRunner(search_tool)
    results = runner.run_all(test_cases)

    print(f"Total: {results['total']}")
    print(f"Pasados: {results['passed']}")
    print(f"Fallidos: {results['failed']}")
    print(f"Tasa de éxito: {results['success_rate']:.1%}")

    print("\n=== Detalles ===")
    for detail in results['details']:
        status = "✓" if detail['passed'] else "✗"
        print(f"{status} {detail['test_name']}")
        if not detail['passed']:
            print(f"  Fallo: {detail.get('failure', 'Unknown')}")

    # Tests generados automáticamente
    print("\n=== Tests Generados Automáticamente ===\n")

    generator = ToolTestGenerator(search_tool)
    auto_cases = generator.generate_test_cases()

    print(f"Casos generados: {len(auto_cases)}")
    for case in auto_cases:
        print(f"  - {case.name}")

    # Simulador de function calling
    print("\n=== Simulación de Function Calling ===\n")

    simulator = FunctionCallSimulator(tools=[search_tool])

    # Simular llamadas
    result1 = simulator.simulate_call("search", {"query": "AI agents", "max_results": 3})
    print(f"Call 1: success={result1['success']}")

    result2 = simulator.simulate_call("search", {"query": "machine learning", "max_results": 5})
    print(f"Call 2: success={result2['success']}")

    result3 = simulator.simulate_call("unknown", {})
    print(f"Call 3 (unknown): success={result3['success']}, error={result3.get('error')}")

    print(f"\nHistorial: {len(simulator.call_history)} llamadas registradas")
```

## Ejercicios Prácticos

### Ejercicio 1: Tool de Cálculo
Implementa una CalculatorTool con tests para:
- Operaciones básicas (+, -, *, /)
- División por cero
- Overflow numérico
- Inputs inválidos

### Ejercicio 2: Test Coverage Report
Crea un sistema que:
- Mida cobertura de código de tests
- Identifique paths no testeados
- Genere reporte de cobertura

### Ejercicio 3: Property-Based Testing
Implementa tests basados en propiedades:
- Generar inputs aleatorios válidos
- Verificar invariantes del sistema
- Encontrar edge cases automáticamente

## Resumen

| Concepto | Descripción |
|----------|-------------|
| BaseTool | Clase base con validación y manejo de errores |
| ToolTestCase | Caso de test estructurado |
| ToolTestRunner | Ejecutor de tests para tools |
| FunctionCallSimulator | Simula ciclo de function calling |
| Mocking | Aislar dependencias externas |
| Test Generator | Genera tests desde schema |

---

**Siguiente:** [9.2.2 Integration Testing de Flujos](./9.2.2-integration-testing-flujos.md)
