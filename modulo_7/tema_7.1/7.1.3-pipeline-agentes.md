# 7.1.3 Pipeline de Agentes Especializados

## Objetivo de Aprendizaje

Al finalizar este subtema, ser√°s capaz de dise√±ar e implementar pipelines donde agentes especializados procesan informaci√≥n de manera secuencial, cada uno transformando o enriqueciendo el resultado del anterior.

## Introducci√≥n

Un **pipeline de agentes** es una cadena de procesamiento donde la salida de un agente se convierte en la entrada del siguiente. Cada agente est√° especializado en una tarea espec√≠fica, similar a una l√≠nea de ensamblaje.

### Arquitectura de Pipeline

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    PIPELINE DE AGENTES                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                  ‚îÇ
‚îÇ  INPUT                                                           ‚îÇ
‚îÇ    ‚îÇ                                                             ‚îÇ
‚îÇ    ‚ñº                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇ  AGENTE 1   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  AGENTE 2   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  AGENTE 3   ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ (Extractor) ‚îÇ     ‚îÇ (Analizador)‚îÇ     ‚îÇ (Generador) ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ             ‚îÇ     ‚îÇ             ‚îÇ     ‚îÇ             ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ Input: Raw  ‚îÇ     ‚îÇInput: Datos ‚îÇ     ‚îÇInput:An√°lisis‚îÇ       ‚îÇ
‚îÇ  ‚îÇ Output:Datos‚îÇ     ‚îÇOutput:Insight‚îÇ    ‚îÇOutput:Reporte‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îÇ                                                ‚îÇ                 ‚îÇ
‚îÇ                                                ‚ñº                 ‚îÇ
‚îÇ                                             OUTPUT               ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  CARACTER√çSTICAS:                                                ‚îÇ
‚îÇ  ‚Ä¢ Cada agente tiene una responsabilidad √∫nica                  ‚îÇ
‚îÇ  ‚Ä¢ Los datos fluyen en una direcci√≥n                            ‚îÇ
‚îÇ  ‚Ä¢ F√°cil de testear y mantener                                  ‚îÇ
‚îÇ  ‚Ä¢ Escalable horizontalmente                                     ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Implementaci√≥n Base

### Componentes del Pipeline

```python
"""
Framework de Pipeline de Agentes
"""
import google.generativeai as genai
from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Callable
from abc import ABC, abstractmethod
from datetime import datetime
import json


@dataclass
class PipelineContext:
    """Contexto que fluye a trav√©s del pipeline."""
    data: Any
    metadata: Dict = field(default_factory=dict)
    history: List[Dict] = field(default_factory=list)
    errors: List[str] = field(default_factory=list)

    def add_step(self, agent_name: str, input_data: Any, output_data: Any):
        """Registra un paso del pipeline."""
        self.history.append({
            "agent": agent_name,
            "timestamp": datetime.now().isoformat(),
            "input_preview": str(input_data)[:100],
            "output_preview": str(output_data)[:100]
        })

    def set_data(self, data: Any):
        """Actualiza los datos del contexto."""
        self.data = data


class PipelineAgent(ABC):
    """Agente base para pipelines."""

    def __init__(self, name: str, api_key: str = None):
        self.name = name
        if api_key:
            genai.configure(api_key=api_key)
            self.model = genai.GenerativeModel("gemini-2.0-flash")
        else:
            self.model = None

    @abstractmethod
    def process(self, context: PipelineContext) -> PipelineContext:
        """Procesa el contexto y retorna el resultado."""
        pass

    def validate_input(self, context: PipelineContext) -> bool:
        """Valida que el input sea correcto para este agente."""
        return context.data is not None

    def __repr__(self):
        return f"{self.__class__.__name__}('{self.name}')"


class Pipeline:
    """
    Pipeline que encadena m√∫ltiples agentes.
    """

    def __init__(self, name: str = "default"):
        self.name = name
        self.agents: List[PipelineAgent] = []
        self.error_handlers: Dict[str, Callable] = {}

    def add_agent(self, agent: PipelineAgent) -> 'Pipeline':
        """Agrega un agente al pipeline (fluent interface)."""
        self.agents.append(agent)
        return self

    def add_error_handler(
        self,
        agent_name: str,
        handler: Callable
    ) -> 'Pipeline':
        """Agrega un manejador de errores para un agente."""
        self.error_handlers[agent_name] = handler
        return self

    def run(
        self,
        initial_data: Any,
        metadata: Dict = None
    ) -> PipelineContext:
        """Ejecuta el pipeline completo."""
        context = PipelineContext(
            data=initial_data,
            metadata=metadata or {}
        )

        print(f"\nüöÄ Iniciando Pipeline: {self.name}")
        print(f"   Agentes: {len(self.agents)}")

        for i, agent in enumerate(self.agents, 1):
            print(f"\n   [{i}/{len(self.agents)}] {agent.name}...")

            try:
                # Validar input
                if not agent.validate_input(context):
                    raise ValueError(f"Input inv√°lido para {agent.name}")

                # Procesar
                input_data = context.data
                context = agent.process(context)
                context.add_step(agent.name, input_data, context.data)

                print(f"       ‚úì Completado")

            except Exception as e:
                error_msg = f"Error en {agent.name}: {str(e)}"
                context.errors.append(error_msg)
                print(f"       ‚úó Error: {e}")

                # Intentar error handler
                if agent.name in self.error_handlers:
                    try:
                        context = self.error_handlers[agent.name](context, e)
                        print(f"       ‚Üª Recuperado por error handler")
                    except Exception as handler_error:
                        print(f"       ‚úó Error handler fall√≥: {handler_error}")
                        break
                else:
                    break

        print(f"\n‚úì Pipeline completado")
        return context

    def run_parallel_branch(
        self,
        initial_data: Any,
        branches: List[List[PipelineAgent]]
    ) -> List[PipelineContext]:
        """Ejecuta m√∫ltiples branches en paralelo."""
        results = []

        for branch in branches:
            branch_pipeline = Pipeline(f"{self.name}_branch")
            for agent in branch:
                branch_pipeline.add_agent(agent)

            result = branch_pipeline.run(initial_data)
            results.append(result)

        return results
```

### Agentes Especializados

```python
"""
Agentes especializados para pipelines comunes
"""


class TextExtractorAgent(PipelineAgent):
    """Extrae informaci√≥n estructurada de texto."""

    def __init__(self, api_key: str, extraction_schema: Dict):
        super().__init__("TextExtractor", api_key)
        self.schema = extraction_schema

    def process(self, context: PipelineContext) -> PipelineContext:
        text = context.data

        schema_str = json.dumps(self.schema, indent=2)

        prompt = f"""Extrae informaci√≥n del siguiente texto seg√∫n el esquema.

TEXTO:
{text}

ESQUEMA DE EXTRACCI√ìN:
{schema_str}

Responde SOLO con el JSON extra√≠do, sin explicaciones."""

        response = self.model.generate_content(prompt)

        try:
            extracted = json.loads(response.text)
        except:
            # Intentar limpiar el JSON
            text = response.text
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0]
            extracted = json.loads(text)

        context.set_data(extracted)
        return context


class DataEnricherAgent(PipelineAgent):
    """Enriquece datos con informaci√≥n adicional."""

    def __init__(self, api_key: str, enrichment_instructions: str):
        super().__init__("DataEnricher", api_key)
        self.instructions = enrichment_instructions

    def process(self, context: PipelineContext) -> PipelineContext:
        data = context.data

        prompt = f"""Enriquece los siguientes datos seg√∫n las instrucciones.

DATOS ACTUALES:
{json.dumps(data, indent=2, ensure_ascii=False)}

INSTRUCCIONES DE ENRIQUECIMIENTO:
{self.instructions}

Agrega campos adicionales relevantes. Responde con el JSON enriquecido."""

        response = self.model.generate_content(prompt)

        try:
            enriched = json.loads(response.text)
        except:
            text = response.text
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0]
            enriched = json.loads(text)

        context.set_data(enriched)
        return context


class ValidatorAgent(PipelineAgent):
    """Valida datos seg√∫n reglas definidas."""

    def __init__(self, api_key: str, validation_rules: List[str]):
        super().__init__("Validator", api_key)
        self.rules = validation_rules

    def process(self, context: PipelineContext) -> PipelineContext:
        data = context.data
        rules_text = "\n".join([f"- {r}" for r in self.rules])

        prompt = f"""Valida los siguientes datos seg√∫n las reglas.

DATOS:
{json.dumps(data, indent=2, ensure_ascii=False)}

REGLAS DE VALIDACI√ìN:
{rules_text}

Responde en JSON:
{{
    "is_valid": true/false,
    "errors": ["error 1", "error 2"],
    "warnings": ["warning 1"],
    "validated_data": {{datos corregidos si es necesario}}
}}"""

        response = self.model.generate_content(prompt)

        try:
            result = json.loads(response.text)
        except:
            text = response.text
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0]
            result = json.loads(text)

        if not result.get("is_valid"):
            context.errors.extend(result.get("errors", []))

        context.set_data(result.get("validated_data", data))
        context.metadata["validation"] = {
            "is_valid": result.get("is_valid"),
            "errors": result.get("errors", []),
            "warnings": result.get("warnings", [])
        }

        return context


class TransformerAgent(PipelineAgent):
    """Transforma datos de un formato a otro."""

    def __init__(
        self,
        api_key: str,
        target_format: str,
        transformation_rules: str = ""
    ):
        super().__init__("Transformer", api_key)
        self.target_format = target_format
        self.rules = transformation_rules

    def process(self, context: PipelineContext) -> PipelineContext:
        data = context.data

        prompt = f"""Transforma los datos al formato especificado.

DATOS ORIGINALES:
{json.dumps(data, indent=2, ensure_ascii=False)}

FORMATO DESTINO:
{self.target_format}

REGLAS DE TRANSFORMACI√ìN:
{self.rules if self.rules else 'Transformaci√≥n est√°ndar'}

Responde SOLO con los datos transformados en el formato solicitado."""

        response = self.model.generate_content(prompt)

        try:
            transformed = json.loads(response.text)
        except:
            # Si no es JSON, mantener como texto
            transformed = response.text

        context.set_data(transformed)
        return context


class SummarizerAgent(PipelineAgent):
    """Resume y sintetiza informaci√≥n."""

    def __init__(
        self,
        api_key: str,
        summary_type: str = "executive",
        max_length: int = 500
    ):
        super().__init__("Summarizer", api_key)
        self.summary_type = summary_type
        self.max_length = max_length

    def process(self, context: PipelineContext) -> PipelineContext:
        data = context.data

        prompt = f"""Genera un resumen {self.summary_type} de los siguientes datos.

DATOS:
{json.dumps(data, indent=2, ensure_ascii=False) if isinstance(data, dict) else data}

Tipo de resumen: {self.summary_type}
Longitud m√°xima: {self.max_length} caracteres

RESUMEN:"""

        response = self.model.generate_content(prompt)

        context.set_data({
            "original_data": data,
            "summary": response.text,
            "summary_type": self.summary_type
        })

        return context


class ReportGeneratorAgent(PipelineAgent):
    """Genera reportes formateados."""

    def __init__(
        self,
        api_key: str,
        template: str,
        format: str = "markdown"
    ):
        super().__init__("ReportGenerator", api_key)
        self.template = template
        self.format = format

    def process(self, context: PipelineContext) -> PipelineContext:
        data = context.data
        history = context.history

        prompt = f"""Genera un reporte basado en los datos y el template.

DATOS:
{json.dumps(data, indent=2, ensure_ascii=False)}

HISTORIAL DEL PIPELINE:
{json.dumps(history, indent=2)}

TEMPLATE:
{self.template}

FORMATO: {self.format}

REPORTE:"""

        response = self.model.generate_content(prompt)

        context.set_data({
            "report": response.text,
            "format": self.format,
            "generated_at": datetime.now().isoformat()
        })

        return context
```

## Ejemplo: Pipeline de An√°lisis de Documentos

```python
"""
Pipeline completo para an√°lisis de documentos
"""


def create_document_analysis_pipeline(api_key: str) -> Pipeline:
    """Crea un pipeline de an√°lisis de documentos."""

    pipeline = Pipeline("document_analysis")

    # Agente 1: Extractor
    extractor = TextExtractorAgent(
        api_key=api_key,
        extraction_schema={
            "title": "string",
            "author": "string",
            "date": "string",
            "main_topics": ["string"],
            "key_points": ["string"],
            "entities": {
                "people": ["string"],
                "organizations": ["string"],
                "locations": ["string"]
            }
        }
    )

    # Agente 2: Enriquecedor
    enricher = DataEnricherAgent(
        api_key=api_key,
        enrichment_instructions="""
        Para cada entidad identificada:
        - Agrega una breve descripci√≥n si es conocida
        - Clasifica la relevancia (alta/media/baja)
        - Identifica relaciones entre entidades
        """
    )

    # Agente 3: Validador
    validator = ValidatorAgent(
        api_key=api_key,
        validation_rules=[
            "El t√≠tulo debe existir y no estar vac√≠o",
            "Debe haber al menos un tema principal identificado",
            "Las fechas deben estar en formato v√°lido",
            "Los puntos clave deben ser concretos y accionables"
        ]
    )

    # Agente 4: Analizador de Sentimiento
    class SentimentAnalyzerAgent(PipelineAgent):
        def __init__(self, api_key: str):
            super().__init__("SentimentAnalyzer", api_key)

        def process(self, context: PipelineContext) -> PipelineContext:
            data = context.data

            prompt = f"""Analiza el sentimiento y tono del contenido.

DATOS:
{json.dumps(data, indent=2)}

Eval√∫a:
1. Sentimiento general (positivo/negativo/neutral)
2. Tono (formal/informal, t√©cnico/casual)
3. Nivel de confianza del an√°lisis

Responde en JSON."""

            response = self.model.generate_content(prompt)

            try:
                sentiment = json.loads(response.text)
            except:
                sentiment = {"analysis": response.text}

            data["sentiment_analysis"] = sentiment
            context.set_data(data)
            return context

    sentiment_analyzer = SentimentAnalyzerAgent(api_key)

    # Agente 5: Generador de Resumen
    summarizer = SummarizerAgent(
        api_key=api_key,
        summary_type="executive",
        max_length=300
    )

    # Agente 6: Generador de Reporte
    report_generator = ReportGeneratorAgent(
        api_key=api_key,
        template="""
# Reporte de An√°lisis de Documento

## Informaci√≥n General
- T√≠tulo: {title}
- Autor: {author}
- Fecha: {date}

## Temas Principales
{main_topics}

## Puntos Clave
{key_points}

## Entidades Identificadas
{entities}

## An√°lisis de Sentimiento
{sentiment}

## Resumen Ejecutivo
{summary}

---
Generado autom√°ticamente por Pipeline de An√°lisis
        """,
        format="markdown"
    )

    # Construir pipeline
    pipeline.add_agent(extractor) \
            .add_agent(enricher) \
            .add_agent(validator) \
            .add_agent(sentiment_analyzer) \
            .add_agent(summarizer) \
            .add_agent(report_generator)

    return pipeline


# Uso del pipeline
def demo_document_pipeline():
    api_key = "TU_API_KEY"

    pipeline = create_document_analysis_pipeline(api_key)

    document = """
    Informe Anual de Sostenibilidad 2024 - TechCorp Inc.

    Autor: Mar√≠a Garc√≠a, Directora de Sostenibilidad
    Fecha: 15 de Enero de 2024

    Resumen Ejecutivo:
    Durante 2023, TechCorp logr√≥ reducir sus emisiones de carbono en un 25%,
    superando nuestra meta del 20%. Implementamos paneles solares en todas
    nuestras oficinas de Am√©rica Latina, lideradas por el equipo de
    Carlos Rodr√≠guez en Ciudad de M√©xico.

    Principales Logros:
    1. Reducci√≥n del 25% en emisiones de CO2
    2. 100% de energ√≠a renovable en oficinas de LATAM
    3. Programa de reciclaje con 85% de participaci√≥n
    4. Alianza con GreenTech Foundation para reforestaci√≥n

    La junta directiva, presidida por Ana Mart√≠nez, aprob√≥ un presupuesto
    adicional de $5M para iniciativas de sostenibilidad en 2024.

    Pr√≥ximos pasos incluyen la certificaci√≥n ISO 14001 y la expansi√≥n
    del programa a nuestras oficinas en Europa y Asia.
    """

    result = pipeline.run(document)

    print("\n" + "="*60)
    print("RESULTADO DEL PIPELINE")
    print("="*60)

    if result.errors:
        print(f"\n‚ö†Ô∏è Errores: {result.errors}")

    print(f"\nüìä Datos finales:")
    print(json.dumps(result.data, indent=2, ensure_ascii=False))

    print(f"\nüìú Historial del pipeline:")
    for step in result.history:
        print(f"   - {step['agent']} @ {step['timestamp'][:19]}")


if __name__ == "__main__":
    demo_document_pipeline()
```

## Pipelines con Ramificaci√≥n

```python
"""
Pipelines con ramificaci√≥n condicional y merge
"""


class ConditionalRouter(PipelineAgent):
    """Enruta a diferentes ramas seg√∫n condiciones."""

    def __init__(
        self,
        name: str,
        condition: Callable[[PipelineContext], str],
        branches: Dict[str, Pipeline]
    ):
        super().__init__(name)
        self.condition = condition
        self.branches = branches

    def process(self, context: PipelineContext) -> PipelineContext:
        # Evaluar condici√≥n
        branch_name = self.condition(context)

        if branch_name not in self.branches:
            context.errors.append(f"Rama '{branch_name}' no encontrada")
            return context

        # Ejecutar rama seleccionada
        branch = self.branches[branch_name]
        context.metadata["selected_branch"] = branch_name

        return branch.run(context.data, context.metadata)


class MergeAgent(PipelineAgent):
    """Combina resultados de m√∫ltiples ramas."""

    def __init__(
        self,
        api_key: str,
        merge_strategy: str = "combine"
    ):
        super().__init__("Merger", api_key)
        self.strategy = merge_strategy

    def process(self, context: PipelineContext) -> PipelineContext:
        # Asume que context.data contiene resultados de m√∫ltiples ramas
        branch_results = context.data

        if self.strategy == "combine":
            merged = self._combine_results(branch_results)
        elif self.strategy == "best":
            merged = self._select_best(branch_results)
        else:
            merged = branch_results

        context.set_data(merged)
        return context

    def _combine_results(self, results: List[Dict]) -> Dict:
        """Combina todos los resultados."""
        combined = {}
        for i, result in enumerate(results):
            combined[f"branch_{i}"] = result
        return combined

    def _select_best(self, results: List[Dict]) -> Dict:
        """Selecciona el mejor resultado (usando LLM)."""
        prompt = f"""Selecciona el mejor resultado de estas opciones:

{json.dumps(results, indent=2)}

Responde con el resultado seleccionado y justificaci√≥n."""

        response = self.model.generate_content(prompt)
        return {"selected": response.text, "all_options": results}


class BranchingPipeline:
    """Pipeline con soporte para ramificaci√≥n."""

    def __init__(self, api_key: str):
        self.api_key = api_key
        self.stages: List = []

    def add_stage(self, agent: PipelineAgent) -> 'BranchingPipeline':
        """Agrega un stage secuencial."""
        self.stages.append(("sequential", agent))
        return self

    def add_parallel_stage(
        self,
        agents: List[PipelineAgent]
    ) -> 'BranchingPipeline':
        """Agrega stages que se ejecutan en paralelo."""
        self.stages.append(("parallel", agents))
        return self

    def add_conditional_stage(
        self,
        condition: Callable,
        branches: Dict[str, PipelineAgent]
    ) -> 'BranchingPipeline':
        """Agrega stage condicional."""
        self.stages.append(("conditional", (condition, branches)))
        return self

    def run(self, initial_data: Any) -> PipelineContext:
        """Ejecuta el pipeline con ramificaci√≥n."""
        context = PipelineContext(data=initial_data)

        for stage_type, stage_config in self.stages:
            if stage_type == "sequential":
                context = stage_config.process(context)

            elif stage_type == "parallel":
                # Ejecutar en paralelo y recolectar resultados
                results = []
                for agent in stage_config:
                    branch_context = PipelineContext(data=context.data)
                    result = agent.process(branch_context)
                    results.append(result.data)
                context.set_data(results)

            elif stage_type == "conditional":
                condition, branches = stage_config
                branch_name = condition(context)
                if branch_name in branches:
                    context = branches[branch_name].process(context)

        return context
```

## Ejercicio Pr√°ctico

```python
"""
EJERCICIO: Pipeline de Procesamiento de Curr√≠culums

Implementa un pipeline que procese curr√≠culums para un ATS
(Applicant Tracking System).
"""


class ResumeProcessingPipeline:
    """
    Pipeline para procesamiento de CVs.

    TODO: Implementar las funcionalidades.
    """

    def __init__(self, api_key: str):
        """
        TODO: Inicializar agentes del pipeline:
        1. ParserAgent: Extrae estructura del CV
        2. NormalizerAgent: Normaliza formatos
        3. SkillExtractorAgent: Identifica habilidades
        4. ExperienceCalculatorAgent: Calcula a√±os de experiencia
        5. ScorerAgent: Punt√∫a seg√∫n requisitos del puesto
        6. MatcherAgent: Compara con requisitos del puesto
        """
        pass

    def create_parser_agent(self) -> PipelineAgent:
        """
        Crea agente que parsea el CV.

        TODO:
        1. Extraer secciones (educaci√≥n, experiencia, skills)
        2. Identificar fechas y periodos
        3. Normalizar formato de datos
        """
        pass

    def create_skill_extractor(self) -> PipelineAgent:
        """
        Crea agente que extrae y categoriza skills.

        TODO:
        1. Identificar skills t√©cnicos
        2. Identificar soft skills
        3. Mapear a taxonom√≠a est√°ndar
        4. Estimar nivel de competencia
        """
        pass

    def create_scorer_agent(
        self,
        job_requirements: Dict
    ) -> PipelineAgent:
        """
        Crea agente que punt√∫a el CV.

        TODO:
        1. Comparar skills con requisitos
        2. Evaluar experiencia requerida
        3. Verificar educaci√≥n m√≠nima
        4. Calcular score de match
        """
        pass

    def process_resume(
        self,
        resume_text: str,
        job_requirements: Dict
    ) -> Dict:
        """
        Procesa un CV completo.

        TODO:
        1. Ejecutar pipeline completo
        2. Generar reporte de compatibilidad
        3. Sugerir mejoras al candidato
        """
        pass


def test_resume_pipeline():
    """Prueba el pipeline de CVs."""
    # TODO: Implementar prueba con CV de ejemplo
    pass
```

## Resumen

| Patr√≥n | Uso | Beneficio |
|--------|-----|-----------|
| Secuencial | Transformaciones paso a paso | Simple, predecible |
| Paralelo | Procesamiento independiente | Velocidad |
| Condicional | Flujos alternativos | Flexibilidad |
| Merge | Combinar resultados | S√≠ntesis |

### Checklist de Implementaci√≥n

- [ ] Definir stages con responsabilidades claras
- [ ] Implementar paso de contexto entre agentes
- [ ] Agregar validaci√≥n entre stages
- [ ] Implementar manejo de errores
- [ ] Agregar logging del historial
- [ ] Considerar ejecuci√≥n paralela donde sea posible

## Siguiente Paso

En el pr√≥ximo tema exploraremos **Comunicaci√≥n Inter-Agente**, con formatos de mensaje, memoria compartida y manejo de conflictos.
