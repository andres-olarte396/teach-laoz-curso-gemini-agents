# 4.3.1 Agente de Investigaci√≥n Web

## Tiempo estimado: 90 minutos
## Nivel: Intermedio-Avanzado

## Prerrequisitos
- Modelo ReAct (4.1.1)
- Plan-and-Execute (4.2.2)
- Function Calling (M√≥dulo 3)

## ¬øPor qu√© es importante?

Un **agente de investigaci√≥n web** es uno de los casos de uso m√°s pr√°cticos y demandados de los agentes de IA. Permite:
- Recopilar informaci√≥n de m√∫ltiples fuentes autom√°ticamente
- Sintetizar hallazgos de manera coherente
- Verificar informaci√≥n cruzando fuentes
- Generar reportes estructurados

Este tipo de agente es fundamental para aplicaciones de business intelligence, an√°lisis competitivo, y soporte a la investigaci√≥n.

## Arquitectura del Agente de Investigaci√≥n

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   AGENTE DE INVESTIGACI√ìN WEB                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                         ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ   ‚îÇ                     QUERY DEL USUARIO                            ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   "Investiga las tendencias de IA generativa en 2024"           ‚îÇ  ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                               ‚îÇ                                         ‚îÇ
‚îÇ                               ‚ñº                                         ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ   ‚îÇ                   M√ìDULO DE PLANIFICACI√ìN                        ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                                                                   ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   1. Analizar query y extraer temas clave                        ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   2. Identificar fuentes relevantes                              ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   3. Generar sub-queries de b√∫squeda                            ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   4. Planificar orden de investigaci√≥n                          ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                                                                   ‚îÇ  ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                               ‚îÇ                                         ‚îÇ
‚îÇ                               ‚ñº                                         ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ   ‚îÇ                   M√ìDULO DE B√öSQUEDA                             ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                                                                   ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ Google    ‚îÇ  ‚îÇ Wikipedia ‚îÇ  ‚îÇ News API  ‚îÇ  ‚îÇ Scholar   ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ Search    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ           ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ         ‚îÇ              ‚îÇ              ‚îÇ              ‚îÇ          ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                               ‚îÇ                                  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                               ‚ñº                                  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                    [Resultados Crudos]                          ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                                                                   ‚îÇ  ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                               ‚îÇ                                         ‚îÇ
‚îÇ                               ‚ñº                                         ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ   ‚îÇ                   M√ìDULO DE AN√ÅLISIS                             ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                                                                   ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚Ä¢ Filtrar informaci√≥n irrelevante                             ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚Ä¢ Extraer datos clave                                          ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚Ä¢ Verificar consistencia entre fuentes                        ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚Ä¢ Identificar contradicciones                                 ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚Ä¢ Evaluar credibilidad                                        ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                                                                   ‚îÇ  ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                               ‚îÇ                                         ‚îÇ
‚îÇ                               ‚ñº                                         ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ   ‚îÇ                   M√ìDULO DE S√çNTESIS                             ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                                                                   ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚Ä¢ Organizar hallazgos por tema                                ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚Ä¢ Generar resumen ejecutivo                                    ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚Ä¢ Crear secciones detalladas                                  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚Ä¢ Incluir citas y referencias                                 ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚Ä¢ Formatear reporte final                                     ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                                                                   ‚îÇ  ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                               ‚îÇ                                         ‚îÇ
‚îÇ                               ‚ñº                                         ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ   ‚îÇ                     REPORTE FINAL                                ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   üìÑ Documento estructurado con hallazgos                       ‚îÇ  ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Implementaci√≥n Completa

```python
import google.generativeai as genai
from dataclasses import dataclass, field
from typing import Optional, Any
from enum import Enum
import json
import requests
import time
from datetime import datetime
import os
from urllib.parse import quote_plus

class SourceType(Enum):
    """Tipos de fuentes de informaci√≥n."""
    WIKIPEDIA = "wikipedia"
    NEWS = "news"
    ACADEMIC = "academic"
    WEB_SEARCH = "web_search"
    CUSTOM_API = "custom_api"

@dataclass
class SearchResult:
    """Resultado de una b√∫squeda."""
    title: str
    url: str
    snippet: str
    source_type: SourceType
    relevance_score: float = 0.0
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    metadata: dict = field(default_factory=dict)

@dataclass
class ResearchFinding:
    """Hallazgo de investigaci√≥n."""
    topic: str
    content: str
    sources: list[SearchResult]
    confidence: float
    contradictions: list[str] = field(default_factory=list)

@dataclass
class ResearchReport:
    """Reporte de investigaci√≥n completo."""
    query: str
    executive_summary: str
    findings: list[ResearchFinding]
    sources_used: list[SearchResult]
    generated_at: str = field(default_factory=lambda: datetime.now().isoformat())
    metadata: dict = field(default_factory=dict)


class WebSearcher:
    """
    M√≥dulo de b√∫squeda web con m√∫ltiples fuentes.
    """

    def __init__(self):
        self.rate_limits = {
            SourceType.WIKIPEDIA: 0.5,  # segundos entre requests
            SourceType.NEWS: 1.0,
            SourceType.WEB_SEARCH: 1.0
        }
        self.last_request = {}

    def _respect_rate_limit(self, source_type: SourceType):
        """Respeta l√≠mites de tasa de requests."""
        if source_type in self.last_request:
            elapsed = time.time() - self.last_request[source_type]
            wait_time = self.rate_limits.get(source_type, 1.0) - elapsed
            if wait_time > 0:
                time.sleep(wait_time)
        self.last_request[source_type] = time.time()

    def search_wikipedia(self, query: str, limit: int = 3) -> list[SearchResult]:
        """Busca en Wikipedia."""
        self._respect_rate_limit(SourceType.WIKIPEDIA)

        results = []
        base_url = "https://es.wikipedia.org/api/rest_v1/page/summary/"

        # Buscar el art√≠culo principal
        try:
            url = base_url + quote_plus(query.replace(" ", "_"))
            response = requests.get(url, timeout=10)

            if response.status_code == 200:
                data = response.json()
                results.append(SearchResult(
                    title=data.get("title", query),
                    url=data.get("content_urls", {}).get("desktop", {}).get("page", ""),
                    snippet=data.get("extract", "")[:500],
                    source_type=SourceType.WIKIPEDIA,
                    relevance_score=0.9
                ))
        except Exception as e:
            print(f"  ‚ö†Ô∏è Error Wikipedia: {e}")

        return results

    def search_news(self, query: str, api_key: str = None, limit: int = 5) -> list[SearchResult]:
        """Busca noticias recientes (simulado sin API key)."""
        self._respect_rate_limit(SourceType.NEWS)

        # Simulaci√≥n - en producci√≥n usar NewsAPI u otra fuente
        return [SearchResult(
            title=f"Noticia sobre {query}",
            url=f"https://news.example.com/{quote_plus(query)}",
            snippet=f"√öltimas noticias relacionadas con {query}. [Contenido simulado]",
            source_type=SourceType.NEWS,
            relevance_score=0.7,
            metadata={"simulated": True}
        )]

    def search_custom(self, query: str, endpoint: str, headers: dict = None) -> list[SearchResult]:
        """Busca en un endpoint personalizado."""
        try:
            response = requests.get(
                endpoint,
                params={"q": query},
                headers=headers or {},
                timeout=10
            )
            if response.status_code == 200:
                data = response.json()
                # Adaptar seg√∫n la estructura del API
                return self._parse_custom_results(data, query)
        except Exception as e:
            print(f"  ‚ö†Ô∏è Error en b√∫squeda personalizada: {e}")
        return []

    def _parse_custom_results(self, data: dict, query: str) -> list[SearchResult]:
        """Parsea resultados de API personalizada."""
        results = []
        items = data.get("results", data.get("items", []))

        for item in items[:5]:
            results.append(SearchResult(
                title=item.get("title", "Sin t√≠tulo"),
                url=item.get("url", item.get("link", "")),
                snippet=item.get("snippet", item.get("description", ""))[:500],
                source_type=SourceType.CUSTOM_API,
                relevance_score=0.8
            ))

        return results

    def search_all(self, query: str) -> list[SearchResult]:
        """Busca en todas las fuentes disponibles."""
        all_results = []

        print(f"  üîç Buscando: {query}")

        # Wikipedia
        wiki_results = self.search_wikipedia(query)
        all_results.extend(wiki_results)
        print(f"    üìö Wikipedia: {len(wiki_results)} resultados")

        # News
        news_results = self.search_news(query)
        all_results.extend(news_results)
        print(f"    üì∞ Noticias: {len(news_results)} resultados")

        return all_results


class ResearchPlanner:
    """
    Planifica la estrategia de investigaci√≥n.
    """

    def __init__(self, model: genai.GenerativeModel):
        self.model = model

    def create_research_plan(self, query: str) -> dict:
        """Crea un plan de investigaci√≥n."""

        prompt = f"""Analiza esta consulta de investigaci√≥n y crea un plan:

CONSULTA: {query}

Genera un plan de investigaci√≥n en JSON:
{{
    "main_topics": ["tema principal 1", "tema 2", ...],
    "sub_queries": ["b√∫squeda espec√≠fica 1", "b√∫squeda 2", ...],
    "expected_sources": ["tipo de fuente 1", ...],
    "key_questions": ["pregunta clave 1", ...],
    "research_depth": "shallow|medium|deep"
}}

Genera 3-5 sub-queries espec√≠ficas que ayuden a investigar el tema.
Responde SOLO con el JSON."""

        response = self.model.generate_content(prompt)

        try:
            text = response.text.strip()
            if text.startswith("```"):
                text = text.split("```")[1]
                if text.startswith("json"):
                    text = text[4:]
            return json.loads(text)
        except:
            return {
                "main_topics": [query],
                "sub_queries": [query],
                "expected_sources": ["wikipedia", "news"],
                "key_questions": [f"¬øQu√© es {query}?"],
                "research_depth": "medium"
            }


class ContentAnalyzer:
    """
    Analiza y procesa el contenido recopilado.
    """

    def __init__(self, model: genai.GenerativeModel):
        self.model = model

    def extract_key_info(self, results: list[SearchResult], query: str) -> list[dict]:
        """Extrae informaci√≥n clave de los resultados."""
        extracted = []

        for result in results:
            if not result.snippet:
                continue

            prompt = f"""Extrae informaci√≥n clave de este texto relacionada con: {query}

TEXTO:
{result.snippet}

Responde en JSON:
{{
    "relevant": true/false,
    "key_facts": ["hecho 1", "hecho 2"],
    "entities": ["entidad mencionada 1", ...],
    "dates": ["fecha mencionada si hay"],
    "sentiment": "positive|negative|neutral"
}}"""

            try:
                response = self.model.generate_content(prompt)
                text = response.text.strip()
                if text.startswith("```"):
                    text = text.split("```")[1]
                    if text.startswith("json"):
                        text = text[4:]
                data = json.loads(text)
                data["source"] = result
                extracted.append(data)
            except:
                extracted.append({
                    "relevant": True,
                    "key_facts": [result.snippet[:200]],
                    "entities": [],
                    "dates": [],
                    "sentiment": "neutral",
                    "source": result
                })

        return extracted

    def find_contradictions(self, extracted: list[dict]) -> list[str]:
        """Identifica contradicciones entre fuentes."""
        if len(extracted) < 2:
            return []

        all_facts = []
        for item in extracted:
            all_facts.extend(item.get("key_facts", []))

        if not all_facts:
            return []

        prompt = f"""Analiza estos hechos e identifica contradicciones:

HECHOS:
{json.dumps(all_facts, indent=2)}

Si hay contradicciones, lista cada una.
Si no hay contradicciones, responde "NONE".

Responde en formato:
- Contradicci√≥n 1: [descripci√≥n]
- Contradicci√≥n 2: [descripci√≥n]
O: NONE"""

        response = self.model.generate_content(prompt)
        text = response.text.strip()

        if "NONE" in text.upper():
            return []

        contradictions = []
        for line in text.split("\n"):
            if line.strip().startswith("-") or line.strip().startswith("‚Ä¢"):
                contradictions.append(line.strip("- ‚Ä¢").strip())

        return contradictions


class ReportGenerator:
    """
    Genera reportes estructurados de investigaci√≥n.
    """

    def __init__(self, model: genai.GenerativeModel):
        self.model = model

    def generate_report(
        self,
        query: str,
        findings: list[dict],
        sources: list[SearchResult]
    ) -> ResearchReport:
        """Genera un reporte completo de investigaci√≥n."""

        # Preparar contexto
        findings_text = json.dumps(findings, indent=2, default=str)[:3000]

        prompt = f"""Genera un reporte de investigaci√≥n sobre: {query}

HALLAZGOS RECOPILADOS:
{findings_text}

N√öMERO DE FUENTES: {len(sources)}

Genera un reporte estructurado en JSON:
{{
    "executive_summary": "Resumen ejecutivo de 2-3 p√°rrafos",
    "main_findings": [
        {{
            "topic": "Tema del hallazgo",
            "content": "Descripci√≥n detallada",
            "confidence": 0.0-1.0
        }}
    ],
    "conclusions": ["conclusi√≥n 1", "conclusi√≥n 2"],
    "limitations": ["limitaci√≥n del estudio"]
}}

S√© objetivo y basa todo en los hallazgos proporcionados."""

        response = self.model.generate_content(prompt)

        try:
            text = response.text.strip()
            if text.startswith("```"):
                text = text.split("```")[1]
                if text.startswith("json"):
                    text = text[4:]
            data = json.loads(text)
        except:
            data = {
                "executive_summary": "No se pudo generar el resumen autom√°tico.",
                "main_findings": [],
                "conclusions": [],
                "limitations": ["Error en generaci√≥n del reporte"]
            }

        # Crear findings estructurados
        research_findings = []
        for finding in data.get("main_findings", []):
            research_findings.append(ResearchFinding(
                topic=finding.get("topic", "General"),
                content=finding.get("content", ""),
                sources=[s for s in sources if s.relevance_score > 0.5][:3],
                confidence=finding.get("confidence", 0.5)
            ))

        return ResearchReport(
            query=query,
            executive_summary=data.get("executive_summary", ""),
            findings=research_findings,
            sources_used=sources,
            metadata={
                "conclusions": data.get("conclusions", []),
                "limitations": data.get("limitations", [])
            }
        )


class WebResearchAgent:
    """
    Agente completo de investigaci√≥n web.
    """

    def __init__(self, model_name: str = "gemini-2.0-flash"):
        genai.configure(api_key=os.environ["GOOGLE_API_KEY"])
        self.model = genai.GenerativeModel(model_name)

        self.searcher = WebSearcher()
        self.planner = ResearchPlanner(self.model)
        self.analyzer = ContentAnalyzer(self.model)
        self.reporter = ReportGenerator(self.model)

        self.max_searches = 10
        self.verbose = True

    def research(self, query: str) -> ResearchReport:
        """
        Ejecuta una investigaci√≥n completa.

        Args:
            query: La consulta o tema a investigar

        Returns:
            ResearchReport con todos los hallazgos
        """
        if self.verbose:
            print(f"\n{'='*60}")
            print(f"üî¨ INICIANDO INVESTIGACI√ìN")
            print(f"{'='*60}")
            print(f"üìù Query: {query}\n")

        # 1. Planificaci√≥n
        if self.verbose:
            print("üìã FASE 1: Planificaci√≥n")
        plan = self.planner.create_research_plan(query)

        if self.verbose:
            print(f"   Temas principales: {plan.get('main_topics', [])}")
            print(f"   Sub-queries: {len(plan.get('sub_queries', []))}")
            print()

        # 2. B√∫squeda
        if self.verbose:
            print("üîç FASE 2: B√∫squeda")
        all_results = []

        queries_to_search = [query] + plan.get("sub_queries", [])[:self.max_searches-1]

        for search_query in queries_to_search:
            results = self.searcher.search_all(search_query)
            all_results.extend(results)

            if len(all_results) >= self.max_searches * 3:
                break

        if self.verbose:
            print(f"\n   Total resultados: {len(all_results)}\n")

        # 3. An√°lisis
        if self.verbose:
            print("üß† FASE 3: An√°lisis")
        extracted = self.analyzer.extract_key_info(all_results, query)
        contradictions = self.analyzer.find_contradictions(extracted)

        if self.verbose:
            print(f"   Informaci√≥n extra√≠da: {len(extracted)} items")
            if contradictions:
                print(f"   ‚ö†Ô∏è Contradicciones encontradas: {len(contradictions)}")
            print()

        # 4. S√≠ntesis
        if self.verbose:
            print("üìÑ FASE 4: Generaci√≥n de Reporte")
        report = self.reporter.generate_report(query, extracted, all_results)

        if contradictions:
            for finding in report.findings:
                finding.contradictions = contradictions

        if self.verbose:
            print("   ‚úÖ Reporte generado\n")
            print("="*60)

        return report

    def format_report_markdown(self, report: ResearchReport) -> str:
        """Formatea el reporte como Markdown."""
        md = []
        md.append(f"# Reporte de Investigaci√≥n\n")
        md.append(f"**Query:** {report.query}\n")
        md.append(f"**Fecha:** {report.generated_at}\n")
        md.append(f"**Fuentes consultadas:** {len(report.sources_used)}\n")

        md.append("\n## Resumen Ejecutivo\n")
        md.append(report.executive_summary)

        md.append("\n## Hallazgos Principales\n")
        for i, finding in enumerate(report.findings, 1):
            md.append(f"\n### {i}. {finding.topic}\n")
            md.append(finding.content)
            md.append(f"\n*Confianza: {finding.confidence:.0%}*\n")

            if finding.contradictions:
                md.append("\n**‚ö†Ô∏è Contradicciones detectadas:**\n")
                for c in finding.contradictions:
                    md.append(f"- {c}\n")

        md.append("\n## Fuentes\n")
        for source in report.sources_used[:10]:
            md.append(f"- [{source.title}]({source.url}) - {source.source_type.value}\n")

        if report.metadata.get("conclusions"):
            md.append("\n## Conclusiones\n")
            for conclusion in report.metadata["conclusions"]:
                md.append(f"- {conclusion}\n")

        if report.metadata.get("limitations"):
            md.append("\n## Limitaciones\n")
            for limitation in report.metadata["limitations"]:
                md.append(f"- {limitation}\n")

        return "\n".join(md)
```

## Ejemplo de Uso

```python
# Crear el agente
agent = WebResearchAgent()

# Ejecutar investigaci√≥n
report = agent.research(
    "Impacto de la inteligencia artificial generativa en el mercado laboral 2024"
)

# Mostrar reporte formateado
print(agent.format_report_markdown(report))

# Acceder a datos espec√≠ficos
print(f"\nEstad√≠sticas:")
print(f"  - Hallazgos: {len(report.findings)}")
print(f"  - Fuentes: {len(report.sources_used)}")
print(f"  - Confianza promedio: {sum(f.confidence for f in report.findings)/len(report.findings):.0%}")
```

## Variante: Agente con Verificaci√≥n de Hechos

```python
class FactCheckingResearchAgent(WebResearchAgent):
    """
    Agente de investigaci√≥n con verificaci√≥n de hechos.
    """

    def __init__(self, model_name: str = "gemini-2.0-flash"):
        super().__init__(model_name)
        self.verification_threshold = 2  # M√≠nimo de fuentes para verificar

    def research_with_verification(self, query: str) -> ResearchReport:
        """Investiga verificando hechos clave."""
        report = self.research(query)

        # Verificar cada hallazgo
        verified_findings = []
        for finding in report.findings:
            verification = self._verify_finding(finding)
            finding.metadata = finding.metadata if hasattr(finding, 'metadata') else {}
            finding.confidence = verification["confidence"]
            verified_findings.append(finding)

        report.findings = verified_findings
        return report

    def _verify_finding(self, finding: ResearchFinding) -> dict:
        """Verifica un hallazgo espec√≠fico."""
        if len(finding.sources) < self.verification_threshold:
            return {
                "verified": False,
                "confidence": 0.3,
                "reason": "Pocas fuentes"
            }

        # Buscar corroboraci√≥n adicional
        verification_results = self.searcher.search_all(
            f"verificar {finding.topic}"
        )

        prompt = f"""Verifica este hallazgo:

HALLAZGO: {finding.content}

FUENTES ORIGINALES: {len(finding.sources)}
FUENTES DE VERIFICACI√ìN: {len(verification_results)}

¬øEl hallazgo est√° bien fundamentado?
Responde: VERIFIED (0.8-1.0), LIKELY (0.5-0.8), UNCERTAIN (0.3-0.5), DISPUTED (0.0-0.3)
Y explica brevemente."""

        response = self.model.generate_content(prompt)
        text = response.text.upper()

        if "VERIFIED" in text:
            return {"verified": True, "confidence": 0.9, "reason": "Verificado"}
        elif "LIKELY" in text:
            return {"verified": True, "confidence": 0.7, "reason": "Probable"}
        elif "UNCERTAIN" in text:
            return {"verified": False, "confidence": 0.4, "reason": "Incierto"}
        else:
            return {"verified": False, "confidence": 0.2, "reason": "Disputado"}


# Uso
fact_checker = FactCheckingResearchAgent()
verified_report = fact_checker.research_with_verification(
    "Efectos del cambio clim√°tico en la agricultura"
)
```

## Errores Comunes y Soluciones

### 1. Sesgo de Fuentes

```python
# ‚ùå MAL: Solo usar una fuente
results = searcher.search_wikipedia(query)  # Sesgo hacia Wikipedia

# ‚úÖ BIEN: Diversificar fuentes
def get_diverse_sources(self, query):
    sources = []
    sources.extend(self.searcher.search_wikipedia(query))
    sources.extend(self.searcher.search_news(query))
    sources.extend(self.searcher.search_academic(query))

    # Balancear por tipo
    balanced = self._balance_sources(sources)
    return balanced

def _balance_sources(self, sources):
    by_type = {}
    for s in sources:
        by_type.setdefault(s.source_type, []).append(s)

    balanced = []
    for source_type, items in by_type.items():
        balanced.extend(items[:3])  # M√°ximo 3 por tipo
    return balanced
```

### 2. Informaci√≥n Desactualizada

```python
# ‚ùå MAL: No verificar fechas
def process_result(result):
    return result.snippet  # Puede ser de 2010

# ‚úÖ BIEN: Priorizar informaci√≥n reciente
def process_result_with_date(result, max_age_days=365):
    if result.metadata.get("date"):
        result_date = parse_date(result.metadata["date"])
        age = (datetime.now() - result_date).days

        if age > max_age_days:
            result.relevance_score *= 0.5  # Penalizar antiguo
            result.metadata["warning"] = "Informaci√≥n potencialmente desactualizada"

    return result
```

### 3. Alucinaciones en S√≠ntesis

```python
# ‚ùå MAL: Generar contenido sin restricciones
prompt = f"Escribe sobre {topic}"  # Puede inventar

# ‚úÖ BIEN: Anclar en fuentes espec√≠ficas
def synthesize_with_grounding(self, topic, sources):
    source_quotes = []
    for s in sources:
        source_quotes.append(f'- "{s.snippet[:200]}" (Fuente: {s.title})')

    prompt = f"""Sintetiza informaci√≥n sobre {topic}.

USA SOLO estas fuentes:
{chr(10).join(source_quotes)}

REGLAS:
- Solo incluir informaci√≥n que est√© en las fuentes
- Citar la fuente de cada afirmaci√≥n
- Si algo no est√° en las fuentes, NO lo menciones
- Indica claramente si hay informaci√≥n faltante

S√≠ntesis:"""

    return self.model.generate_content(prompt)
```

## Aplicaciones del Agente

| Aplicaci√≥n | Descripci√≥n | Ejemplo de Query |
|------------|-------------|------------------|
| An√°lisis competitivo | Investigar competidores | "Estrategias de marketing de Tesla 2024" |
| Due diligence | Verificar informaci√≥n de empresas | "Historial financiero de StartupX" |
| Investigaci√≥n acad√©mica | Revisi√≥n de literatura | "Avances en computaci√≥n cu√°ntica" |
| Monitoreo de tendencias | Seguir temas de inter√©s | "Tendencias en desarrollo web" |
| Fact-checking | Verificar afirmaciones | "¬øEs cierto que X reduce Y?" |

## Resumen

El **agente de investigaci√≥n web** automatiza la recopilaci√≥n y an√°lisis de informaci√≥n:

**Componentes clave**:
1. **Planificador**: Genera estrategia de b√∫squeda
2. **Buscador**: Consulta m√∫ltiples fuentes
3. **Analizador**: Extrae y verifica informaci√≥n
4. **Reportero**: Sintetiza hallazgos

**Mejores pr√°cticas**:
- Diversificar fuentes para evitar sesgos
- Verificar fechas de la informaci√≥n
- Anclar s√≠ntesis en fuentes espec√≠ficas
- Identificar y reportar contradicciones
- Indicar nivel de confianza

---

## Navegaci√≥n

- **Anterior**: [4.2.3 Replanificaci√≥n Din√°mica](../tema_4.2/4.2.3-replanificacion-dinamica.md)
- **Siguiente**: [4.3.2 Agente de An√°lisis de Datos](./4.3.2-agente-analisis-datos.md)
- **√çndice**: [README del Curso](../../README.md)
