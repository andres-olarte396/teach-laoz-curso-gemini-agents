# Generación Multimodal

**Tiempo estimado**: 40 minutos
**Nivel**: Intermedio
**Prerrequisitos**: Análisis de imágenes (1.2.1), Audio y video (1.2.2)

## ¿Por qué importa este concepto?

La generación multimodal permite crear contenido que **combina** diferentes modalidades en una sola interacción. No solo puedes enviar texto e imágenes a Gemini, sino también solicitar que genere respuestas que integren análisis visual, textual y estructurado simultáneamente.

Casos de uso clave:
- Generar descripciones detalladas de múltiples imágenes
- Crear documentación técnica a partir de diagramas
- Combinar análisis de video con transcripción de audio
- Generar código a partir de mockups visuales

---

## Combinando modalidades en el input

### Texto + Imagen

```python
import google.generativeai as genai
from PIL import Image
import os

genai.configure(api_key=os.environ["GOOGLE_API_KEY"])
model = genai.GenerativeModel("gemini-1.5-flash")


def analyze_with_context(image_path: str, context: str, question: str) -> str:
    """
    Analiza una imagen con contexto textual adicional.

    Args:
        image_path: Ruta a la imagen
        context: Información de contexto
        question: Pregunta específica

    Returns:
        Análisis del modelo
    """
    image = Image.open(image_path)

    prompt = f"""
CONTEXTO:
{context}

IMAGEN: [adjunta]

PREGUNTA:
{question}

Responde considerando tanto el contexto como lo que ves en la imagen.
"""

    response = model.generate_content([prompt, image])
    return response.text


# Uso
result = analyze_with_context(
    "diagrama_arquitectura.png",
    context="Este es el diagrama de arquitectura de nuestra aplicación de e-commerce. Usamos microservicios en Kubernetes.",
    question="¿Qué mejoras de escalabilidad sugieres basándote en el diagrama?"
)
print(result)
```

### Múltiples imágenes + Texto

```python
def compare_and_generate(
    images: list,
    labels: list,
    task: str
) -> str:
    """
    Compara múltiples imágenes y genera contenido basado en ellas.

    Args:
        images: Lista de rutas de imágenes
        labels: Etiquetas para cada imagen
        task: Tarea a realizar

    Returns:
        Contenido generado
    """
    content = [f"TAREA: {task}\n\n"]

    for i, (img_path, label) in enumerate(zip(images, labels)):
        img = Image.open(img_path)
        content.append(f"IMAGEN {i+1} - {label}:")
        content.append(img)
        content.append("\n")

    content.append("\nGenera tu respuesta considerando TODAS las imágenes anteriores.")

    response = model.generate_content(content)
    return response.text


# Uso: Comparar diseños de UI
result = compare_and_generate(
    images=["mockup_v1.png", "mockup_v2.png", "mockup_v3.png"],
    labels=["Versión 1 - Original", "Versión 2 - Minimalista", "Versión 3 - Colorida"],
    task="Compara estos tres diseños de interfaz y recomienda cuál usar para una app de finanzas personales. Justifica tu elección."
)
```

### Imagen + Audio/Video

```python
def multimodal_analysis(
    video_path: str = None,
    image_path: str = None,
    audio_path: str = None,
    prompt: str = ""
) -> str:
    """
    Análisis combinando múltiples modalidades.

    Args:
        video_path: Ruta al video (opcional)
        image_path: Ruta a imagen (opcional)
        audio_path: Ruta a audio (opcional)
        prompt: Instrucciones de análisis

    Returns:
        Análisis integrado
    """
    content = [prompt + "\n\n"]
    files_to_cleanup = []

    # Agregar video si existe
    if video_path:
        video_file = genai.upload_file(video_path)
        # Esperar procesamiento
        import time
        while video_file.state.name == "PROCESSING":
            time.sleep(2)
            video_file = genai.get_file(video_file.name)
        content.append("VIDEO:\n")
        content.append(video_file)
        files_to_cleanup.append(video_file.name)

    # Agregar imagen si existe
    if image_path:
        img = Image.open(image_path)
        content.append("\nIMAGEN:\n")
        content.append(img)

    # Agregar audio si existe
    if audio_path:
        audio_file = genai.upload_file(audio_path)
        import time
        while audio_file.state.name == "PROCESSING":
            time.sleep(2)
            audio_file = genai.get_file(audio_file.name)
        content.append("\nAUDIO:\n")
        content.append(audio_file)
        files_to_cleanup.append(audio_file.name)

    # Generar respuesta
    response = model.generate_content(content)

    # Limpiar archivos subidos
    for file_name in files_to_cleanup:
        try:
            genai.delete_file(file_name)
        except:
            pass

    return response.text


# Uso: Analizar presentación con slides y narración
result = multimodal_analysis(
    video_path="presentacion.mp4",
    image_path="slide_principal.png",
    prompt="""
    Analiza esta presentación:
    1. Resume el contenido del video
    2. Compara el slide principal con lo presentado
    3. Identifica discrepancias entre lo visual y lo narrado
    4. Sugiere mejoras
    """
)
```

---

## Generación de contenido estructurado multimodal

### Generar documentación desde diagramas

```python
def generate_docs_from_diagram(diagram_path: str, doc_type: str = "técnica") -> dict:
    """
    Genera documentación a partir de un diagrama.

    Args:
        diagram_path: Ruta al diagrama
        doc_type: Tipo de documentación (técnica, usuario, api)

    Returns:
        Dict con secciones de documentación
    """
    image = Image.open(diagram_path)

    prompts = {
        "técnica": """
Analiza este diagrama de arquitectura y genera documentación técnica.

Responde en JSON:
{
    "titulo": "nombre del sistema",
    "descripcion_general": "párrafo describiendo el sistema",
    "componentes": [
        {
            "nombre": "nombre del componente",
            "tipo": "servicio/database/api/etc",
            "descripcion": "qué hace",
            "tecnologias": ["lista", "de", "tecnologías"],
            "dependencias": ["otros", "componentes"]
        }
    ],
    "flujos_datos": [
        {
            "nombre": "nombre del flujo",
            "origen": "componente origen",
            "destino": "componente destino",
            "descripcion": "qué datos y cómo fluyen"
        }
    ],
    "consideraciones": ["lista de notas importantes"]
}
""",
        "usuario": """
Analiza este diagrama y genera documentación para usuarios finales.

Responde en JSON:
{
    "titulo": "nombre amigable del sistema",
    "que_hace": "explicación simple de qué hace el sistema",
    "funcionalidades": [
        {
            "nombre": "funcionalidad",
            "descripcion": "qué puede hacer el usuario",
            "como_usarlo": "instrucciones simples"
        }
    ],
    "preguntas_frecuentes": [
        {"pregunta": "...", "respuesta": "..."}
    ]
}
""",
        "api": """
Analiza este diagrama de API/servicios y genera documentación de API.

Responde en JSON:
{
    "nombre_api": "nombre",
    "version": "inferida o N/A",
    "base_url": "inferida o placeholder",
    "endpoints": [
        {
            "path": "/ruta",
            "method": "GET/POST/etc",
            "descripcion": "qué hace",
            "parametros": [{"nombre": "...", "tipo": "...", "requerido": true/false}],
            "respuesta": "descripción de la respuesta"
        }
    ],
    "autenticacion": "método inferido",
    "notas": ["observaciones adicionales"]
}
"""
    }

    prompt = prompts.get(doc_type, prompts["técnica"])
    response = model.generate_content([prompt, image])

    import json
    try:
        text = response.text.strip()
        if "```" in text:
            text = text.split("```")[1]
            if text.startswith("json"):
                text = text[4:]
            text = text.strip()
        return json.loads(text)
    except json.JSONDecodeError:
        return {"raw_response": response.text, "parse_error": True}


# Uso
docs = generate_docs_from_diagram("arquitectura_sistema.png", "técnica")
print(f"Sistema: {docs.get('titulo')}")
for comp in docs.get('componentes', []):
    print(f"  - {comp['nombre']}: {comp['descripcion']}")
```

### Generar código desde mockups

```python
def generate_code_from_mockup(
    mockup_path: str,
    framework: str = "React",
    style: str = "Tailwind CSS"
) -> str:
    """
    Genera código de UI a partir de un mockup visual.

    Args:
        mockup_path: Ruta al mockup/wireframe
        framework: Framework de frontend
        style: Sistema de estilos

    Returns:
        Código generado
    """
    image = Image.open(mockup_path)

    prompt = f"""
Analiza este mockup/diseño de interfaz y genera código {framework} con {style}.

INSTRUCCIONES:
1. Identifica todos los elementos visuales
2. Determina la estructura/layout
3. Genera componentes reutilizables donde sea apropiado
4. Usa nombres descriptivos para componentes y clases
5. Incluye estados básicos (hover, active) si son evidentes

FORMATO DE RESPUESTA:
```{framework.lower()}
// Código aquí
```

Notas adicionales sobre decisiones de implementación:
- [lista de notas]
"""

    response = model.generate_content([prompt, image])
    return response.text


# Uso
code = generate_code_from_mockup(
    "login_mockup.png",
    framework="React",
    style="Tailwind CSS"
)
print(code)
```

---

## Workflows multimodales

### Pipeline de procesamiento de documentos

```python
from dataclasses import dataclass
from typing import List, Optional
import json


@dataclass
class DocumentPage:
    """Representa una página de documento."""
    page_number: int
    image_path: str
    extracted_text: Optional[str] = None
    tables: Optional[List[dict]] = None
    figures: Optional[List[dict]] = None


class MultimodalDocumentProcessor:
    """Procesador de documentos multimodal."""

    def __init__(self):
        self.model = genai.GenerativeModel("gemini-1.5-flash")

    def process_page(self, page: DocumentPage) -> DocumentPage:
        """Procesa una página extrayendo texto, tablas y figuras."""
        image = Image.open(page.image_path)

        prompt = """
Analiza esta página de documento y extrae:

1. **Texto**: Todo el texto legible
2. **Tablas**: Si hay tablas, extrae como JSON
3. **Figuras**: Describe cualquier imagen, gráfico o diagrama

Responde en JSON:
{
    "text": "texto extraído completo",
    "tables": [
        {
            "title": "título si existe",
            "headers": ["col1", "col2"],
            "rows": [["val1", "val2"], ...]
        }
    ],
    "figures": [
        {
            "type": "gráfico/imagen/diagrama",
            "description": "descripción detallada",
            "location": "posición en la página"
        }
    ]
}
"""

        response = self.model.generate_content([prompt, image])

        try:
            text = response.text.strip()
            if "```" in text:
                text = text.split("```")[1].replace("json", "").strip()
            data = json.loads(text)

            page.extracted_text = data.get("text", "")
            page.tables = data.get("tables", [])
            page.figures = data.get("figures", [])
        except:
            page.extracted_text = response.text

        return page

    def summarize_document(self, pages: List[DocumentPage]) -> dict:
        """Genera resumen del documento completo."""
        # Construir contexto de todas las páginas
        full_context = ""
        for page in pages:
            full_context += f"\n--- Página {page.page_number} ---\n"
            full_context += page.extracted_text or ""

        prompt = f"""
Basándote en el siguiente contenido de documento, genera un resumen ejecutivo.

CONTENIDO:
{full_context[:50000]}  # Limitar para no exceder contexto

Responde en JSON:
{{
    "titulo_documento": "título inferido",
    "tipo_documento": "informe/manual/artículo/etc",
    "resumen_ejecutivo": "2-3 párrafos",
    "puntos_clave": ["punto 1", "punto 2", ...],
    "conclusiones": ["conclusión 1", ...],
    "palabras_clave": ["keyword1", "keyword2", ...]
}}
"""

        response = self.model.generate_content(prompt)

        try:
            text = response.text.strip()
            if "```" in text:
                text = text.split("```")[1].replace("json", "").strip()
            return json.loads(text)
        except:
            return {"raw_summary": response.text}


# Uso
processor = MultimodalDocumentProcessor()

# Procesar páginas de un PDF convertido a imágenes
pages = [
    DocumentPage(page_number=1, image_path="doc_page_1.png"),
    DocumentPage(page_number=2, image_path="doc_page_2.png"),
    DocumentPage(page_number=3, image_path="doc_page_3.png"),
]

for page in pages:
    processor.process_page(page)
    print(f"Página {page.page_number}: {len(page.extracted_text or '')} caracteres extraídos")

summary = processor.summarize_document(pages)
print(f"\nResumen: {summary.get('resumen_ejecutivo', '')[:200]}...")
```

---

## Generación creativa multimodal

### Crear contenido a partir de imágenes de referencia

```python
def generate_creative_content(
    reference_images: List[str],
    content_type: str,
    style_notes: str = ""
) -> str:
    """
    Genera contenido creativo basado en imágenes de referencia.

    Args:
        reference_images: Rutas a imágenes de referencia
        content_type: Tipo de contenido (historia, poema, descripción, etc.)
        style_notes: Notas sobre el estilo deseado

    Returns:
        Contenido generado
    """
    content = []

    content.append(f"""
Genera contenido creativo del tipo: {content_type}

Usa las siguientes imágenes como inspiración/referencia:
""")

    for i, img_path in enumerate(reference_images):
        img = Image.open(img_path)
        content.append(f"\nReferencia {i+1}:")
        content.append(img)

    if style_notes:
        content.append(f"\n\nNotas de estilo: {style_notes}")

    content.append("""

Genera el contenido siendo creativo pero coherente con las referencias visuales.
El contenido debe ser original y evocador.
""")

    response = model.generate_content(content)
    return response.text


# Uso: Generar historia basada en fotos
story = generate_creative_content(
    reference_images=["paisaje_montaña.jpg", "cabaña_nieve.jpg", "persona_solitaria.jpg"],
    content_type="cuento corto de 500 palabras",
    style_notes="Tono melancólico pero esperanzador, narrador en primera persona"
)
print(story)
```

---

## Casos de prueba

```python
# test_multimodal_generation.py
import pytest
from PIL import Image
import tempfile
import os


@pytest.fixture
def test_image():
    """Crea imagen de prueba."""
    img = Image.new('RGB', (200, 200), color='blue')
    # Agregar algo de "contenido"
    from PIL import ImageDraw
    draw = ImageDraw.Draw(img)
    draw.rectangle([50, 50, 150, 150], fill='white')
    draw.text((70, 90), "TEST", fill='black')
    return img


@pytest.fixture
def temp_image_file(test_image):
    """Guarda imagen temporal."""
    with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as f:
        test_image.save(f.name)
        yield f.name
    os.unlink(f.name)


def test_text_and_image_combined(temp_image_file):
    """Test combinando texto e imagen."""
    image = Image.open(temp_image_file)

    response = model.generate_content([
        "Describe lo que ves en esta imagen y qué texto contiene:",
        image
    ])

    assert response.text is not None
    assert len(response.text) > 0
    print(f"✓ Respuesta multimodal: {response.text[:100]}...")


def test_multiple_images():
    """Test con múltiples imágenes."""
    img1 = Image.new('RGB', (100, 100), color='red')
    img2 = Image.new('RGB', (100, 100), color='green')

    response = model.generate_content([
        "¿De qué colores son estas dos imágenes?",
        "Imagen 1:", img1,
        "Imagen 2:", img2
    ])

    assert "rojo" in response.text.lower() or "red" in response.text.lower()
    assert "verde" in response.text.lower() or "green" in response.text.lower()
    print(f"✓ Múltiples imágenes: {response.text[:100]}...")


def test_structured_output_from_image(temp_image_file):
    """Test generación de JSON desde imagen."""
    image = Image.open(temp_image_file)

    response = model.generate_content([
        """Analiza esta imagen y responde en JSON:
        {"tiene_texto": true/false, "colores_principales": ["color1", "color2"]}""",
        image
    ])

    import json
    try:
        text = response.text.strip()
        if "```" in text:
            text = text.split("```")[1].replace("json", "").strip()
        data = json.loads(text)
        assert "tiene_texto" in data or "colores_principales" in data
        print(f"✓ JSON estructurado: {data}")
    except json.JSONDecodeError:
        # Puede fallar el parsing pero al menos debe responder
        assert response.text is not None
        print(f"✓ Respuesta (no JSON): {response.text[:50]}...")


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
```

---

## Resumen del concepto

**En una frase**: La generación multimodal combina texto, imágenes, audio y video en una sola interacción, permitiendo análisis integrados y generación de contenido rico.

**Patrones clave**:
```python
# Combinar modalidades
response = model.generate_content([
    "Texto de contexto",
    imagen1,
    "Más texto",
    imagen2,
    archivo_video
])
```

**Casos de uso principales**:
- Documentación automática desde diagramas
- Código desde mockups
- Análisis comparativo de imágenes
- Procesamiento de documentos escaneados
- Contenido creativo basado en referencias visuales

**Módulo 1 Completo** (8/8 subtemas). Siguiente: Módulo 2 - Ingeniería de Prompts Avanzada.
