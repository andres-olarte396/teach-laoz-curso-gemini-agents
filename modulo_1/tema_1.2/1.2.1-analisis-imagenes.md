# Análisis de Imágenes con Gemini

**Tiempo estimado**: 45 minutos
**Nivel**: Intermedio
**Prerrequisitos**: API básica de Gemini (Módulo 1.1)

## ¿Por qué importa este concepto?

Gemini es **nativo multimodal**: puede procesar texto e imágenes en la misma llamada. Esto habilita casos de uso como:
- Descripción automática de imágenes
- Extracción de texto de fotos (OCR inteligente)
- Análisis de gráficos y diagramas
- Verificación visual de interfaces
- Agentes que "ven" el mundo

---

## Enviar imágenes a Gemini

### Método 1: Desde archivo local

```python
import google.generativeai as genai
from PIL import Image
import os

genai.configure(api_key=os.environ["GOOGLE_API_KEY"])
model = genai.GenerativeModel("gemini-1.5-flash")


def analyze_image(image_path: str, prompt: str) -> str:
    """
    Analiza una imagen con un prompt específico.

    Args:
        image_path: Ruta al archivo de imagen
        prompt: Pregunta o instrucción sobre la imagen

    Returns:
        Respuesta del modelo
    """
    # Cargar imagen con PIL
    image = Image.open(image_path)

    # Enviar imagen + prompt
    response = model.generate_content([prompt, image])

    return response.text


# Uso
result = analyze_image(
    "foto.jpg",
    "Describe detalladamente qué ves en esta imagen"
)
print(result)
```

### Método 2: Desde URL

```python
import requests
from io import BytesIO


def analyze_image_from_url(url: str, prompt: str) -> str:
    """Analiza imagen desde URL."""
    # Descargar imagen
    response = requests.get(url)
    image = Image.open(BytesIO(response.content))

    # Analizar
    model_response = model.generate_content([prompt, image])
    return model_response.text


# Uso
result = analyze_image_from_url(
    "https://example.com/imagen.jpg",
    "¿Qué objetos ves en esta imagen?"
)
```

### Método 3: Desde bytes (base64)

```python
import base64


def analyze_image_from_base64(b64_string: str, prompt: str) -> str:
    """Analiza imagen desde string base64."""
    # Decodificar
    image_bytes = base64.b64decode(b64_string)
    image = Image.open(BytesIO(image_bytes))

    response = model.generate_content([prompt, image])
    return response.text
```

### Método 4: Múltiples imágenes

```python
def compare_images(image_paths: list, prompt: str) -> str:
    """
    Compara múltiples imágenes.

    Args:
        image_paths: Lista de rutas a imágenes
        prompt: Instrucción de comparación

    Returns:
        Análisis comparativo
    """
    images = [Image.open(path) for path in image_paths]

    # Construir contenido intercalado
    content = [prompt]
    for i, img in enumerate(images):
        content.append(f"\nImagen {i+1}:")
        content.append(img)

    response = model.generate_content(content)
    return response.text


# Uso
result = compare_images(
    ["antes.jpg", "despues.jpg"],
    "Compara estas dos imágenes y describe las diferencias"
)
```

---

## Casos de uso prácticos

### OCR inteligente

```python
def extract_text_from_image(image_path: str) -> dict:
    """
    Extrae texto de una imagen con contexto.

    Returns:
        Dict con texto extraído y metadata
    """
    image = Image.open(image_path)

    prompt = """
    Extrae todo el texto visible en esta imagen.
    Responde en formato JSON con la estructura:
    {
        "text": "texto completo extraído",
        "language": "idioma detectado",
        "text_type": "tipo de documento (recibo, carta, cartel, etc.)",
        "confidence": "alta/media/baja"
    }
    """

    response = model.generate_content([prompt, image])

    # Parsear JSON de la respuesta
    import json
    try:
        # Limpiar respuesta si tiene markdown
        text = response.text.strip()
        if text.startswith("```"):
            text = text.split("```")[1]
            if text.startswith("json"):
                text = text[4:]
        return json.loads(text)
    except json.JSONDecodeError:
        return {"text": response.text, "parse_error": True}


# Uso
result = extract_text_from_image("recibo.jpg")
print(f"Texto: {result.get('text')}")
print(f"Tipo: {result.get('text_type')}")
```

### Análisis de gráficos

```python
def analyze_chart(image_path: str) -> dict:
    """Analiza un gráfico o diagrama."""
    image = Image.open(image_path)

    prompt = """
    Analiza este gráfico y proporciona:
    1. Tipo de gráfico (barras, líneas, pie, etc.)
    2. Qué datos representa
    3. Tendencias principales o insights
    4. Valores específicos si son legibles

    Responde en JSON estructurado.
    """

    response = model.generate_content([prompt, image])
    return {"analysis": response.text}
```

### Verificación de UI

```python
def verify_ui_screenshot(
    screenshot_path: str,
    expected_elements: list
) -> dict:
    """
    Verifica que una captura de UI contenga elementos esperados.

    Args:
        screenshot_path: Ruta a la captura de pantalla
        expected_elements: Lista de elementos que deberían estar presentes

    Returns:
        Dict con resultados de verificación
    """
    image = Image.open(screenshot_path)

    elements_str = "\n".join(f"- {e}" for e in expected_elements)
    prompt = f"""
    Analiza esta captura de pantalla de una interfaz de usuario.

    Verifica si los siguientes elementos están presentes:
    {elements_str}

    Para cada elemento, responde en JSON:
    {{
        "element": "nombre del elemento",
        "present": true/false,
        "location": "descripción de ubicación si está presente",
        "notes": "observaciones adicionales"
    }}

    Responde con un array JSON de todos los elementos.
    """

    response = model.generate_content([prompt, image])

    import json
    try:
        text = response.text.strip()
        if "```" in text:
            text = text.split("```")[1].replace("json", "").strip()
        results = json.loads(text)
        return {
            "results": results,
            "all_present": all(r.get("present", False) for r in results)
        }
    except:
        return {"raw_response": response.text}


# Uso
result = verify_ui_screenshot(
    "app_screenshot.png",
    ["botón de login", "campo de email", "logo de la empresa"]
)
print(f"Todos presentes: {result.get('all_present')}")
```

### Descripción para accesibilidad

```python
def generate_alt_text(image_path: str) -> str:
    """
    Genera texto alternativo para accesibilidad.
    """
    image = Image.open(image_path)

    prompt = """
    Genera una descripción de texto alternativo (alt text) para esta imagen.
    La descripción debe ser:
    - Concisa (máximo 125 caracteres)
    - Descriptiva de lo esencial
    - Útil para personas que usan lectores de pantalla

    Responde SOLO con el texto alternativo, sin explicaciones.
    """

    response = model.generate_content([prompt, image])
    return response.text.strip()
```

---

## Procesamiento de múltiples imágenes

```python
from concurrent.futures import ThreadPoolExecutor
from typing import List, Dict
import os


def batch_analyze_images(
    image_dir: str,
    prompt: str,
    max_workers: int = 5
) -> List[Dict]:
    """
    Analiza múltiples imágenes en paralelo.

    Args:
        image_dir: Directorio con imágenes
        prompt: Prompt para cada imagen
        max_workers: Hilos paralelos

    Returns:
        Lista de resultados
    """
    # Obtener archivos de imagen
    extensions = {'.jpg', '.jpeg', '.png', '.gif', '.webp'}
    image_files = [
        os.path.join(image_dir, f)
        for f in os.listdir(image_dir)
        if os.path.splitext(f)[1].lower() in extensions
    ]

    def analyze_single(path: str) -> Dict:
        try:
            image = Image.open(path)
            response = model.generate_content([prompt, image])
            return {
                "file": os.path.basename(path),
                "success": True,
                "result": response.text
            }
        except Exception as e:
            return {
                "file": os.path.basename(path),
                "success": False,
                "error": str(e)
            }

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        results = list(executor.map(analyze_single, image_files))

    return results


# Uso
results = batch_analyze_images(
    "./product_images/",
    "Describe este producto en una oración"
)
for r in results:
    if r["success"]:
        print(f"{r['file']}: {r['result'][:50]}...")
```

---

## Limitaciones y consideraciones

### Formatos soportados
- JPEG, PNG, GIF, WebP
- Máximo ~20MB por imagen
- Se recomienda resolución razonable (no necesita ser 4K)

### Tokens de imagen
Las imágenes consumen tokens. Una imagen típica puede usar 250-1000 tokens dependiendo de su complejidad.

```python
def estimate_image_tokens(image_path: str) -> int:
    """Estima tokens que consumirá una imagen."""
    image = Image.open(image_path)

    # Heurística: ~258 tokens base + más por resolución alta
    width, height = image.size
    pixels = width * height

    base_tokens = 258
    # Más tokens para imágenes grandes
    if pixels > 1_000_000:  # > 1 megapixel
        base_tokens += 100
    if pixels > 4_000_000:  # > 4 megapixels
        base_tokens += 200

    return base_tokens
```

### Contenido no permitido
Gemini no procesará imágenes que:
- Contengan contenido explícito
- Muestren violencia gráfica
- Violen derechos de autor de manera obvia

---

## Casos de prueba

```python
# test_image_analysis.py
import pytest
from PIL import Image
import io


@pytest.fixture
def test_image():
    """Crea imagen de prueba."""
    img = Image.new('RGB', (100, 100), color='red')
    return img


def test_basic_image_analysis(test_image):
    """Test análisis básico de imagen."""
    response = model.generate_content([
        "¿De qué color es esta imagen?",
        test_image
    ])
    assert response.text is not None
    assert "rojo" in response.text.lower() or "red" in response.text.lower()
    print(f"✓ Análisis básico: {response.text[:50]}")


def test_multiple_images(test_image):
    """Test con múltiples imágenes."""
    img2 = Image.new('RGB', (100, 100), color='blue')

    response = model.generate_content([
        "Describe los colores de estas dos imágenes",
        test_image,
        img2
    ])
    assert response.text is not None
    print(f"✓ Múltiples imágenes: {response.text[:50]}")


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
```

---

## Resumen del concepto

**En una frase**: Gemini puede "ver" imágenes y responder preguntas sobre ellas, habilitando agentes con capacidades visuales.

**Patrón básico**:
```python
image = Image.open("foto.jpg")
response = model.generate_content(["¿Qué ves?", image])
```

**Casos de uso clave**:
- OCR inteligente
- Análisis de gráficos
- Verificación de UI
- Descripción para accesibilidad

**Siguiente paso**: Tema 1.2.2 - Procesamiento de Audio y Video.
