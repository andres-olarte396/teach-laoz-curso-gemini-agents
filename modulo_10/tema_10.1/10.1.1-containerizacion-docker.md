# 10.1.1 Containerización con Docker

## Objetivo de Aprendizaje

Al finalizar este subtema, serás capaz de containerizar agentes de IA con Docker, creando imágenes optimizadas y configuraciones reproducibles para despliegue en cualquier entorno.

## Introducción

Docker permite empaquetar agentes con todas sus dependencias, asegurando que funcionen igual en desarrollo, testing y producción. Esto es crítico para agentes que dependen de versiones específicas de librerías y configuraciones.

```
┌─────────────────────────────────────────────────────────────────┐
│              ARQUITECTURA CONTAINERIZADA                        │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │                    DOCKER HOST                          │   │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐     │   │
│  │  │  AGENT      │  │  REDIS      │  │  POSTGRES   │     │   │
│  │  │  CONTAINER  │  │  CONTAINER  │  │  CONTAINER  │     │   │
│  │  │             │  │             │  │             │     │   │
│  │  │ ┌─────────┐ │  │  Cache &    │  │  Memory     │     │   │
│  │  │ │ Gemini  │ │  │  Pub/Sub    │  │  Storage    │     │   │
│  │  │ │ Agent   │ │  │             │  │             │     │   │
│  │  │ ├─────────┤ │  └──────┬──────┘  └──────┬──────┘     │   │
│  │  │ │ Tools   │ │         │                │            │   │
│  │  │ ├─────────┤ │         └────────┬───────┘            │   │
│  │  │ │ FastAPI │ │                  │                    │   │
│  │  │ └────┬────┘ │                  │                    │   │
│  │  └──────┼──────┘                  │                    │   │
│  │         │          DOCKER NETWORK │                    │   │
│  │  ───────┴─────────────────────────┴────────────────    │   │
│  └─────────────────────────────────────────────────────────┘   │
│                              │                                  │
│                         PORT 8080                               │
│                              ▼                                  │
│                       EXTERNAL ACCESS                           │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

## Estructura del Proyecto

### Organización de Archivos

```
agent-production/
├── src/
│   ├── __init__.py
│   ├── agent/
│   │   ├── __init__.py
│   │   ├── core.py           # Lógica principal del agente
│   │   ├── tools.py          # Herramientas del agente
│   │   └── memory.py         # Sistema de memoria
│   ├── api/
│   │   ├── __init__.py
│   │   ├── main.py           # FastAPI app
│   │   ├── routes.py         # Endpoints
│   │   └── schemas.py        # Pydantic models
│   └── config/
│       ├── __init__.py
│       └── settings.py       # Configuración
├── tests/
│   └── ...
├── Dockerfile
├── Dockerfile.dev
├── docker-compose.yml
├── docker-compose.prod.yml
├── requirements.txt
├── requirements-dev.txt
├── .dockerignore
├── .env.example
└── README.md
```

## Dockerfile Optimizado

### Dockerfile Multi-Stage

```dockerfile
# Dockerfile
# =============================================================================
# STAGE 1: Builder - Instalar dependencias
# =============================================================================
FROM python:3.11-slim as builder

# Configurar variables de entorno
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

# Instalar dependencias del sistema para compilación
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Crear directorio de trabajo
WORKDIR /app

# Copiar e instalar dependencias
COPY requirements.txt .

# Crear virtual environment e instalar dependencias
RUN python -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

RUN pip install --upgrade pip && \
    pip install -r requirements.txt

# =============================================================================
# STAGE 2: Production - Imagen final optimizada
# =============================================================================
FROM python:3.11-slim as production

# Metadatos
LABEL maintainer="tu-email@ejemplo.com" \
      version="1.0.0" \
      description="Agente de IA con Google Gemini"

# Variables de entorno
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PYTHONFAULTHANDLER=1 \
    APP_HOME=/app \
    APP_USER=appuser

# Crear usuario no-root por seguridad
RUN groupadd --gid 1000 ${APP_USER} && \
    useradd --uid 1000 --gid ${APP_USER} --shell /bin/bash --create-home ${APP_USER}

# Instalar dependencias mínimas del sistema
RUN apt-get update && apt-get install -y --no-install-recommends \
    curl \
    tini \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Copiar virtual environment del builder
COPY --from=builder /opt/venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# Configurar directorio de trabajo
WORKDIR ${APP_HOME}

# Copiar código de la aplicación
COPY --chown=${APP_USER}:${APP_USER} src/ ./src/
COPY --chown=${APP_USER}:${APP_USER} scripts/ ./scripts/

# Cambiar a usuario no-root
USER ${APP_USER}

# Exponer puerto
EXPOSE 8080

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8080/health || exit 1

# Usar tini como init system
ENTRYPOINT ["/usr/bin/tini", "--"]

# Comando por defecto
CMD ["python", "-m", "uvicorn", "src.api.main:app", "--host", "0.0.0.0", "--port", "8080"]
```

### Dockerfile de Desarrollo

```dockerfile
# Dockerfile.dev
FROM python:3.11-slim

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1

WORKDIR /app

# Instalar dependencias del sistema
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    curl \
    git \
    && rm -rf /var/lib/apt/lists/*

# Copiar requirements
COPY requirements.txt requirements-dev.txt ./

# Instalar dependencias incluyendo dev
RUN pip install --upgrade pip && \
    pip install -r requirements.txt && \
    pip install -r requirements-dev.txt

# El código se monta como volumen
EXPOSE 8080

# Hot reload con uvicorn
CMD ["uvicorn", "src.api.main:app", "--host", "0.0.0.0", "--port", "8080", "--reload"]
```

### .dockerignore

```dockerignore
# .dockerignore
# Git
.git
.gitignore

# Python
__pycache__
*.py[cod]
*$py.class
*.so
.Python
.env
.venv
env/
venv/
.pytest_cache/
.coverage
htmlcov/
*.egg-info/
dist/
build/

# IDE
.idea/
.vscode/
*.swp
*.swo

# Docker
Dockerfile*
docker-compose*
.docker/

# Docs
docs/
*.md
!README.md

# Tests (para producción)
tests/
pytest.ini

# Misc
.DS_Store
*.log
tmp/
temp/
```

## Docker Compose

### Configuración de Desarrollo

```yaml
# docker-compose.yml
version: '3.8'

services:
  agent:
    build:
      context: .
      dockerfile: Dockerfile.dev
    ports:
      - "8080:8080"
    volumes:
      - ./src:/app/src:cached
      - ./tests:/app/tests:cached
    environment:
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - REDIS_URL=redis://redis:6379/0
      - DATABASE_URL=postgresql://postgres:postgres@db:5432/agent_db
      - LOG_LEVEL=DEBUG
      - ENVIRONMENT=development
    depends_on:
      - redis
      - db
    networks:
      - agent-network
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes
    networks:
      - agent-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  db:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: agent_db
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - agent-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Opcional: Vector DB para RAG
  chromadb:
    image: chromadb/chroma:latest
    ports:
      - "8000:8000"
    volumes:
      - chroma-data:/chroma/chroma
    networks:
      - agent-network

networks:
  agent-network:
    driver: bridge

volumes:
  redis-data:
  postgres-data:
  chroma-data:
```

### Configuración de Producción

```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  agent:
    image: ${REGISTRY}/gemini-agent:${VERSION:-latest}
    build:
      context: .
      dockerfile: Dockerfile
      args:
        - BUILD_DATE=${BUILD_DATE}
        - VCS_REF=${VCS_REF}
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
        order: start-first
    ports:
      - "8080:8080"
    environment:
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - REDIS_URL=redis://redis:6379/0
      - DATABASE_URL=${DATABASE_URL}
      - LOG_LEVEL=INFO
      - ENVIRONMENT=production
      - SENTRY_DSN=${SENTRY_DSN}
    secrets:
      - google_api_key
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - agent-network
      - traefik-public
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.agent.rule=Host(`api.example.com`)"
      - "traefik.http.routers.agent.tls=true"
      - "traefik.http.routers.agent.tls.certresolver=letsencrypt"
      - "traefik.http.services.agent.loadbalancer.server.port=8080"

  redis:
    image: redis:7-alpine
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
    command: >
      redis-server
      --appendonly yes
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
    volumes:
      - redis-data:/data
    networks:
      - agent-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

secrets:
  google_api_key:
    external: true

networks:
  agent-network:
    driver: overlay
    attachable: true
  traefik-public:
    external: true

volumes:
  redis-data:
    driver: local
```

## Código del Agente Containerizado

### Configuración con Pydantic Settings

```python
# src/config/settings.py
from pydantic_settings import BaseSettings
from pydantic import Field, validator
from typing import Optional
from functools import lru_cache

class Settings(BaseSettings):
    """Configuración de la aplicación"""

    # API
    app_name: str = "Gemini Agent API"
    app_version: str = "1.0.0"
    debug: bool = False
    environment: str = "development"

    # Servidor
    host: str = "0.0.0.0"
    port: int = 8080
    workers: int = 4

    # Google AI
    google_api_key: str = Field(..., env="GOOGLE_API_KEY")
    gemini_model: str = "gemini-2.0-flash"
    max_tokens: int = 8192

    # Redis
    redis_url: str = "redis://localhost:6379/0"
    redis_ttl: int = 3600

    # Database
    database_url: Optional[str] = None

    # Rate Limiting
    rate_limit_requests: int = 100
    rate_limit_window: int = 60  # segundos

    # Logging
    log_level: str = "INFO"
    log_format: str = "json"

    # Observabilidad
    sentry_dsn: Optional[str] = None
    otel_exporter_endpoint: Optional[str] = None

    # Seguridad
    api_key_header: str = "X-API-Key"
    cors_origins: list[str] = ["*"]

    @validator("log_level")
    def validate_log_level(cls, v):
        valid_levels = ["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"]
        if v.upper() not in valid_levels:
            raise ValueError(f"Log level must be one of {valid_levels}")
        return v.upper()

    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"
        case_sensitive = False

@lru_cache()
def get_settings() -> Settings:
    """Obtiene settings cacheados"""
    return Settings()
```

### API Principal con FastAPI

```python
# src/api/main.py
import logging
from contextlib import asynccontextmanager
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import google.generativeai as genai
import redis.asyncio as redis
import time

from src.config.settings import get_settings
from src.api.routes import router
from src.agent.core import GeminiAgent

settings = get_settings()
logger = logging.getLogger(__name__)

# Estado global de la aplicación
class AppState:
    agent: GeminiAgent = None
    redis_client: redis.Redis = None
    start_time: float = None

app_state = AppState()

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Gestión del ciclo de vida de la aplicación"""

    # Startup
    logger.info("Iniciando aplicación...")

    # Configurar Gemini
    genai.configure(api_key=settings.google_api_key)

    # Inicializar Redis
    app_state.redis_client = redis.from_url(
        settings.redis_url,
        encoding="utf-8",
        decode_responses=True
    )

    # Verificar conexión Redis
    try:
        await app_state.redis_client.ping()
        logger.info("Conexión Redis establecida")
    except Exception as e:
        logger.warning(f"Redis no disponible: {e}")

    # Inicializar agente
    app_state.agent = GeminiAgent(
        model_name=settings.gemini_model,
        redis_client=app_state.redis_client
    )

    app_state.start_time = time.time()

    logger.info(f"Aplicación iniciada en modo {settings.environment}")

    yield

    # Shutdown
    logger.info("Cerrando aplicación...")

    if app_state.redis_client:
        await app_state.redis_client.close()

    logger.info("Aplicación cerrada correctamente")

# Crear aplicación
app = FastAPI(
    title=settings.app_name,
    version=settings.app_version,
    lifespan=lifespan,
    docs_url="/docs" if settings.debug else None,
    redoc_url="/redoc" if settings.debug else None
)

# Middleware CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Middleware de logging
@app.middleware("http")
async def log_requests(request: Request, call_next):
    start_time = time.time()

    response = await call_next(request)

    duration = time.time() - start_time
    logger.info(
        f"{request.method} {request.url.path} "
        f"status={response.status_code} "
        f"duration={duration:.3f}s"
    )

    response.headers["X-Process-Time"] = str(duration)
    return response

# Health checks
@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "version": settings.app_version,
        "environment": settings.environment
    }

@app.get("/ready")
async def readiness_check():
    """Readiness check - verifica dependencias"""
    checks = {}

    # Verificar Redis
    try:
        await app_state.redis_client.ping()
        checks["redis"] = "healthy"
    except Exception:
        checks["redis"] = "unhealthy"

    # Verificar agente
    checks["agent"] = "healthy" if app_state.agent else "unhealthy"

    all_healthy = all(v == "healthy" for v in checks.values())

    return JSONResponse(
        status_code=200 if all_healthy else 503,
        content={
            "status": "ready" if all_healthy else "not_ready",
            "checks": checks,
            "uptime_seconds": time.time() - app_state.start_time
        }
    )

# Incluir rutas
app.include_router(router, prefix="/api/v1")
```

### Routes del API

```python
# src/api/routes.py
from fastapi import APIRouter, HTTPException, Depends, BackgroundTasks
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
import logging

from src.api.main import app_state
from src.config.settings import get_settings

router = APIRouter()
logger = logging.getLogger(__name__)
settings = get_settings()

# Schemas
class ChatRequest(BaseModel):
    message: str = Field(..., min_length=1, max_length=10000)
    session_id: Optional[str] = None
    context: Optional[Dict[str, Any]] = None

class ChatResponse(BaseModel):
    response: str
    session_id: str
    tokens_used: int
    cached: bool = False

class TaskRequest(BaseModel):
    task: str = Field(..., min_length=1)
    tools: Optional[List[str]] = None
    max_steps: int = Field(default=10, ge=1, le=50)

class TaskResponse(BaseModel):
    task_id: str
    status: str
    result: Optional[Any] = None
    steps_taken: int = 0

# Endpoints
@router.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """Endpoint de chat con el agente"""

    try:
        # Verificar cache
        cache_key = f"chat:{hash(request.message)}"
        cached_response = await app_state.redis_client.get(cache_key)

        if cached_response:
            return ChatResponse(
                response=cached_response,
                session_id=request.session_id or "default",
                tokens_used=0,
                cached=True
            )

        # Generar respuesta
        result = await app_state.agent.chat(
            message=request.message,
            session_id=request.session_id,
            context=request.context
        )

        # Cachear respuesta
        await app_state.redis_client.setex(
            cache_key,
            settings.redis_ttl,
            result["response"]
        )

        return ChatResponse(
            response=result["response"],
            session_id=result["session_id"],
            tokens_used=result["tokens_used"]
        )

    except Exception as e:
        logger.error(f"Error en chat: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/tasks", response_model=TaskResponse)
async def create_task(
    request: TaskRequest,
    background_tasks: BackgroundTasks
):
    """Crea una tarea para el agente"""

    import uuid
    task_id = str(uuid.uuid4())

    # Guardar estado inicial
    await app_state.redis_client.hset(
        f"task:{task_id}",
        mapping={
            "status": "pending",
            "task": request.task,
            "steps": 0
        }
    )

    # Ejecutar en background
    background_tasks.add_task(
        execute_task,
        task_id,
        request.task,
        request.tools,
        request.max_steps
    )

    return TaskResponse(
        task_id=task_id,
        status="pending"
    )

@router.get("/tasks/{task_id}", response_model=TaskResponse)
async def get_task(task_id: str):
    """Obtiene estado de una tarea"""

    task_data = await app_state.redis_client.hgetall(f"task:{task_id}")

    if not task_data:
        raise HTTPException(status_code=404, detail="Task not found")

    return TaskResponse(
        task_id=task_id,
        status=task_data.get("status", "unknown"),
        result=task_data.get("result"),
        steps_taken=int(task_data.get("steps", 0))
    )

async def execute_task(
    task_id: str,
    task: str,
    tools: Optional[List[str]],
    max_steps: int
):
    """Ejecuta tarea en background"""

    try:
        # Actualizar estado
        await app_state.redis_client.hset(
            f"task:{task_id}",
            "status",
            "running"
        )

        # Ejecutar agente
        result = await app_state.agent.execute_task(
            task=task,
            available_tools=tools,
            max_steps=max_steps
        )

        # Guardar resultado
        await app_state.redis_client.hset(
            f"task:{task_id}",
            mapping={
                "status": "completed",
                "result": str(result["output"]),
                "steps": result["steps"]
            }
        )

    except Exception as e:
        logger.error(f"Error ejecutando task {task_id}: {e}")
        await app_state.redis_client.hset(
            f"task:{task_id}",
            mapping={
                "status": "failed",
                "error": str(e)
            }
        )
```

## Scripts de Despliegue

### Build y Push

```bash
#!/bin/bash
# scripts/build.sh

set -e

# Variables
REGISTRY="${REGISTRY:-ghcr.io/tu-usuario}"
IMAGE_NAME="gemini-agent"
VERSION="${VERSION:-$(git describe --tags --always)}"
BUILD_DATE=$(date -u +'%Y-%m-%dT%H:%M:%SZ')
VCS_REF=$(git rev-parse --short HEAD)

echo "Building ${REGISTRY}/${IMAGE_NAME}:${VERSION}"

# Build
docker build \
    --build-arg BUILD_DATE="${BUILD_DATE}" \
    --build-arg VCS_REF="${VCS_REF}" \
    --build-arg VERSION="${VERSION}" \
    -t "${REGISTRY}/${IMAGE_NAME}:${VERSION}" \
    -t "${REGISTRY}/${IMAGE_NAME}:latest" \
    -f Dockerfile \
    .

# Tests
echo "Running tests..."
docker run --rm "${REGISTRY}/${IMAGE_NAME}:${VERSION}" python -m pytest tests/ -v

# Push
if [ "${PUSH:-false}" = "true" ]; then
    echo "Pushing images..."
    docker push "${REGISTRY}/${IMAGE_NAME}:${VERSION}"
    docker push "${REGISTRY}/${IMAGE_NAME}:latest"
fi

echo "Build complete: ${REGISTRY}/${IMAGE_NAME}:${VERSION}"
```

### Inicio Local

```bash
#!/bin/bash
# scripts/start-local.sh

set -e

echo "Starting local development environment..."

# Verificar .env
if [ ! -f .env ]; then
    echo "Creating .env from .env.example..."
    cp .env.example .env
    echo "Please edit .env with your GOOGLE_API_KEY"
    exit 1
fi

# Build y start
docker-compose up --build -d

# Esperar a que esté listo
echo "Waiting for services..."
sleep 5

# Health check
until curl -s http://localhost:8080/health > /dev/null; do
    echo "Waiting for agent to be ready..."
    sleep 2
done

echo "Agent is ready at http://localhost:8080"
echo "API docs at http://localhost:8080/docs"
```

## Ejemplo Práctico

```python
# test_container.py
import requests
import time

BASE_URL = "http://localhost:8080"

def test_health():
    """Test health endpoint"""
    response = requests.get(f"{BASE_URL}/health")
    assert response.status_code == 200
    data = response.json()
    assert data["status"] == "healthy"
    print(f"Health: {data}")

def test_chat():
    """Test chat endpoint"""
    response = requests.post(
        f"{BASE_URL}/api/v1/chat",
        json={
            "message": "¿Qué es Docker?",
            "session_id": "test-session"
        }
    )
    assert response.status_code == 200
    data = response.json()
    print(f"Response: {data['response'][:100]}...")
    print(f"Tokens: {data['tokens_used']}")
    print(f"Cached: {data['cached']}")

def test_task():
    """Test task endpoint"""
    # Crear tarea
    response = requests.post(
        f"{BASE_URL}/api/v1/tasks",
        json={
            "task": "Investiga los beneficios de containerización",
            "max_steps": 5
        }
    )
    assert response.status_code == 200
    task_id = response.json()["task_id"]
    print(f"Task created: {task_id}")

    # Esperar y verificar
    for _ in range(30):
        response = requests.get(f"{BASE_URL}/api/v1/tasks/{task_id}")
        data = response.json()
        print(f"Status: {data['status']}")

        if data["status"] in ["completed", "failed"]:
            print(f"Result: {data.get('result', 'N/A')[:200]}")
            break

        time.sleep(2)

if __name__ == "__main__":
    print("=== Testing Containerized Agent ===\n")

    test_health()
    print()
    test_chat()
    print()
    test_task()
```

## Ejercicios Prácticos

### Ejercicio 1: Optimización de Imagen
Reduce el tamaño de la imagen Docker:
- Usar alpine base
- Eliminar archivos innecesarios
- Optimizar layers

### Ejercicio 2: Multi-Arquitectura
Crea builds para múltiples arquitecturas:
- amd64 y arm64
- Usar docker buildx
- Push a registry multi-arch

### Ejercicio 3: CI/CD Pipeline
Implementa pipeline de CI/CD:
- Build automático en push
- Tests en container
- Deploy a staging/production

## Resumen

| Concepto | Descripción |
|----------|-------------|
| Multi-stage Build | Reduce tamaño separando build de runtime |
| Non-root User | Seguridad ejecutando como usuario no privilegiado |
| Health Checks | Verificación de salud del contenedor |
| Docker Compose | Orquestación local de múltiples servicios |
| Volume Mounts | Persistencia de datos y hot-reload |
| Environment Variables | Configuración mediante variables de entorno |

---

**Siguiente:** [10.1.2 Orquestación con Kubernetes](./10.1.2-orquestacion-kubernetes.md)
