# Rate Limiting y Retry Patterns

**Tiempo estimado**: 40 minutos
**Nivel**: Intermedio
**Prerrequisitos**: Manejo de Respuestas Asíncronas (3.3.2)

## ¿Por qué importa este concepto?

Las APIs tienen límites. Excederlos resulta en:

- Errores 429 (Too Many Requests)
- Bloqueos temporales o permanentes
- Degradación del servicio
- Costos inesperados

Los agentes robustos deben respetar rate limits y manejar fallos transitorios con estrategias de retry inteligentes.

---

## Anatomía del Rate Limiting

```
┌─────────────────────────────────────────────────────────────────┐
│ TIPOS DE RATE LIMITS                                            │
│ ────────────────────                                            │
│                                                                 │
│ POR SEGUNDO (RPS)                                               │
│ ├─ Límite: 10 requests/segundo                                 │
│ └─ Uso: APIs de alta frecuencia                                │
│                                                                 │
│ POR MINUTO (RPM)                                                │
│ ├─ Límite: 100 requests/minuto                                 │
│ └─ Uso: APIs generales                                         │
│                                                                 │
│ POR DÍA                                                         │
│ ├─ Límite: 10,000 requests/día                                 │
│ └─ Uso: APIs con cuota diaria                                  │
│                                                                 │
│ POR TOKENS                                                      │
│ ├─ Límite: 100,000 tokens/minuto                               │
│ └─ Uso: APIs de LLM (Gemini, OpenAI)                           │
│                                                                 │
│ CONCURRENCIA                                                    │
│ ├─ Límite: 5 requests simultáneos                              │
│ └─ Uso: APIs con procesamiento pesado                          │
└─────────────────────────────────────────────────────────────────┘
```

---

## Implementación práctica

### Rate Limiter local

```python
import time
from collections import deque
from dataclasses import dataclass, field
from typing import Dict, Optional, Callable
from threading import Lock
import asyncio


@dataclass
class RateLimitConfig:
    """Configuración de rate limit."""
    requests_per_second: Optional[float] = None
    requests_per_minute: Optional[float] = None
    requests_per_hour: Optional[float] = None
    tokens_per_minute: Optional[int] = None
    max_concurrent: int = 10


class TokenBucketLimiter:
    """
    Implementación de Token Bucket para rate limiting.

    El bucket se llena a una tasa constante y cada request
    consume un token. Si no hay tokens, se espera.
    """

    def __init__(
        self,
        rate: float,  # tokens por segundo
        capacity: int = None  # capacidad máxima del bucket
    ):
        self.rate = rate
        self.capacity = capacity or int(rate * 2)
        self.tokens = self.capacity
        self.last_update = time.time()
        self.lock = Lock()

    def _refill(self):
        """Rellena el bucket basándose en tiempo transcurrido."""
        now = time.time()
        elapsed = now - self.last_update
        self.tokens = min(
            self.capacity,
            self.tokens + elapsed * self.rate
        )
        self.last_update = now

    def acquire(self, tokens: int = 1, timeout: float = None) -> bool:
        """
        Intenta adquirir tokens.

        Args:
            tokens: Número de tokens a adquirir
            timeout: Tiempo máximo de espera

        Returns:
            True si se adquirieron los tokens
        """
        start = time.time()

        with self.lock:
            while True:
                self._refill()

                if self.tokens >= tokens:
                    self.tokens -= tokens
                    return True

                if timeout is not None:
                    elapsed = time.time() - start
                    if elapsed >= timeout:
                        return False

                # Calcular tiempo de espera
                wait_time = (tokens - self.tokens) / self.rate
                if timeout is not None:
                    wait_time = min(wait_time, timeout - (time.time() - start))

                time.sleep(min(wait_time, 0.1))


class SlidingWindowLimiter:
    """
    Rate limiter con ventana deslizante.

    Más preciso que ventana fija, evita ráfagas
    al inicio de cada ventana.
    """

    def __init__(self, limit: int, window_seconds: float):
        self.limit = limit
        self.window_seconds = window_seconds
        self.requests: deque = deque()
        self.lock = Lock()

    def _cleanup(self):
        """Elimina requests fuera de la ventana."""
        cutoff = time.time() - self.window_seconds
        while self.requests and self.requests[0] < cutoff:
            self.requests.popleft()

    def can_proceed(self) -> bool:
        """Verifica si se puede hacer un request."""
        with self.lock:
            self._cleanup()
            return len(self.requests) < self.limit

    def acquire(self, timeout: float = None) -> bool:
        """Intenta adquirir un slot."""
        start = time.time()

        while True:
            with self.lock:
                self._cleanup()

                if len(self.requests) < self.limit:
                    self.requests.append(time.time())
                    return True

            if timeout is not None and time.time() - start >= timeout:
                return False

            # Esperar hasta que expire el request más antiguo
            with self.lock:
                if self.requests:
                    wait_time = self.requests[0] + self.window_seconds - time.time()
                    wait_time = max(0.01, min(wait_time, 1.0))
                else:
                    wait_time = 0.1

            time.sleep(wait_time)

    def get_wait_time(self) -> float:
        """Retorna tiempo de espera estimado."""
        with self.lock:
            self._cleanup()

            if len(self.requests) < self.limit:
                return 0

            return self.requests[0] + self.window_seconds - time.time()


class CompositeRateLimiter:
    """
    Rate limiter que combina múltiples límites.
    Todos los límites deben satisfacerse.
    """

    def __init__(self, config: RateLimitConfig):
        self.limiters: Dict[str, SlidingWindowLimiter] = {}

        if config.requests_per_second:
            self.limiters["rps"] = SlidingWindowLimiter(
                int(config.requests_per_second), 1.0
            )

        if config.requests_per_minute:
            self.limiters["rpm"] = SlidingWindowLimiter(
                int(config.requests_per_minute), 60.0
            )

        if config.requests_per_hour:
            self.limiters["rph"] = SlidingWindowLimiter(
                int(config.requests_per_hour), 3600.0
            )

    def acquire(self, timeout: float = 60) -> bool:
        """Adquiere un slot de todos los limiters."""
        # Verificar primero si todos pueden proceder
        for limiter in self.limiters.values():
            if not limiter.can_proceed():
                # Esperar el máximo necesario
                wait_time = max(
                    l.get_wait_time() for l in self.limiters.values()
                )
                if wait_time > timeout:
                    return False
                time.sleep(wait_time)

        # Adquirir de todos
        for limiter in self.limiters.values():
            if not limiter.acquire(timeout=timeout):
                return False

        return True

    def get_status(self) -> Dict:
        """Retorna estado de los limiters."""
        return {
            name: {
                "current": len(limiter.requests),
                "limit": limiter.limit,
                "wait_time": limiter.get_wait_time()
            }
            for name, limiter in self.limiters.items()
        }
```

### Patrones de Retry

```python
import random
from functools import wraps
from typing import Callable, Type, Tuple, List


class RetryStrategy:
    """Estrategia base de retry."""

    def get_delay(self, attempt: int) -> float:
        """Retorna delay antes del siguiente intento."""
        raise NotImplementedError


class ExponentialBackoff(RetryStrategy):
    """Backoff exponencial con jitter."""

    def __init__(
        self,
        base_delay: float = 1.0,
        max_delay: float = 60.0,
        exponential_base: float = 2.0,
        jitter: bool = True
    ):
        self.base_delay = base_delay
        self.max_delay = max_delay
        self.exponential_base = exponential_base
        self.jitter = jitter

    def get_delay(self, attempt: int) -> float:
        delay = min(
            self.base_delay * (self.exponential_base ** attempt),
            self.max_delay
        )

        if self.jitter:
            # Añadir jitter aleatorio (±25%)
            delay = delay * (0.75 + random.random() * 0.5)

        return delay


class LinearBackoff(RetryStrategy):
    """Backoff lineal."""

    def __init__(self, delay: float = 1.0, increment: float = 1.0, max_delay: float = 30.0):
        self.delay = delay
        self.increment = increment
        self.max_delay = max_delay

    def get_delay(self, attempt: int) -> float:
        return min(self.delay + self.increment * attempt, self.max_delay)


class ConstantBackoff(RetryStrategy):
    """Delay constante entre intentos."""

    def __init__(self, delay: float = 1.0):
        self.delay = delay

    def get_delay(self, attempt: int) -> float:
        return self.delay


def with_retry(
    max_attempts: int = 3,
    strategy: RetryStrategy = None,
    retry_on: Tuple[Type[Exception], ...] = (Exception,),
    on_retry: Callable = None
):
    """
    Decorador para retry automático.

    Args:
        max_attempts: Máximo de intentos
        strategy: Estrategia de backoff
        retry_on: Excepciones que disparan retry
        on_retry: Callback al hacer retry
    """
    strategy = strategy or ExponentialBackoff()

    def decorator(func: Callable):
        @wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None

            for attempt in range(max_attempts):
                try:
                    return func(*args, **kwargs)

                except retry_on as e:
                    last_exception = e

                    if attempt < max_attempts - 1:
                        delay = strategy.get_delay(attempt)

                        if on_retry:
                            on_retry(attempt, e, delay)

                        time.sleep(delay)

            raise last_exception

        return wrapper
    return decorator


class RetryableHTTPClient:
    """Cliente HTTP con retry automático."""

    def __init__(
        self,
        rate_limiter: CompositeRateLimiter = None,
        retry_strategy: RetryStrategy = None,
        max_retries: int = 3,
        retry_status_codes: List[int] = None
    ):
        import requests
        self.session = requests.Session()
        self.rate_limiter = rate_limiter
        self.retry_strategy = retry_strategy or ExponentialBackoff()
        self.max_retries = max_retries
        self.retry_status_codes = retry_status_codes or [429, 500, 502, 503, 504]

    def request(self, method: str, url: str, **kwargs) -> 'requests.Response':
        """Ejecuta request con rate limiting y retry."""
        import requests

        last_response = None

        for attempt in range(self.max_retries + 1):
            # Rate limiting
            if self.rate_limiter:
                if not self.rate_limiter.acquire(timeout=60):
                    raise Exception("Rate limit timeout")

            try:
                response = self.session.request(method, url, **kwargs)

                # Verificar si necesita retry
                if response.status_code in self.retry_status_codes:
                    last_response = response

                    if attempt < self.max_retries:
                        # Respetar Retry-After header si existe
                        retry_after = response.headers.get("Retry-After")
                        if retry_after:
                            delay = float(retry_after)
                        else:
                            delay = self.retry_strategy.get_delay(attempt)

                        print(f"Retry {attempt + 1}/{self.max_retries} after {delay:.1f}s "
                              f"(status: {response.status_code})")
                        time.sleep(delay)
                        continue

                return response

            except requests.RequestException as e:
                if attempt < self.max_retries:
                    delay = self.retry_strategy.get_delay(attempt)
                    print(f"Retry {attempt + 1}/{self.max_retries} after {delay:.1f}s "
                          f"(error: {e})")
                    time.sleep(delay)
                else:
                    raise

        return last_response
```

### Tool con rate limiting

```python
class RateLimitedAPITool:
    """Tool de API con rate limiting integrado."""

    def __init__(self, config: RateLimitConfig = None):
        self.limiter = CompositeRateLimiter(
            config or RateLimitConfig(
                requests_per_second=5,
                requests_per_minute=100
            )
        )
        self.client = RetryableHTTPClient(
            rate_limiter=self.limiter,
            max_retries=3
        )
        self.stats = {
            "total_requests": 0,
            "successful": 0,
            "rate_limited": 0,
            "errors": 0
        }

    def get_tool_definition(self) -> Dict:
        return {
            "name": "api_request",
            "description": """
Realiza requests a APIs externas con rate limiting automático.
El sistema maneja automáticamente:
- Límites de requests por segundo/minuto
- Reintentos con backoff exponencial
- Errores 429 (Too Many Requests)
""",
            "parameters": {
                "type": "object",
                "properties": {
                    "method": {"type": "string", "enum": ["GET", "POST", "PUT", "DELETE"]},
                    "url": {"type": "string"},
                    "headers": {"type": "object"},
                    "body": {"type": "object"}
                },
                "required": ["method", "url"]
            }
        }

    def execute(
        self,
        method: str,
        url: str,
        headers: Dict = None,
        body: Dict = None
    ) -> Dict:
        """Ejecuta request con rate limiting."""
        self.stats["total_requests"] += 1

        try:
            response = self.client.request(
                method=method,
                url=url,
                headers=headers,
                json=body
            )

            if response.status_code == 429:
                self.stats["rate_limited"] += 1
                return {
                    "success": False,
                    "error": "Rate limited",
                    "retry_after": response.headers.get("Retry-After")
                }

            self.stats["successful"] += 1

            return {
                "success": response.ok,
                "status_code": response.status_code,
                "data": response.json() if response.headers.get("content-type", "").startswith("application/json") else response.text,
                "rate_limit_status": self.limiter.get_status()
            }

        except Exception as e:
            self.stats["errors"] += 1
            return {
                "success": False,
                "error": str(e)
            }

    def get_stats(self) -> Dict:
        """Retorna estadísticas de uso."""
        return {
            **self.stats,
            "rate_limit_status": self.limiter.get_status()
        }
```

---

## Manejo de headers de rate limit

```python
class RateLimitHeaderParser:
    """Parsea headers de rate limit de diferentes APIs."""

    # Mapeo de headers comunes
    HEADER_MAPPINGS = {
        # GitHub style
        "x-ratelimit-limit": "limit",
        "x-ratelimit-remaining": "remaining",
        "x-ratelimit-reset": "reset",

        # OpenAI/Anthropic style
        "x-ratelimit-limit-requests": "limit_requests",
        "x-ratelimit-remaining-requests": "remaining_requests",
        "x-ratelimit-limit-tokens": "limit_tokens",
        "x-ratelimit-remaining-tokens": "remaining_tokens",

        # Standard
        "retry-after": "retry_after",
        "ratelimit-limit": "limit",
        "ratelimit-remaining": "remaining",
        "ratelimit-reset": "reset"
    }

    @classmethod
    def parse(cls, headers: Dict) -> Dict:
        """Parsea headers de rate limit."""
        result = {}

        headers_lower = {k.lower(): v for k, v in headers.items()}

        for header, key in cls.HEADER_MAPPINGS.items():
            if header in headers_lower:
                value = headers_lower[header]
                try:
                    result[key] = int(value)
                except ValueError:
                    result[key] = value

        return result

    @classmethod
    def should_wait(cls, headers: Dict) -> Tuple[bool, float]:
        """Determina si se debe esperar y por cuánto."""
        parsed = cls.parse(headers)

        # Verificar Retry-After
        if "retry_after" in parsed:
            return True, float(parsed["retry_after"])

        # Verificar remaining
        remaining = parsed.get("remaining", parsed.get("remaining_requests"))
        if remaining is not None and remaining <= 0:
            # Calcular tiempo hasta reset
            reset = parsed.get("reset")
            if reset:
                wait_time = reset - time.time()
                if wait_time > 0:
                    return True, wait_time

            return True, 60.0  # Default 60s

        return False, 0
```

---

## Errores frecuentes

### Error 1: No respetar Retry-After

```python
# ❌ Ignorar el header
def bad_retry(response):
    if response.status_code == 429:
        time.sleep(1)  # Delay arbitrario
        retry()

# ✓ Respetar Retry-After
def good_retry(response):
    if response.status_code == 429:
        retry_after = response.headers.get("Retry-After", "60")
        time.sleep(float(retry_after))
        retry()
```

### Error 2: Retry en errores no transitorios

```python
# ❌ Retry en cualquier error
@with_retry(max_attempts=5)
def bad_api_call():
    response = requests.get(url)
    response.raise_for_status()  # Retry en 401, 403, 404...

# ✓ Solo retry en errores transitorios
@with_retry(
    max_attempts=5,
    retry_on=(requests.Timeout, requests.ConnectionError)
)
def good_api_call():
    response = requests.get(url)
    if response.status_code in [429, 500, 502, 503, 504]:
        raise RetryableError()
    response.raise_for_status()
```

---

## Resumen del concepto

**En una frase**: Rate limiting y retry patterns permiten a los agentes interactuar con APIs de forma sostenible y resiliente.

**Estrategias de backoff**:
- **Exponencial**: 1s, 2s, 4s, 8s... (más común)
- **Lineal**: 1s, 2s, 3s, 4s...
- **Constante**: 1s, 1s, 1s...

**Headers importantes**:
- `Retry-After`: Tiempo de espera obligatorio
- `X-RateLimit-Remaining`: Requests restantes
- `X-RateLimit-Reset`: Timestamp de reset

**Mejores prácticas**:
1. Implementar rate limiting local preventivo
2. Respetar siempre Retry-After
3. Usar jitter en backoff para evitar thundering herd
4. Solo retry en errores transitorios
5. Monitorear estadísticas de rate limit

**Siguiente paso**: Módulo 4 - Arquitectura de Agentes Básicos.
