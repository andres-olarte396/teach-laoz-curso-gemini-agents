# 8.2.1 Razonamiento Causal

## Objetivo de Aprendizaje

Implementar agentes capaces de razonar sobre relaciones causa-efecto, construir modelos causales din√°micos y tomar decisiones basadas en inferencia causal usando Google Gemini.

## Introducci√≥n

El razonamiento causal va m√°s all√° de la correlaci√≥n estad√≠stica. Permite a los agentes entender por qu√© ocurren las cosas, predecir efectos de intervenciones y razonar contrafactualmente ("¬øqu√© hubiera pasado si...?"). Esta capacidad es fundamental para agentes que deben tomar decisiones en entornos complejos.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    CAUSAL REASONING FRAMEWORK                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ   NIVELES DE RAZONAMIENTO CAUSAL (Pearl's Ladder)              ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ   3. CONTRAFACTUAL      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ      "¬øQu√© hubiera      ‚îÇ Si X hubiera sido diferente,    ‚îÇ    ‚îÇ
‚îÇ       pasado si...?"    ‚îÇ ¬øc√≥mo habr√≠a cambiado Y?        ‚îÇ    ‚îÇ
‚îÇ                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                    ‚ñ≤                            ‚îÇ
‚îÇ   2. INTERVENCI√ìN       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ      "¬øQu√© pasa si      ‚îÇ Si forzamos X=x, ¬øqu√©          ‚îÇ    ‚îÇ
‚îÇ       hago...?"         ‚îÇ valor tendr√° Y?                 ‚îÇ    ‚îÇ
‚îÇ                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                    ‚ñ≤                            ‚îÇ
‚îÇ   1. OBSERVACI√ìN        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ      "¬øQu√© veo?"        ‚îÇ Dado X=x, ¬øcu√°l es P(Y)?       ‚îÇ    ‚îÇ
‚îÇ                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ   MODELO CAUSAL:                                               ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ      ‚îå‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îê                          ‚îÇ
‚îÇ      ‚îÇ A ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ B ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ C ‚îÇ                          ‚îÇ
‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚î¨‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ
‚îÇ                     ‚îÇ            ‚ñ≤                             ‚îÇ
‚îÇ                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                             ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Implementaci√≥n del Modelo Causal

```python
"""
Sistema de razonamiento causal para agentes.
"""
import google.generativeai as genai
from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Set, Tuple
from datetime import datetime
from enum import Enum
import json
import os
import networkx as nx


class RelationType(Enum):
    """Tipos de relaci√≥n causal."""
    CAUSES = "causes"
    PREVENTS = "prevents"
    ENABLES = "enables"
    CORRELATES = "correlates"
    INFLUENCES = "influences"


@dataclass
class CausalRelation:
    """Representa una relaci√≥n causal."""
    cause: str
    effect: str
    relation_type: RelationType
    strength: float  # 0-1
    confidence: float  # 0-1
    conditions: List[str] = field(default_factory=list)
    evidence: List[str] = field(default_factory=list)
    discovered_at: datetime = field(default_factory=datetime.now)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "cause": self.cause,
            "effect": self.effect,
            "relation_type": self.relation_type.value,
            "strength": self.strength,
            "confidence": self.confidence,
            "conditions": self.conditions
        }


class CausalGraph:
    """Grafo de relaciones causales."""

    def __init__(self):
        self.graph = nx.DiGraph()
        self.relations: Dict[Tuple[str, str], CausalRelation] = {}

    def add_variable(self, name: str, properties: Dict[str, Any] = None):
        """Agrega variable al grafo."""
        self.graph.add_node(name, **(properties or {}))

    def add_relation(self, relation: CausalRelation):
        """Agrega relaci√≥n causal."""
        self.graph.add_edge(
            relation.cause,
            relation.effect,
            relation_type=relation.relation_type.value,
            strength=relation.strength,
            confidence=relation.confidence
        )
        self.relations[(relation.cause, relation.effect)] = relation

    def get_causes(self, effect: str) -> List[str]:
        """Obtiene causas directas de un efecto."""
        return list(self.graph.predecessors(effect))

    def get_effects(self, cause: str) -> List[str]:
        """Obtiene efectos directos de una causa."""
        return list(self.graph.successors(cause))

    def get_all_ancestors(self, node: str) -> Set[str]:
        """Obtiene todas las causas ancestrales."""
        return nx.ancestors(self.graph, node)

    def get_all_descendants(self, node: str) -> Set[str]:
        """Obtiene todos los efectos descendientes."""
        return nx.descendants(self.graph, node)

    def find_causal_paths(
        self,
        source: str,
        target: str
    ) -> List[List[str]]:
        """Encuentra todos los caminos causales."""
        try:
            return list(nx.all_simple_paths(self.graph, source, target))
        except nx.NetworkXError:
            return []

    def get_confounders(self, cause: str, effect: str) -> Set[str]:
        """Identifica confounders entre causa y efecto."""
        cause_ancestors = self.get_all_ancestors(cause)
        effect_ancestors = self.get_all_ancestors(effect)
        return cause_ancestors & effect_ancestors

    def to_dict(self) -> Dict[str, Any]:
        """Serializa el grafo."""
        return {
            "nodes": list(self.graph.nodes()),
            "relations": [r.to_dict() for r in self.relations.values()]
        }

    def from_dict(self, data: Dict[str, Any]):
        """Deserializa el grafo."""
        for node in data.get("nodes", []):
            self.add_variable(node)

        for rel_data in data.get("relations", []):
            relation = CausalRelation(
                cause=rel_data["cause"],
                effect=rel_data["effect"],
                relation_type=RelationType(rel_data["relation_type"]),
                strength=rel_data["strength"],
                confidence=rel_data["confidence"],
                conditions=rel_data.get("conditions", [])
            )
            self.add_relation(relation)


class CausalReasoner:
    """Motor de razonamiento causal."""

    def __init__(self, api_key: str = None):
        genai.configure(api_key=api_key or os.getenv("GOOGLE_API_KEY"))
        self.model = genai.GenerativeModel("gemini-1.5-flash")
        self.causal_graph = CausalGraph()

    def discover_relations(
        self,
        observations: List[Dict[str, Any]]
    ) -> List[CausalRelation]:
        """Descubre relaciones causales de observaciones."""
        obs_text = json.dumps(observations[:10], indent=2)

        prompt = f"""Analiza estas observaciones e identifica relaciones causales.

OBSERVACIONES:
{obs_text}

Para cada relaci√≥n causal identificada, considera:
1. ¬øEs una causa directa o hay intermediarios?
2. ¬øHay variables confusoras?
3. ¬øCu√°l es la fuerza de la relaci√≥n?
4. ¬øBajo qu√© condiciones aplica?

Responde con JSON:
{{
    "relations": [
        {{
            "cause": "variable_causa",
            "effect": "variable_efecto",
            "relation_type": "causes|prevents|enables|influences",
            "strength": 0.0-1.0,
            "confidence": 0.0-1.0,
            "conditions": ["condici√≥n1"],
            "evidence": ["evidencia que soporta esta relaci√≥n"]
        }}
    ],
    "confounders_identified": ["variable1", "variable2"]
}}"""

        response = self.model.generate_content(prompt)

        try:
            text = response.text
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0]

            result = json.loads(text.strip())
            relations = []

            for rel_data in result.get("relations", []):
                relation = CausalRelation(
                    cause=rel_data["cause"],
                    effect=rel_data["effect"],
                    relation_type=RelationType(rel_data.get("relation_type", "influences")),
                    strength=float(rel_data.get("strength", 0.5)),
                    confidence=float(rel_data.get("confidence", 0.5)),
                    conditions=rel_data.get("conditions", []),
                    evidence=rel_data.get("evidence", [])
                )
                relations.append(relation)
                self.causal_graph.add_relation(relation)

            return relations

        except (json.JSONDecodeError, KeyError):
            return []

    def predict_intervention(
        self,
        intervention: Dict[str, Any],
        target_variable: str
    ) -> Dict[str, Any]:
        """Predice efecto de una intervenci√≥n."""
        # Obtener variables afectadas
        intervened_var = list(intervention.keys())[0]
        effects = self.causal_graph.get_all_descendants(intervened_var)

        # Encontrar caminos causales
        paths = self.causal_graph.find_causal_paths(intervened_var, target_variable)

        # Serializar grafo para contexto
        graph_context = self.causal_graph.to_dict()

        prompt = f"""Predice el efecto de esta intervenci√≥n usando razonamiento causal.

INTERVENCI√ìN:
{json.dumps(intervention)}

VARIABLE OBJETIVO: {target_variable}

MODELO CAUSAL:
{json.dumps(graph_context, indent=2)}

CAMINOS CAUSALES RELEVANTES:
{paths if paths else "No hay caminos directos"}

VARIABLES QUE SER√ÅN AFECTADAS:
{list(effects)}

Razona sobre:
1. Efecto directo de la intervenci√≥n
2. Efectos indirectos a trav√©s de mediadores
3. Posibles efectos colaterales
4. Incertidumbre en la predicci√≥n

Responde con JSON:
{{
    "predicted_effect": {{
        "{target_variable}": {{
            "direction": "increase|decrease|no_change",
            "magnitude": "small|medium|large",
            "confidence": 0.0-1.0
        }}
    }},
    "mechanism": "explicaci√≥n del mecanismo causal",
    "side_effects": [
        {{"variable": "var", "effect": "descripci√≥n"}}
    ],
    "assumptions": ["asunci√≥n1", "asunci√≥n2"]
}}"""

        response = self.model.generate_content(prompt)

        try:
            text = response.text
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0]
            return json.loads(text.strip())
        except:
            return {
                "predicted_effect": {target_variable: {"direction": "unknown", "confidence": 0.3}},
                "mechanism": "No se pudo determinar",
                "side_effects": [],
                "assumptions": []
            }

    def counterfactual_reasoning(
        self,
        actual_scenario: Dict[str, Any],
        counterfactual_change: Dict[str, Any],
        outcome_variable: str
    ) -> Dict[str, Any]:
        """Razonamiento contrafactual: ¬øqu√© hubiera pasado si...?"""
        graph_context = self.causal_graph.to_dict()

        prompt = f"""Realiza razonamiento contrafactual.

ESCENARIO REAL:
{json.dumps(actual_scenario, indent=2)}

CAMBIO CONTRAFACTUAL:
"¬øQu√© hubiera pasado si {json.dumps(counterfactual_change)} hubiera sido diferente?"

VARIABLE DE RESULTADO: {outcome_variable}

MODELO CAUSAL:
{json.dumps(graph_context, indent=2)}

Pasos del razonamiento contrafactual:
1. ABDUCCI√ìN: Determinar valores de variables ex√≥genas dado el escenario real
2. INTERVENCI√ìN: Aplicar el cambio contrafactual
3. PREDICCI√ìN: Propagar efectos para obtener nuevo outcome

Responde con JSON:
{{
    "original_outcome": "valor/estado original de {outcome_variable}",
    "counterfactual_outcome": "valor/estado contrafactual",
    "difference": "descripci√≥n de la diferencia",
    "probability_of_change": 0.0-1.0,
    "reasoning_chain": [
        "paso 1: ...",
        "paso 2: ..."
    ],
    "key_mediators": ["variable que media el efecto"],
    "confidence": 0.0-1.0
}}"""

        response = self.model.generate_content(prompt)

        try:
            text = response.text
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0]
            return json.loads(text.strip())
        except:
            return {
                "original_outcome": "unknown",
                "counterfactual_outcome": "unknown",
                "confidence": 0.3
            }

    def explain_causally(
        self,
        event: str,
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Genera explicaci√≥n causal de un evento."""
        graph_context = self.causal_graph.to_dict()

        prompt = f"""Genera una explicaci√≥n causal para este evento.

EVENTO A EXPLICAR: {event}

CONTEXTO:
{json.dumps(context, indent=2)}

MODELO CAUSAL CONOCIDO:
{json.dumps(graph_context, indent=2)}

Proporciona una explicaci√≥n causal que incluya:
1. Causas inmediatas (directas)
2. Causas distales (ra√≠z)
3. Factores contribuyentes
4. Cadena causal completa

Responde con JSON:
{{
    "immediate_causes": [
        {{"cause": "causa", "contribution": 0.0-1.0, "mechanism": "c√≥mo"}}
    ],
    "root_causes": [
        {{"cause": "causa", "chain": ["paso1", "paso2", "evento"]}}
    ],
    "contributing_factors": ["factor1", "factor2"],
    "causal_narrative": "Narrativa explicativa completa",
    "alternative_explanations": [
        {{"explanation": "alternativa", "plausibility": 0.0-1.0}}
    ]
}}"""

        response = self.model.generate_content(prompt)

        try:
            text = response.text
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0]
            return json.loads(text.strip())
        except:
            return {
                "causal_narrative": "No se pudo generar explicaci√≥n",
                "immediate_causes": [],
                "root_causes": []
            }


# Ejemplo de uso
if __name__ == "__main__":
    reasoner = CausalReasoner()

    # Agregar relaciones conocidas
    reasoner.causal_graph.add_relation(CausalRelation(
        cause="precio_alto",
        effect="ventas_bajas",
        relation_type=RelationType.CAUSES,
        strength=0.7,
        confidence=0.9
    ))

    reasoner.causal_graph.add_relation(CausalRelation(
        cause="marketing_activo",
        effect="ventas_altas",
        relation_type=RelationType.CAUSES,
        strength=0.6,
        confidence=0.8
    ))

    reasoner.causal_graph.add_relation(CausalRelation(
        cause="competencia_fuerte",
        effect="ventas_bajas",
        relation_type=RelationType.INFLUENCES,
        strength=0.5,
        confidence=0.7
    ))

    # Predicci√≥n de intervenci√≥n
    print("=== PREDICCI√ìN DE INTERVENCI√ìN ===")
    prediction = reasoner.predict_intervention(
        intervention={"precio_alto": False},
        target_variable="ventas_bajas"
    )
    print(json.dumps(prediction, indent=2))

    # Razonamiento contrafactual
    print("\n=== RAZONAMIENTO CONTRAFACTUAL ===")
    counterfactual = reasoner.counterfactual_reasoning(
        actual_scenario={
            "precio_alto": True,
            "marketing_activo": False,
            "ventas": "bajas"
        },
        counterfactual_change={"marketing_activo": True},
        outcome_variable="ventas"
    )
    print(json.dumps(counterfactual, indent=2))
```

## Agente con Razonamiento Causal

```python
"""
Agente que usa razonamiento causal para tomar decisiones.
"""
import google.generativeai as genai
from dataclasses import dataclass
from typing import List, Dict, Any, Optional
import json
import os


class CausalAgent:
    """Agente con capacidades de razonamiento causal."""

    def __init__(
        self,
        name: str,
        domain: str,
        api_key: str = None
    ):
        self.api_key = api_key or os.getenv("GOOGLE_API_KEY")
        genai.configure(api_key=self.api_key)
        self.model = genai.GenerativeModel("gemini-1.5-flash")

        self.name = name
        self.domain = domain
        self.reasoner = CausalReasoner(self.api_key)
        self.action_history: List[Dict[str, Any]] = []

    def observe_and_update(self, observations: List[Dict[str, Any]]):
        """Observa y actualiza modelo causal."""
        new_relations = self.reasoner.discover_relations(observations)
        print(f"üìä Descubiertas {len(new_relations)} nuevas relaciones causales")

        for rel in new_relations:
            print(f"   {rel.cause} --[{rel.relation_type.value}]--> {rel.effect}")

    def plan_with_causality(
        self,
        goal: str,
        current_state: Dict[str, Any],
        available_actions: List[str]
    ) -> Dict[str, Any]:
        """Planifica acciones usando razonamiento causal."""
        graph_context = self.reasoner.causal_graph.to_dict()

        prompt = f"""Como agente causal en el dominio de {self.domain}, planifica acciones.

META: {goal}

ESTADO ACTUAL:
{json.dumps(current_state, indent=2)}

ACCIONES DISPONIBLES:
{available_actions}

MODELO CAUSAL:
{json.dumps(graph_context, indent=2)}

Razona causalmente:
1. ¬øQu√© variables necesitan cambiar para lograr la meta?
2. ¬øQu√© acciones causan esos cambios?
3. ¬øHay efectos secundarios negativos?
4. ¬øCu√°l es la secuencia √≥ptima?

Responde con JSON:
{{
    "analysis": {{
        "target_variables": ["var que debe cambiar"],
        "current_blockers": ["qu√© impide la meta"],
        "causal_path_to_goal": ["acci√≥n1 causa X", "X causa Y", "Y logra meta"]
    }},
    "recommended_plan": [
        {{
            "action": "acci√≥n",
            "expected_effect": "efecto esperado",
            "causal_mechanism": "por qu√© funciona",
            "risk": "riesgo potencial"
        }}
    ],
    "alternative_plans": [
        {{
            "actions": ["acci√≥n1", "acci√≥n2"],
            "trade_offs": "pros y contras"
        }}
    ],
    "confidence": 0.0-1.0
}}"""

        response = self.model.generate_content(prompt)

        try:
            text = response.text
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0]
            return json.loads(text.strip())
        except:
            return {"recommended_plan": [], "confidence": 0.3}

    def evaluate_action_causally(
        self,
        action: str,
        current_state: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Eval√∫a una acci√≥n usando razonamiento causal."""
        # Predecir efectos
        predictions = {}

        for node in self.reasoner.causal_graph.graph.nodes():
            pred = self.reasoner.predict_intervention(
                intervention={action: True},
                target_variable=node
            )
            predictions[node] = pred.get("predicted_effect", {})

        # An√°lisis de riesgos
        graph_context = self.reasoner.causal_graph.to_dict()

        prompt = f"""Eval√∫a los riesgos causales de esta acci√≥n.

ACCI√ìN PROPUESTA: {action}

ESTADO ACTUAL:
{json.dumps(current_state, indent=2)}

PREDICCIONES DE EFECTOS:
{json.dumps(predictions, indent=2)}

MODELO CAUSAL:
{json.dumps(graph_context, indent=2)}

Eval√∫a:
1. Efectos deseados vs no deseados
2. Reversibilidad de los efectos
3. Cascadas causales potenciales
4. Puntos de no retorno

Responde con JSON:
{{
    "overall_assessment": "favorable|neutral|risky|dangerous",
    "desired_effects": [{{"effect": "...", "probability": 0.0-1.0}}],
    "undesired_effects": [{{"effect": "...", "severity": "low|medium|high"}}],
    "causal_cascades": ["cascada potencial"],
    "reversibility": "fully|partially|irreversible",
    "recommendation": "proceed|proceed_with_caution|reconsider|abort",
    "mitigations": ["acci√≥n de mitigaci√≥n"]
}}"""

        response = self.model.generate_content(prompt)

        try:
            text = response.text
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0]
            return json.loads(text.strip())
        except:
            return {"overall_assessment": "unknown", "recommendation": "reconsider"}

    def learn_from_outcome(
        self,
        action: str,
        predicted_effects: Dict[str, Any],
        actual_effects: Dict[str, Any]
    ):
        """Aprende de la diferencia entre predicci√≥n y realidad."""
        prompt = f"""Analiza la diferencia entre efectos predichos y reales.

ACCI√ìN: {action}

EFECTOS PREDICHOS:
{json.dumps(predicted_effects, indent=2)}

EFECTOS REALES:
{json.dumps(actual_effects, indent=2)}

Identifica:
1. ¬øQu√© relaciones causales fueron correctas?
2. ¬øCu√°les fueron incorrectas?
3. ¬øHay relaciones causales no modeladas?
4. ¬øC√≥mo actualizar el modelo?

Responde con JSON:
{{
    "correct_predictions": ["predicci√≥n1"],
    "incorrect_predictions": [
        {{"prediction": "...", "actual": "...", "possible_reason": "..."}}
    ],
    "missing_relations": [
        {{"cause": "...", "effect": "...", "evidence": "..."}}
    ],
    "model_updates": [
        {{"relation": "causa->efecto", "update": "aumentar|disminuir|eliminar|agregar"}}
    ]
}}"""

        response = self.model.generate_content(prompt)

        try:
            text = response.text
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0]

            result = json.loads(text.strip())

            # Actualizar modelo con nuevas relaciones
            for new_rel in result.get("missing_relations", []):
                relation = CausalRelation(
                    cause=new_rel["cause"],
                    effect=new_rel["effect"],
                    relation_type=RelationType.INFLUENCES,
                    strength=0.5,
                    confidence=0.6,
                    evidence=[new_rel.get("evidence", "Observado en ejecuci√≥n")]
                )
                self.reasoner.causal_graph.add_relation(relation)

            return result

        except:
            return {}

    def explain_decision(
        self,
        decision: str,
        context: Dict[str, Any]
    ) -> str:
        """Explica una decisi√≥n en t√©rminos causales."""
        explanation = self.reasoner.explain_causally(
            event=f"Decisi√≥n de {decision}",
            context=context
        )

        narrative = explanation.get("causal_narrative", "")

        return f"""
**Explicaci√≥n Causal de la Decisi√≥n**

{narrative}

**Causas Inmediatas:**
{json.dumps(explanation.get('immediate_causes', []), indent=2)}

**Causas Ra√≠z:**
{json.dumps(explanation.get('root_causes', []), indent=2)}

**Factores Contribuyentes:**
{', '.join(explanation.get('contributing_factors', []))}
"""


# Ejemplo de uso
if __name__ == "__main__":
    agent = CausalAgent(
        name="BusinessAgent",
        domain="gesti√≥n empresarial"
    )

    # Agregar conocimiento causal inicial
    agent.reasoner.causal_graph.add_relation(CausalRelation(
        cause="inversi√≥n_marketing",
        effect="conocimiento_marca",
        relation_type=RelationType.CAUSES,
        strength=0.8,
        confidence=0.9
    ))

    agent.reasoner.causal_graph.add_relation(CausalRelation(
        cause="conocimiento_marca",
        effect="ventas",
        relation_type=RelationType.CAUSES,
        strength=0.6,
        confidence=0.8
    ))

    agent.reasoner.causal_graph.add_relation(CausalRelation(
        cause="calidad_producto",
        effect="satisfaccion_cliente",
        relation_type=RelationType.CAUSES,
        strength=0.9,
        confidence=0.95
    ))

    agent.reasoner.causal_graph.add_relation(CausalRelation(
        cause="satisfaccion_cliente",
        effect="ventas",
        relation_type=RelationType.CAUSES,
        strength=0.7,
        confidence=0.85
    ))

    # Planificar para aumentar ventas
    print("=== PLANIFICACI√ìN CAUSAL ===")
    plan = agent.plan_with_causality(
        goal="Aumentar ventas en 20%",
        current_state={
            "ventas": "estables",
            "conocimiento_marca": "medio",
            "satisfaccion_cliente": "alta",
            "presupuesto": "limitado"
        },
        available_actions=[
            "aumentar_inversi√≥n_marketing",
            "mejorar_calidad_producto",
            "reducir_precios",
            "expandir_canales"
        ]
    )

    print(json.dumps(plan, indent=2))

    # Evaluar acci√≥n espec√≠fica
    print("\n=== EVALUACI√ìN CAUSAL ===")
    evaluation = agent.evaluate_action_causally(
        action="reducir_precios",
        current_state={"margen_ganancia": "saludable", "competencia": "agresiva"}
    )

    print(json.dumps(evaluation, indent=2))
```

## Ejercicios Pr√°cticos

### Ejercicio 1: Detector de Causalidad Espuria
```python
"""
Ejercicio: Detectar relaciones causales espurias.
"""

class SpuriousCausalityDetector:
    """
    TODO: Implementar detector que:
    1. Identifique correlaciones que no son causales
    2. Detecte variables confusoras ocultas
    3. Sugiera experimentos para verificar causalidad
    4. Calcule probabilidad de que relaci√≥n sea espuria
    """

    def analyze_relation(
        self,
        cause: str,
        effect: str,
        data: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Analiza si una relaci√≥n es espuria."""
        pass
```

### Ejercicio 2: Simulador de Intervenciones
```python
"""
Ejercicio: Simular efectos de intervenciones.
"""

class InterventionSimulator:
    """
    TODO: Implementar simulador que:
    1. Modele sistema con ecuaciones estructurales
    2. Simule do(X=x) interventions
    3. Genere distribuciones de resultados
    4. Calcule intervalos de confianza
    """

    def simulate(
        self,
        intervention: Dict[str, Any],
        num_simulations: int = 1000
    ) -> Dict[str, Any]:
        """Simula intervenci√≥n."""
        pass
```

## Resumen

| Componente | Funci√≥n | Nivel de Pearl |
|------------|---------|----------------|
| **CausalGraph** | Modelado de relaciones | Estructura |
| **predict_intervention** | Efecto de do(X) | Intervenci√≥n |
| **counterfactual_reasoning** | ¬øQu√© hubiera pasado? | Contrafactual |
| **discover_relations** | Aprendizaje de estructura | Observaci√≥n |
| **explain_causally** | Narrativas causales | Explicaci√≥n |

---

**Siguiente:** [8.2.2 Meta-Cognici√≥n: Agentes que Razonan sobre su Razonamiento](./8.2.2-meta-cognicion.md)
